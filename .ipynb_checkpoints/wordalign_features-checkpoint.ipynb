{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0453510-71c2-4a70-960a-970940bfc5d5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "docstring = \"\"\"\n",
    "(Use fastpitch conda env)\n",
    "\n",
    "Helper script that takes a folder of speech reps (wav2vec2, mel-spec, etc.)\n",
    "and aligns them at word-level using MFA alignments.\n",
    "\n",
    "Speech reps corresponding to word tokens in the corpus are then saved individually to an output folder\n",
    "with the following structure:\n",
    "- data_path\n",
    "    - word1\n",
    "        - word1_LJ010-0292_001.pt\n",
    "        - word1_LJ010-0292_002.pt\n",
    "        - ...\n",
    "    - word2\n",
    "        - word2_LJ001-0012_001.pt\n",
    "        - word2_LJ002-0024_001.pt\n",
    "        - ...\n",
    "    - ...\n",
    "\n",
    "- word1, word2, ... subfolders refer to a particular wordtype in the corpus.\n",
    "- .pt files contain speech representations that map to a particular example of a wordtype.\n",
    "  It is named as:\n",
    "    <wordtype>_<utt id>_<numbered occurrence in the utterance>.pt\n",
    "\n",
    "Example usage:\n",
    "    #hubert w/ padding offset\n",
    "    cd ~/fairseq\n",
    "    python examples/lexicon_learner/wordalign_speechreps.py \\\n",
    "        -t hubert \\\n",
    "        --padding_idx_offset 1 \\\n",
    "        -s /home/s1785140/fairseq/examples/lexicon_learner/lj_speech_quantized.txt \\\n",
    "        -a /home/s1785140/data/ljspeech_MFA_alignments \\\n",
    "        -o /home/s1785140/data/ljspeech_hubert_reps/hubert-base/layer-6/word_level_with_padding_idx_offset\n",
    "\n",
    "    #hubert w/o padding offset\n",
    "    cd ~/fairseq\n",
    "    python examples/lexicon_learner/wordalign_speechreps.py \\\n",
    "        -t hubert \\\n",
    "        --padding_idx_offset 0 \\\n",
    "        -s /home/s1785140/fairseq/examples/lexicon_learner/lj_speech_quantized.txt \\\n",
    "        -a /home/s1785140/data/ljspeech_MFA_alignments \\\n",
    "        -o /home/s1785140/data/ljspeech_hubert_reps/hubert-base/layer-6/word_level_without_padding_idx_offset\n",
    "\n",
    "    #wav2vec2\n",
    "    cd ~/fairseq\n",
    "    python examples/lexicon_learner/wordalign_speechreps.py \\\n",
    "        -t wav2vec2 \\\n",
    "        -s /home/s1785140/data/ljspeech_wav2vec2_reps/wav2vec2-large-960h/layer-15/utt_level \\\n",
    "        -a /home/s1785140/data/ljspeech_MFA_alignments \\\n",
    "        -o /home/s1785140/data/ljspeech_wav2vec2_reps/wav2vec2-large-960h/layer-15/word_level\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95da2491",
   "metadata": {},
   "source": [
    "Command line args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ed31824-8d7f-4e8c-a96b-937915cfc08f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# imitate CLAs\n",
    "import sys\n",
    "sys.argv = [\n",
    "    # fastpitch features\n",
    "    # 'train.py',\n",
    "    # '--type', 'mel',\n",
    "    # '--utt_id_list', '/home/s1785140/data/ljspeech_fastpitch/respeller_uttids.txt', \n",
    "    # '--input_directory', '/home/s1785140/data/ljspeech_fastpitch/mels',\n",
    "    # '--alignments', '/home/s1785140/data/ljspeech_fastpitch/aligns', \n",
    "    # '--output_directory', '/home/s1785140/data/ljspeech_fastpitch/wordaligned_mels',\n",
    "\n",
    "    # speechbrain features\n",
    "    'train.py',\n",
    "    '--type', 'mel',\n",
    "    '--utt_id_list', '/home/s1785140/data/ljspeech_fastpitch/respeller_uttids.txt', \n",
    "    '--input_directory', '/home/s1785140/speechbrain/templates/speech_recognition_CharTokens_NoLM/data/ljspeech_dumped_feats',\n",
    "    '--alignments', '/home/s1785140/data/ljspeech_fastpitch/aligns', \n",
    "    '--output_directory', '/home/s1785140/speechbrain/templates/speech_recognition_CharTokens_NoLM/data/ljspeech_dumped_feats_word_aligned',\n",
    "    \n",
    "    # FOR TESTING\n",
    "    # '--input_directory', '/home/s1785140/data/ljspeech_fastpitch/mels_test',\n",
    "    # '--alignments', '/home/s1785140/data/ljspeech_fastpitch/aligns_test', \n",
    "    # '--output_directory', '/home/s1785140/data/ljspeech_fastpitch/wordaligned_mels_test',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3f0393f-64f2-4056-b219-a3e4f557516d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import tgt\n",
    "import string\n",
    "\n",
    "SKIP_NON_ASCII = False\n",
    "WORDS_TO_SKIP = [\"wdsu-tv\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1439b58",
   "metadata": {},
   "source": [
    "# Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ff2a0ad-4c05-476f-a430-ddd4e8e92e6e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('-t', '--type', type=str, default='hubert',\n",
    "                    help='type of input speech reps that we are using, i.e. hubert wav2vec2 etc.')\n",
    "parser.add_argument('--padding_idx_offset', type=int, default=0,\n",
    "                    help='add 1 to token id of discrete reps in order to allow for padding_idx==0')\n",
    "parser.add_argument('--utt_id_list', type=str, required=False, default=\"\",\n",
    "                    help='path to text file that contains list of utterance ids that we extract from')\n",
    "parser.add_argument('-s', '--input_directory', type=str, required=True,\n",
    "                    help='path to single non-nested folder containing speech representations (.pt files) or txt file (hubert)')\n",
    "parser.add_argument('-a', '--alignments', type=str, required=True,\n",
    "                    help='path to single non-nested folder containing MFA alignments (.TextGrid files)')\n",
    "parser.add_argument('-o', '--output_directory', type=str, required=True,\n",
    "                    help='where to write word-level data')\n",
    "args = parser.parse_args()\n",
    "\n",
    "if \"speechbrain\" in args.input_directory:\n",
    "    args.corpus_name = \"speechbrain\"\n",
    "    args.transpose_mel = False\n",
    "    SAMPLING_RATE = 16000 # hz\n",
    "    HOP_LENGTH_IN_MS = 10 # in ms\n",
    "    HOP_LENGTH = int(HOP_LENGTH_IN_MS * SAMPLING_RATE / 1000) # convert HOP_LENGTH to samples\n",
    "elif \"ljspeech\" in args.input_directory:\n",
    "    args.corpus_name = \"ljspeech\"\n",
    "    args.transpose_mel = True\n",
    "    SAMPLING_RATE = 22050 # hz\n",
    "    HOP_LENGTH = 256 # in samples\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81205290",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "050c2ce5-b47b-4bf5-96a1-fd8bedc6330a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def save_to_disk(tensor, word, utt_id, count, output_directory):\n",
    "    output_directory = os.path.join(output_directory, word)\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    save_path = os.path.join(output_directory, f'{word}__{utt_id}__occ{count}__seqlen{tensor.size(0)}.pt')\n",
    "    torch.save(tensor, save_path)\n",
    "    \n",
    "def allowed_word(word):\n",
    "    if len(word) <= 1:\n",
    "        return False\n",
    "    if word == '--':\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8affea0-41bb-4739-b9ee-496642017f14",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# load speech reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "225bb850-5a9e-4d90-bc1e-3c44c9d8048d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading mels from disk in dir /home/s1785140/speechbrain/templates/speech_recognition_CharTokens_NoLM/data/ljspeech_dumped_feats for 6551 utts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6551/6551 [02:04<00:00, 52.67it/s]\n"
     ]
    }
   ],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "map_location = 'cuda' if cuda else 'cpu'\n",
    "\n",
    "if args.type == \"hubert\":\n",
    "    with open(args.input_directory, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    num_of_utts = len(lines)\n",
    "    utt_id2speechreps = {l.split('|')[0]:l.split('|')[1] for l in lines}\n",
    "    utt_ids = sorted(utt_id2speechreps.keys()) # ensure we always process utts in same alphabetical order\n",
    "elif args.type == \"wav2vec2\":\n",
    "    num_of_utts = len(os.listdir(args.input_directory))\n",
    "    utt_ids = sorted(file.split('.')[0] for file in os.listdir(args.input_directory))\n",
    "elif args.type == \"mel\":\n",
    "    if args.utt_id_list:\n",
    "        # we specified a subset of utt ids\n",
    "        with open(args.utt_id_list, 'r') as f:\n",
    "            utt_ids = f.read().splitlines()\n",
    "    else:\n",
    "        # all files in directory\n",
    "        utt_ids = list(sorted(file.split('.')[0] for file in os.listdir(args.input_directory)))\n",
    "    num_of_utts = len(utt_ids)\n",
    "    utt_id2speechreps = {}\n",
    "    print(f\"loading mels from disk in dir {args.input_directory} for {len(utt_ids)} utts\")\n",
    "    for utt_id in tqdm(utt_ids):\n",
    "        # load mel data\n",
    "        mel_path = os.path.join(args.input_directory, f'{utt_id}.pt')\n",
    "        mel = torch.load(mel_path, map_location=map_location)\n",
    "        if args.transpose_mel:\n",
    "            mel = mel.transpose(0,1)\n",
    "\n",
    "        # mels should be of shape (T, D) now\n",
    "        utt_id2speechreps[utt_id] = mel\n",
    "else:\n",
    "    raise ValueError(f\"invalid input type {args.type}\")\n",
    "\n",
    "# sanity check - assert that each utt has a corresponding alignment\n",
    "alignment_files = set(os.listdir(args.alignments))\n",
    "for utt_id in utt_ids:\n",
    "    assert f\"{utt_id}.TextGrid\" in alignment_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a8a42a-79ba-468d-9cb8-cae8ef38cb95",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# perform splitting of mel specs using MFA alignments and save to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8392ea9e-a6ac-4084-9558-5e3c1921b96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_textgrid(tier, sampling_rate, hop_length, ignore_all_pauses=True):\n",
    "    # latest MFA replaces silence phones with \"\" in output TextGrids\n",
    "    sil_phones = [\"sil\", \"sp\", \"spn\", \"\"]\n",
    "    utt_start_time = tier[0].start_time\n",
    "    utt_end_time = tier[-1].end_time\n",
    "    phones = []\n",
    "    durations = [] # NOTE includes durations of silences\n",
    "    start_frames = []\n",
    "    end_frames = []\n",
    "    for i, t in enumerate(tier._objects):\n",
    "        s, e, p = t.start_time, t.end_time, t.text\n",
    "        if p not in sil_phones:\n",
    "            phones.append(p)\n",
    "            start_frames.append(int(np.ceil(s * sampling_rate / hop_length)))\n",
    "            end_frames.append(int(np.ceil(e * sampling_rate / hop_length)))\n",
    "            durations.append(int(np.ceil(e * sampling_rate / hop_length)\n",
    "                                 - np.ceil(s * sampling_rate / hop_length)))\n",
    "        else:\n",
    "            if not ignore_all_pauses:\n",
    "                if (i == 0) or (i == len(tier) - 1):\n",
    "                    # leading or trailing silence\n",
    "                    phones.append(\"sil\")\n",
    "                else:\n",
    "                    # short pause between words\n",
    "                    phones.append(\"sp\")\n",
    "\n",
    "    n_samples = utt_end_time * sampling_rate\n",
    "    n_frames = n_samples / hop_length\n",
    "    # fix occasional length mismatches at the end of utterances when\n",
    "    # duration in samples is an integer multiple of hop_length\n",
    "    if n_frames.is_integer():\n",
    "        durations[-1] += 1\n",
    "    return phones, durations, start_frames, end_frames, utt_start_time, utt_end_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d30b8ce-c345-40e2-8ae5-bb1fc4f468bf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split speech reps using word alignments\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                            | 0/6551 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "mel.size(0)=919 != sum(all_durs)=904",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [12], line 43\u001b[0m\n\u001b[1;32m     41\u001b[0m word_occ_in_utt_counter \u001b[38;5;241m=\u001b[39m Counter()\n\u001b[1;32m     42\u001b[0m mel \u001b[38;5;241m=\u001b[39m utt_id2speechreps[utt_id]\n\u001b[0;32m---> 43\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m mel\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28msum\u001b[39m(all_durs), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmel\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m != \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(all_durs)\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m# verify that MFA frame durations match up with the extracted mels\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word, dur, start_frame, end_frame \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(words, all_durs, start_frames, end_frames):\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m allowed_word(word):\n",
      "\u001b[0;31mAssertionError\u001b[0m: mel.size(0)=919 != sum(all_durs)=904"
     ]
    }
   ],
   "source": [
    "longest_word = ''\n",
    "longest_word_utt_id = ''\n",
    "longest_word_num_frames = 0\n",
    "\n",
    "# split each speech reps file using the word-level alignments\n",
    "print(\"split speech reps using word alignments\")\n",
    "for utt_id in tqdm(utt_ids):\n",
    "    # load speech reps\n",
    "    if args.type == \"hubert\":\n",
    "        reps = utt_id2speechreps[utt_id]\n",
    "        reps = [int(s)+args.padding_idx_offset for s in reps.split(' ')] # NOTE add 1 to each index so that 0 is available as a padding_idx\n",
    "        reps = torch.tensor(reps)\n",
    "        reps.requires_grad = False\n",
    "\n",
    "        # check dimensions\n",
    "        if reps.dim() == 1:\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(\"speech representations have an incorrect number of dimensions\")\n",
    "    elif args.type == \"mel\":\n",
    "        reps = utt_id2speechreps[utt_id]\n",
    "        reps.requires_grad = False\n",
    "\n",
    "        # check dimensions\n",
    "        if reps.dim() == 2:\n",
    "            if args.corpus_name == 'speechbrain' and reps.size(1) == 40:\n",
    "                pass\n",
    "            elif args.corpus_name == 'ljspeech' and reps.size(1) == 80:\n",
    "                pass\n",
    "            else:\n",
    "                raise ValueError(f\"feat dimension is wrong size for corpus {reps.size(1)=}\")    \n",
    "        else:\n",
    "            raise ValueError(f\"speech representations have an incorrect number of dimensions {reps.dim()=}\")\n",
    "    else:\n",
    "        raise ValueError(f\"invalid input type {args.type}\")\n",
    "\n",
    "    tg_path = f\"{args.alignments}/{utt_id}.TextGrid\"\n",
    "    tg = tgt.io.read_textgrid(tg_path, include_empty_intervals=True)\n",
    "    words, all_durs, start_frames, end_frames, utt_start, utt_end = parse_textgrid(tg.get_tier_by_name('words'), SAMPLING_RATE, HOP_LENGTH)\n",
    "    \n",
    "    word_occ_in_utt_counter = Counter()\n",
    "    mel = utt_id2speechreps[utt_id]\n",
    "    assert mel.size(0) == sum(all_durs), f\"{mel.size(0)=} != {sum(all_durs)=}\" # verify that MFA frame durations match up with the extracted mels\n",
    "    for word, dur, start_frame, end_frame in zip(words, all_durs, start_frames, end_frames):\n",
    "        if allowed_word(word):\n",
    "            skip_word = False\n",
    "            normalise_non_ascii = False\n",
    "            for c in word:\n",
    "                if c not in string.ascii_lowercase:\n",
    "                    s = f'WARNING: char {c} in word {word}'\n",
    "                    if SKIP_NON_ASCII or word in WORDS_TO_SKIP:\n",
    "                        s += '. skipping!...'\n",
    "                        skip_word = True\n",
    "                    else:\n",
    "                        normalise_non_ascii = True\n",
    "\n",
    "                    print(s)\n",
    "                    \n",
    "            if not skip_word:\n",
    "                if normalise_non_ascii: # normalise word\n",
    "                    prenorm_word = word\n",
    "                    # remove trailing '-'\n",
    "                    word = word.rstrip('-')\n",
    "                    # convert diacritics to ascii\n",
    "                    word = unidecode.unidecode(word)\n",
    "                    print(f\"\\tnormalised '{prenorm_word}' to '{word}'\")\n",
    "                \n",
    "                # check if word is the longest word we have seen so far\n",
    "                word_dur = end_frame - start_frame \n",
    "                if word_dur > longest_word_num_frames:\n",
    "                    longest_word_num_frames = word_dur\n",
    "                    longest_word = word\n",
    "                    longest_word_utt_id = utt_id\n",
    "\n",
    "                # extract mel\n",
    "                wordaligned_mel = mel[start_frame:end_frame]\n",
    "\n",
    "                # save extracted mel to disk\n",
    "                word_occ_in_utt_counter[word] += 1\n",
    "                extracted_timesteps = wordaligned_mel.size(0)\n",
    "                assert dur == extracted_timesteps == word_dur, f\"{dur=}, {extracted_timesteps=}, {word_dur=}\"\n",
    "                save_to_disk(wordaligned_mel, word, utt_id, word_occ_in_utt_counter[word], args.output_directory)\n",
    "\n",
    "print(\"wordtype with longest num of timesteps is\", longest_word, \"from\", longest_word_utt_id, \"with len\", longest_word_num_frames)\n",
    "print(\"you can set transformer max_source_positions to this\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd5c7db-860e-4daf-aa2e-52f6d6a12cff",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# create train,dev,test datasplits for training respeller\n",
    "\n",
    "We hold out WORDTYPES from training for the dev and test splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1d3344-f2ed-44f3-bf87-0f0b038c0421",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835dc300-35a9-4f21-a5d3-584919022662",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "\n",
    "random.seed(1337)\n",
    "\n",
    "train_ratio, dev_ratio, test_ratio = [0.9, 0.05, 0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e9c14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fc263e-51ae-4d31-b7c8-b5b75454bf24",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# get oov wordtypes list (words that are not seen in tts training)\n",
    "oov_wordlist_path = '/home/s1785140/data/ljspeech_fastpitch/oov_list.json'\n",
    "with open(oov_wordlist_path, 'r') as f:\n",
    "    oovs_and_freqs = json.load(f)\n",
    "    \n",
    "all_wordtypes = set(oovs_and_freqs.keys())\n",
    "print(f'original before cleaning/sampling {len(all_wordtypes)=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c6d733-557d-49bf-8ef2-63983caba003",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# clean/remove words that do not have speech reps\n",
    "words_with_aligned_mels = set(os.listdir(args.output_directory))\n",
    "words_no_mels = all_wordtypes - words_with_aligned_mels\n",
    "print(f'{len(words_no_mels)}=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a134aa68-17fb-425e-b5ee-0a4bd19407bd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"list of words to be excluded from respeller training as they do not have mels (likely due to how normalisation is different between mfa and our own data processing):\")\n",
    "words_no_mels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e5f5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cae348a-0333-484a-8245-383537c4877f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# remove these problematic words from respeller training dev test\n",
    "for w in words_no_mels:\n",
    "    del oovs_and_freqs[w]\n",
    "    \n",
    "all_wordtypes = set(oovs_and_freqs.keys())\n",
    "print(f'original after cleaning {len(all_wordtypes)=}')\n",
    "\n",
    "dev_N = int(dev_ratio * len(all_wordtypes))\n",
    "test_N = int(test_ratio * len(all_wordtypes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ce65fc-a973-4fbc-8b82-e63dd0131ee8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def sample_and_remove(s: set, N: int):\n",
    "    \"\"\"sample N words from set s\n",
    "    then remove these words from the set\"\"\"\n",
    "    sampled = random.sample(s, N)\n",
    "    for item in sampled:\n",
    "        s.remove(item)\n",
    "    return set(sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3e4eed-a336-43c1-8634-8b54707034fd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#get dev and test splits\n",
    "oov_singletons = set(wordtype for wordtype, freq in oovs_and_freqs.items() if freq == 1)\n",
    "assert len(oov_singletons) > dev_N + test_N, \"not enough OOV singletons to create dev and test sets\" \n",
    "print(f'before sampling dev and test {len(oov_singletons)=}')\n",
    "\n",
    "dev = sample_and_remove(oov_singletons, dev_N)\n",
    "print(f'after sampling dev {len(oov_singletons)=}, {len(dev)=}')\n",
    "\n",
    "test = sample_and_remove(oov_singletons, test_N)\n",
    "print(f'after sampling test {len(oov_singletons)=}, {len(test)=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69f58b0-b7c7-4c54-9333-adee647b291b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "list(dev)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb7c6d1-0c33-479d-8cbf-859fba31d7bd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "list(test)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01092fe6-fd9f-42db-a206-01097ef558e9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#get train split\n",
    "print(f'before removing dev and test wordtypes {len(all_wordtypes)=}')\n",
    "for word in dev | test:\n",
    "    all_wordtypes.remove(word)\n",
    "print(f'after removing dev and test wordtypes {len(all_wordtypes)=}')\n",
    "\n",
    "train = set(all_wordtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa0bce1-1baa-422d-a6eb-fb53e8d05964",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# sanity checks\n",
    "assert len(dev.intersection(test)) == 0\n",
    "assert len(train.intersection(dev)) == 0\n",
    "assert len(train.intersection(test)) == 0\n",
    "print(\"Good! No overlapping words between train, dev, and test!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455c0255-bf59-480b-9d83-6b43376125f0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# write to disk\n",
    "def save_wordlist(path, words):\n",
    "    with open(path, 'w') as f:\n",
    "        json.dump(sorted(list(words)), f, indent=4)\n",
    "        \n",
    "train_path = '/home/s1785140/data/ljspeech_fastpitch/respeller_train_words.json'\n",
    "dev_path = '/home/s1785140/data/ljspeech_fastpitch/respeller_dev_words.json'\n",
    "test_path = '/home/s1785140/data/ljspeech_fastpitch/respeller_test_words.json'\n",
    "\n",
    "save_wordlist(train_path, train)\n",
    "save_wordlist(dev_path, dev)\n",
    "save_wordlist(test_path, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61f2ebd-5d54-4e81-ae06-295add409a5e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## G2P selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c63569d-3f12-45c0-ba6a-a4379235d35f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "2ed8b345ca459c03f8526b7bad908d345c967956aebabae0df909223b22f2255"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
