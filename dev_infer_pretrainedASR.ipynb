{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4207e21b-d910-485b-8b9c-3fc7d5a59c5a",
   "metadata": {},
   "source": [
    "# Goal of this notebook\n",
    "\n",
    "Develop a training loop for finetuning ASR models using TTS loss by recreating RL training found in RL4LMs/rl4lms/envs/text_generation/training_utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70687ad-9f13-4cdf-8ef7-07eecb34f496",
   "metadata": {},
   "source": [
    "# automatic reloading magic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738aac35-fdd1-4452-aff0-92caa77ec5ab",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53032f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strickland.inf.ed.ac.uk\n"
     ]
    }
   ],
   "source": [
    "# print hostname to make sure we are on correct node\n",
    "import socket\n",
    "print(socket.gethostname())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6f67235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/disk/nfs/ostrom/s1785140/rlspeller'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c8a89c2-38ea-4778-8028-0c7854152301",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import List, Dict, Tuple, Any\n",
    "import hyperpyyaml\n",
    "from tqdm import tqdm\n",
    "from torchaudio.models.decoder import ctc_decoder\n",
    "from torch.nn.functional import softmax\n",
    "import random\n",
    "from jiwer import cer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f67b1b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "723e84d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speechbrain as sb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b236619f-6c04-44b1-a697-a342417a6694",
   "metadata": {},
   "source": [
    "# HPARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8a11879-640c-433e-a192-9c8b551d8ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    \"softdtw_temp\": 0.01,\n",
    "    \"softdtw_bandwidth\": 120,\n",
    "    \"dist_func\": \"l1\",\n",
    "    \"sentencepiece_model_path\": \"/home/s1785140/speechbrain/templates/speech_recognition_CharTokens_NoLM/Tokenizer/save/0_char.model\",\n",
    "    'speechbrain_hparams_file': '/home/s1785140/rlspeller/infer_speechbrain.yaml',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e877615-a6ff-4755-a7e4-e6f72e542432",
   "metadata": {},
   "source": [
    "# TOKENIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0505c38d-bc92-4f84-9f1f-cfc942ad337d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "# load pretrained tokenizer used to tokenizer ASR training inputs \n",
    "import sentencepiece as spm \n",
    "spm_path = hparams[\"sentencepiece_model_path\"]\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(spm_path)\n",
    "print(sp.vocab_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4af21be-9224-4c45-87f6-b86a8d7c63ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 10 2 12 12 4 1 17 4 9 12 11 1 16 20 1 6 5 16 2 1 7 8 1 26 5 8 4 6\n"
     ]
    }
   ],
   "source": [
    "# test tokenizer\n",
    "s = \"hello world my name is jason\"\n",
    "# TODO pass string through text cleaners? \n",
    "encoded = sp.EncodeAsIds(s)\n",
    "assert 0 not in encoded, \"tried to encode an unknown character\"\n",
    "print(\" \".join(str(idx) for idx in encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe3c6048-79c5-47b4-9524-88d2e36ad8d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello world my name is jason'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.DecodeIds(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2996d1f1-d331-4919-8742-7907b46a46ce",
   "metadata": {},
   "source": [
    "# NEW! SIMPLE TOKENIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8951a84-e22e-4c62-a169-403a1b5269af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from speechbrain.tokenizers.SimpleTokenizer import SimpleTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bfec85a8-d20d-445e-8483-cf27092e2962",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = SimpleTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c52e4b5-8d26-44c3-a1ad-c772b6feac62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello|my|name|is|jason\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[9, 6, 13, 13, 16, 1, 14, 26, 1, 15, 2, 14, 6, 1, 10, 20, 1, 11, 2, 20, 16, 15]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"hello my name is jason\"\n",
    "text = text.replace(' ', '|')\n",
    "print(text)\n",
    "ids = tokenizer.encode_as_ids(text)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f5f1bf5e-500b-47ce-986c-3cbe059cdf41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello|my|name|is|jason'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode_ids(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5ea5f7-6224-4089-8136-5c4b8d47a2e2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## test simple tokenizer with probability distribution, and see if CTC decoder successfully generates n-best lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a60ffb1b-6770-466c-90f6-6daa1dbe461b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create empty array of correct dimensions\n",
    "min_len, max_len = 50, 100\n",
    "bsz = 4\n",
    "lens = torch.randint(min_len, max_len, (bsz,))\n",
    "vocab_size = len(tokenizer.vocab)\n",
    "\n",
    "# randomly assign probaility distribution to each timestep\n",
    "\n",
    "# try to decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cac82712-8559-44d0-86d9-66cf1ddfbd5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "randn = torch.randn(bsz, max_len, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26e7e51c-bab1-4f2d-bb12-34f9f9c4454c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ctc_probs = softmax(randn, dim=1)\n",
    "# ctc_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f9abdc6-bd05-4c5c-a091-d04dadbaa9e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('sample 1, hyp 1/2', ['|swz|etfmkjvaurzncidhagmenaojbmzsqtlrnlzjnbtuiqliqcpbzbmtok|rakymfuh|izqvjcmpvrokhc|'])\n",
      "('sample 1, hyp 2/2', ['|swz|atfmkjvaurzncidhagmenaojbmzsqtlrnlzjnbtuiqliqcpbzbmtok|rakymfuh|izqvjcmpvrokhc|'])\n",
      "('sample 2, hyp 1/2', ['|vanhegrcxaqjkbp|sdvymdhk|hgmnljyfupram|pdzjfsdmrfpnznqkexnsohtywtlupuzapfyr|uabsvxegiysjgpkc|'])\n",
      "('sample 2, hyp 2/2', ['|vanhegrsxaqjkbp|sdvymdhk|hgmnljyfupram|pdzjfsdmrfpnznqkexnsohtywtlupuzapfyr|uabsvxegiysjgpkc|'])\n",
      "('sample 3, hyp 1/2', ['|prhzqtngsefbcsyxvjyrwosowqbdzyzjihpgurxotcvfdbueq|pkdyjnxsuawi|rxguwxosk|'])\n",
      "('sample 3, hyp 2/2', ['|prhzqtngsefbcsyxvjyrwosowqbdzyzjihpgvrxotcvfdbueq|pkdyjnxsuawi|rxguwxosk|'])\n",
      "('sample 4, hyp 1/2', ['|lvigopxfntyok|yefjpxgumadukmqrasgthjxbgfqmxiewiqsnyvfey|zuduyliyzplniksrpatwo|'])\n",
      "('sample 4, hyp 2/2', ['|lvigopxfntyok|yefjpvgumadukmqrasgthjxbgfqmxiewiqsnyvfey|zuduyliyzplniksrpatwo|'])\n"
     ]
    }
   ],
   "source": [
    "ctc_beamsearch_decoder_test = ctc_decoder(\n",
    "    lexicon=None,\n",
    "    # tokens=\"/home/s1785140/rlspeller/templates/speech_recognition_CharTokens_NoLM/Tokenizer/save/tokens.txt\",\n",
    "    tokens=tokenizer.vocab,\n",
    "    nbest=2,\n",
    "    blank_token='-',\n",
    "    sil_token=\"|\",\n",
    ")\n",
    "\n",
    "predicted_ids = ctc_beamsearch_decoder_test(ctc_probs, lens)\n",
    "\n",
    "predicted_words = []\n",
    "for i, hyps in enumerate(predicted_ids):\n",
    "    for j, hyp in enumerate(hyps):\n",
    "        words = tokenizer.decode_ids(hyp.tokens.tolist()).split(\" \")\n",
    "        tup = (f\"sample {i+1}, hyp {j+1}/{len(hyps)}\", words)\n",
    "        predicted_words.append(tup)\n",
    "        print(tup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd650fd4",
   "metadata": {},
   "source": [
    "# LOAD ASR (PRETRAINED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "56bf160c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from templates.speech_recognition_CharTokens_NoLM.ASR.train import ASR\n",
    "from templates.speech_recognition_CharTokens_NoLM.ASR.train import dataio_prepare\n",
    "from torch.utils.data import DataLoader\n",
    "from speechbrain.dataio.dataloader import LoopedLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "36d8019b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/s1785140/speechbrain/templates/speech_recognition_CharTokens_NoLM/data/rirs_noises.zip exists. Skipping download\n"
     ]
    }
   ],
   "source": [
    "# Load hyperparameters file with command-line overrides\n",
    "speechbrain_hparams_file = hparams['speechbrain_hparams_file']\n",
    "with open(speechbrain_hparams_file) as f:\n",
    "    speechbrain_hparams = hyperpyyaml.load_hyperpyyaml(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "26c15de1-25d9-428e-900f-967c3af9a8ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/s1785140/speechbrain/templates/speech_recognition_CharTokens_NoLM/ASR/results/CRDNN_CHAR_LJSpeech_halved/2602/save'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speechbrain_hparams['save_folder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b4072195-fb2b-4c9a-b201-c84b7a7ae104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if on_evaluate_start() get runtime error, likely need to restart notebook kernel\n"
     ]
    }
   ],
   "source": [
    "# initialise trainer (we don't want to train, but model is tightly coupled with trainer)\n",
    "asr_brain = ASR(\n",
    "    modules=speechbrain_hparams[\"modules\"],\n",
    "    opt_class=speechbrain_hparams[\"opt_class\"],\n",
    "    hparams=speechbrain_hparams,\n",
    "    checkpointer=speechbrain_hparams[\"checkpointer\"],\n",
    ")\n",
    "\n",
    "def setup_asr_brain_for_infer(asr_brain):\n",
    "    asr_brain.on_evaluate_start(min_key=\"WER\") # We call the on_evaluate_start that will load the best model\n",
    "    asr_brain.modules.eval() # We set the model to eval mode (remove dropout etc)\n",
    "\n",
    "print(\"if on_evaluate_start() get runtime error, likely need to restart notebook kernel\")\n",
    "setup_asr_brain_for_infer(asr_brain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "909b3c39-3a03-4384-82ca-2305b3ed2272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset and dataloader for inference\n",
    "datasets = dataio_prepare(speechbrain_hparams)\n",
    "\n",
    "test_set = datasets['test']\n",
    "\n",
    "if not isinstance(test_set, DataLoader) or isinstance(test_set, LoopedLoader):\n",
    "    test_loader_kwargs=speechbrain_hparams[\"test_dataloader_opts\"]\n",
    "    test_set = asr_brain.make_dataloader(\n",
    "        test_set, stage=sb.Stage.TEST, **test_loader_kwargs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "69b4b4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ⁇ ', '', 'e', 't', 'o', 'a', 'n', 'i', 's', 'r', 'h', 'd', 'l', 'c', 'f', 'u', 'm', 'w', 'p', 'g', 'y', 'b', 'v', 'k', 'x', 'q', 'j', 'z']\n",
      "['-', '|', 'e', 't', 'o', 'a', 'n', 'i', 's', 'r', 'h', 'd', 'l', 'c', 'f', 'u', 'm', 'w', 'p', 'g', 'y', 'b', 'v', 'k', 'x', 'q', 'j', 'z']\n"
     ]
    }
   ],
   "source": [
    "# get vocab from tokenizer (needed for ctc decoding)\n",
    "vocab_size = len(asr_brain.hparams.tokenizer)\n",
    "vocab = []\n",
    "for i in range(vocab_size):\n",
    "    vocab.append(asr_brain.hparams.tokenizer.decode_ids([i]))\n",
    "print(vocab)\n",
    "\n",
    "# edit vocab to match default ctc decoder symbols for blank and silence\n",
    "vocab[0] = '-'\n",
    "vocab[1] = \"|\"\n",
    "\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6af49d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctc_beamsearch_decoder = ctc_decoder(\n",
    "    lexicon=None,\n",
    "    # tokens=\"/home/s1785140/rlspeller/templates/speech_recognition_CharTokens_NoLM/Tokenizer/save/tokens.txt\",\n",
    "    tokens=vocab,\n",
    "    nbest=100,\n",
    "    blank_token='-',\n",
    "    sil_token=\"|\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b4d6501c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                        | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG INSIDE PREPARE FEATURES, feats.shape=torch.Size([8, 627, 40]) wav_lens.shape=torch.Size([8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 1/1 [00:08<00:00,  8.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sample 1 - (LJ039-0175: 'for the first four attempts the firers missed the second shot by several inches')\n",
      "\thyp 1/48 (CER=0.0%): 'for the first four attempts the firers missed the second shot by several inches '\n",
      "\thyp 2/48 (CER=1.3%): 'for the first four attempts the firers mised the second shot by several inches '\n",
      "\thyp 3/48 (CER=1.3%): 'for the fist four attempts the firers missed the second shot by several inches '\n",
      "\thyp 4/48 (CER=1.3%): 'for the first four attempths the firers missed the second shot by several inches '\n",
      "\thyp 5/48 (CER=2.5%): 'for the first four attempts the firerers missed the second shot by several inches '\n",
      "\thyp 6/48 (CER=2.5%): 'for the fist four attempts the firers mised the second shot by several inches '\n",
      "\thyp 7/48 (CER=1.3%): 'fr the first four attempts the firers missed the second shot by several inches '\n",
      "\thyp 8/48 (CER=1.3%): 'for the first four attempts the firers  missed the second shot by several inches '\n",
      "\thyp 9/48 (CER=1.3%): 'for the first four atempts the firers missed the second shot by several inches '\n",
      "\thyp 10/48 (CER=1.3%): 'for the first four attempts the firers missed the second shot by several nches '\n",
      "\thyp 11/48 (CER=1.3%): 'for the first four attemts the firers missed the second shot by several inches '\n",
      "\thyp 12/48 (CER=2.5%): 'for the first four attempths the firers mised the second shot by several inches '\n",
      "\thyp 13/48 (CER=1.3%): 'for the first four attempts the firers misse the second shot by several inches '\n",
      "\thyp 14/48 (CER=1.3%): 'for the first four attempts the firers missed the second shot by several inchies '\n",
      "\thyp 15/48 (CER=1.3%): 'for the first four attempts the firers missed the secod shot by several inches '\n",
      "\thyp 16/48 (CER=2.5%): 'for the first four attempts the firers m missed the second shot by several inches '\n",
      "\thyp 17/48 (CER=1.3%): 'for the first four attempts the firers missed the second schot by several inches '\n",
      "\thyp 18/48 (CER=1.3%): 'for the first four attempts the firers nmissed the second shot by several inches '\n",
      "\thyp 19/48 (CER=2.5%): 'for the first four attempts the firers a missed the second shot by several inches '\n",
      "\thyp 20/48 (CER=2.5%): 'for the first four attempts the firers h missed the second shot by several inches '\n",
      "\thyp 21/48 (CER=1.3%): 'for the first four attemmpts the firers missed the second shot by several inches '\n",
      "\thyp 22/48 (CER=2.5%): 'for the first four attempts the firers n missed the second shot by several inches '\n",
      "\thyp 23/48 (CER=1.3%): 'for the first four attempts the firers missed the second shot by several inces '\n",
      "\thyp 24/48 (CER=1.3%): 'for the first four attemnpts the firers missed the second shot by several inches '\n",
      "\thyp 25/48 (CER=3.8%): 'for the first four attempts the firerers mised the second shot by several inches '\n",
      "\thyp 26/48 (CER=1.3%): 'for the first four attempts the firers missed the sepcond shot by several inches '\n",
      "\thyp 27/48 (CER=2.5%): 'fr the first four attempts the firers mised the second shot by several inches '\n",
      "\thyp 28/48 (CER=1.3%): 'for the first four attemptes the firers missed the second shot by several inches '\n",
      "\thyp 29/48 (CER=2.5%): 'for the first four attempts the firers d missed the second shot by several inches '\n",
      "\thyp 30/48 (CER=1.3%): 'for the first four attempts the firers missed the second shot by several einches '\n",
      "\thyp 31/48 (CER=2.5%): 'for the first four attempts the firers mised the second shot by several nches '\n",
      "\thyp 32/48 (CER=2.5%): 'for the first four attempts the firers missed the second shot by several incheies '\n",
      "\thyp 33/48 (CER=2.5%): 'for the first four attempts the firers mised the second shot by several inchies '\n",
      "\thyp 34/48 (CER=1.3%): 'for the first four attempts the firers missed the second shot by several inchaes '\n",
      "\thyp 35/48 (CER=1.3%): 'for the first four attempts the firers missed the second shot by several inchees '\n",
      "\thyp 36/48 (CER=1.3%): 'for the first four attempts the firers missed the second shot by several inchess '\n",
      "\thyp 37/48 (CER=1.3%): 'for the first four attempts the firers missed the second shot by several inchoes '\n",
      "\thyp 38/48 (CER=3.8%): 'for the first four attempts the firers mised the second shot by several incheies '\n",
      "\thyp 39/48 (CER=2.5%): 'for the first four attempts the firers mised the second shot by several inchess '\n",
      "\thyp 40/48 (CER=0.0%): 'for the first four attempts the firers missed the second shot by several inches '\n",
      "\thyp 41/48 (CER=1.3%): 'for the first four attempts the firers mised the second shot by several inches '\n",
      "\thyp 42/48 (CER=1.3%): 'for the first four attempts the firers missed the second shot by several inchesf '\n",
      "\thyp 43/48 (CER=2.5%): 'for the first four attempts the firers mised the second shot by several inchesf '\n",
      "\thyp 44/48 (CER=1.3%): 'for the fist four attempts the firers missed the second shot by several inches '\n",
      "\thyp 45/48 (CER=1.3%): 'for the first four attempts the firers missed the second shot by several inchesm '\n",
      "\thyp 46/48 (CER=1.3%): 'for the first four attempths the firers missed the second shot by several inches '\n",
      "\thyp 47/48 (CER=2.5%): 'for the first four attempts the firerers missed the second shot by several inches '\n",
      "\thyp 48/48 (CER=2.5%): 'for the fist four attempts the firers mised the second shot by several inches '\n",
      "\t=== Mean CER: 1.7%, Std CER: 0.8% ===\n",
      "\n",
      "sample 2 - (LJ046-0118: 'in addition to this function prs is responsible for such tasks')\n",
      "\thyp 1/49 (CER=0.0%): 'in addition to this function prs is responsible for such tasks '\n",
      "\thyp 2/49 (CER=1.6%): 'in addition to this function prss is responsible for such tasks '\n",
      "\thyp 3/49 (CER=1.6%): 'in additio to this function prs is responsible for such tasks '\n",
      "\thyp 4/49 (CER=3.2%): 'in addition to this function prs is responsible for such tas '\n",
      "\thyp 5/49 (CER=1.6%): 'in additin to this function prs is responsible for such tasks '\n",
      "\thyp 6/49 (CER=1.6%): 'in addition to this function prs is responsible for such taskts '\n",
      "\thyp 7/49 (CER=3.2%): 'in additio to this function prss is responsible for such tasks '\n",
      "\thyp 8/49 (CER=1.6%): 'in addition to this functieon prs is responsible for such tasks '\n",
      "\thyp 9/49 (CER=4.8%): 'in addition to this function prss is responsible for such tas '\n",
      "\thyp 10/49 (CER=4.8%): 'in additio to this function prs is responsible for such tas '\n",
      "\thyp 11/49 (CER=3.2%): 'in additin to this function prss is responsible for such tasks '\n",
      "\thyp 12/49 (CER=3.2%): 'in addition to this function prss is responsible for such taskts '\n",
      "\thyp 13/49 (CER=3.2%): 'in additio to this function prs is responsible for such taskts '\n",
      "\thyp 14/49 (CER=1.6%): 'in addition to this function pr is responsible for such tasks '\n",
      "\thyp 15/49 (CER=1.6%): 'in addition to this function prs is responsible fo such tasks '\n",
      "\thyp 16/49 (CER=1.6%): 'in addition to tis function prs is responsible for such tasks '\n",
      "\thyp 17/49 (CER=1.6%): 'in addition to this function prs is responsible for such tasts '\n",
      "\thyp 18/49 (CER=1.6%): 'in addition to this function prs is responsible for such taesks '\n",
      "\thyp 19/49 (CER=4.8%): 'in additin to this function prs is responsible for such tas '\n",
      "\thyp 20/49 (CER=1.6%): 'in addition to this function prs is responsible for such teasks '\n",
      "\thyp 21/49 (CER=3.2%): 'in addition to this functieon prss is responsible for such tasks '\n",
      "\thyp 22/49 (CER=3.2%): 'in additio to this functieon prs is responsible for such tasks '\n",
      "\thyp 23/49 (CER=1.6%): 'in addition to this function prs is responsible for such tastks '\n",
      "\thyp 24/49 (CER=6.5%): 'in additio to this function prss is responsible for such tas '\n",
      "\thyp 25/49 (CER=1.6%): 'in additioan to this function prs is responsible for such tasks '\n",
      "\thyp 26/49 (CER=3.2%): 'in additin to this function prs is responsible for such taskts '\n",
      "\thyp 27/49 (CER=4.8%): 'in addition to this functieon prs is responsible for such tas '\n",
      "\thyp 28/49 (CER=1.6%): 'in addition to this function prs is responsible for such tass '\n",
      "\thyp 29/49 (CER=1.6%): 'in addition to this function prs is responsibe for such tasks '\n",
      "\thyp 30/49 (CER=1.6%): 'in addition to this function prs is responsible for such taskss '\n",
      "\thyp 31/49 (CER=1.6%): 'in addition to this function prs is responsible for such taskst '\n",
      "\thyp 32/49 (CER=3.2%): 'in addition to this function prss is responsible for such taskss '\n",
      "\thyp 33/49 (CER=3.2%): 'in additio to this function prs is responsible for such taskss '\n",
      "\thyp 34/49 (CER=3.2%): 'in additin to this function prs is responsible for such taskss '\n",
      "\thyp 35/49 (CER=3.2%): 'in addition to this function prs is responsible for such tasktss '\n",
      "\thyp 36/49 (CER=3.2%): 'in addition to this function prss is responsible for such taskst '\n",
      "\thyp 37/49 (CER=3.2%): 'in additio to this function prs is responsible for such taskst '\n",
      "\thyp 38/49 (CER=4.8%): 'in additio to this function prss is responsible for such taskss '\n",
      "\thyp 39/49 (CER=3.2%): 'in addition to this functieon prs is responsible for such taskss '\n",
      "\thyp 40/49 (CER=3.2%): 'in addition to this function prs is responsible for such tast '\n",
      "\thyp 41/49 (CER=3.2%): 'in addition to this function prss is responsible for such tass '\n",
      "\thyp 42/49 (CER=3.2%): 'in additio to this function prs is responsible for such tass '\n",
      "\thyp 43/49 (CER=3.2%): 'in additin to this function prs is responsible for such taskst '\n",
      "\thyp 44/49 (CER=4.8%): 'in additin to this function prss is responsible for such taskss '\n",
      "\thyp 45/49 (CER=1.6%): 'in addition to this function prs is responsible for such tasksn '\n",
      "\thyp 46/49 (CER=3.2%): 'in addition to this function prs is responsible for such tasktst '\n",
      "\thyp 47/49 (CER=4.8%): 'in addition to this function prss is responsible for such tasktss '\n",
      "\thyp 48/49 (CER=4.8%): 'in additio to this function prs is responsible for such tasktss '\n",
      "\thyp 49/49 (CER=4.8%): 'in additio to this function prss is responsible for such taskst '\n",
      "\t=== Mean CER: 2.9%, Std CER: 1.3% ===\n",
      "\n",
      "sample 3 - (LJ049-0095: 'for all offenses within its jurisdiction as are fbi agents and federal marshals')\n",
      "\thyp 1/50 (CER=1.3%): 'for all offenses within its jurisdiction as are fbi agents and federal marfhals '\n",
      "\thyp 2/50 (CER=2.5%): 'for all ofenses within its jurisdiction as are fbi agents and federal marfhals '\n",
      "\thyp 3/50 (CER=2.5%): 'for all offences within its jurisdiction as are fbi agents and federal marfhals '\n",
      "\thyp 4/50 (CER=1.3%): 'for all offenses within its jurisdiction as are fbi agents and federal marhals '\n",
      "\thyp 5/50 (CER=2.5%): 'for all offenses within its jurisdiction as are fbi agents and federal martfhals '\n",
      "\thyp 6/50 (CER=1.3%): 'for all offenses within its jurisdiction as are fbi agents and federal marsfhals '\n",
      "\thyp 7/50 (CER=3.8%): 'for all ofences within its jurisdiction as are fbi agents and federal marfhals '\n",
      "\thyp 8/50 (CER=2.5%): 'for all ofenses within its jurisdiction as are fbi agents and federal marhals '\n",
      "\thyp 9/50 (CER=3.8%): 'for all ofenses within its jurisdiction as are fbi agents and federal martfhals '\n",
      "\thyp 10/50 (CER=2.5%): 'for all offences within its jurisdiction as are fbi agents and federal marhals '\n",
      "\thyp 11/50 (CER=2.5%): 'for all offenses within its jurisdition as are fbi agents and federal marfhals '\n",
      "\thyp 12/50 (CER=3.8%): 'for all offences within its jurisdiction as are fbi agents and federal martfhals '\n",
      "\thyp 13/50 (CER=1.3%): 'for all offenses within its jurisdiction as are fbi agents and federal marthals '\n",
      "\thyp 14/50 (CER=2.5%): 'for all offencses within its jurisdiction as are fbi agents and federal marfhals '\n",
      "\thyp 15/50 (CER=2.5%): 'for all ofenses within its jurisdiction as are fbi agents and federal marsfhals '\n",
      "\thyp 16/50 (CER=1.3%): 'for all offenses within its jurisdiction as are fbi agents and federal marchals '\n",
      "\thyp 17/50 (CER=2.5%): 'for all offenses with in its jurisdiction as are fbi agents and federal marfhals '\n",
      "\thyp 18/50 (CER=2.5%): 'for all offences within its jurisdiction as are fbi agents and federal marsfhals '\n",
      "\thyp 19/50 (CER=0.0%): 'for all offenses within its jurisdiction as are fbi agents and federal marshals '\n",
      "\thyp 20/50 (CER=3.8%): 'for all ofences within its jurisdiction as are fbi agents and federal marhals '\n",
      "\thyp 21/50 (CER=2.5%): 'for all offenses within its jurisdiction as are fbi agents and federal marfials '\n",
      "\thyp 22/50 (CER=2.5%): 'for all offenses within its jurisdicion as are fbi agents and federal marfhals '\n",
      "\thyp 23/50 (CER=3.8%): 'for all ofenses within its jurisdition as are fbi agents and federal marfhals '\n",
      "\thyp 24/50 (CER=2.5%): 'for al offenses within its jurisdiction as are fbi agents and federal marfhals '\n",
      "\thyp 25/50 (CER=5.1%): 'for all ofences within its jurisdiction as are fbi agents and federal martfhals '\n",
      "\thyp 26/50 (CER=2.5%): 'for all ofenses within its jurisdiction as are fbi agents and federal marthals '\n",
      "\thyp 27/50 (CER=3.8%): 'for all ofencses within its jurisdiction as are fbi agents and federal marfhals '\n",
      "\thyp 28/50 (CER=3.8%): 'for all offences within its jurisdition as are fbi agents and federal marfhals '\n",
      "\thyp 29/50 (CER=2.5%): 'for all offenses within its jurisdition as are fbi agents and federal marhals '\n",
      "\thyp 30/50 (CER=2.5%): 'for all offences within its jurisdiction as are fbi agents and federal marthals '\n",
      "\thyp 31/50 (CER=2.5%): 'for all offenses within its jurisdiction as are fbi agents and federal marcfhals '\n",
      "\thyp 32/50 (CER=2.5%): 'for all offencses within its jurisdiction as are fbi agents and federal marhals '\n",
      "\thyp 33/50 (CER=2.5%): 'for all ofenses within its jurisdiction as are fbi agents and federal marchals '\n",
      "\thyp 34/50 (CER=3.8%): 'for all offenses within its jurisdition as are fbi agents and federal martfhals '\n",
      "\thyp 35/50 (CER=2.5%): 'for all offenses within its jurisdiction as are fbi agents and federal marfhalss '\n",
      "\thyp 36/50 (CER=3.8%): 'for all ofenses within its jurisdiction as are fbi agents and federal marfhalss '\n",
      "\thyp 37/50 (CER=2.5%): 'for all offenses within its jurisdiction as are fbi agents and federal marfhalst '\n",
      "\thyp 38/50 (CER=3.8%): 'for all offences within its jurisdiction as are fbi agents and federal marfhalss '\n",
      "\thyp 39/50 (CER=2.5%): 'for all offenses within its jurisdiction as are fbi agents and federal marhalss '\n",
      "\thyp 40/50 (CER=3.8%): 'for all offenses within its jurisdiction as are fbi agents and federal martfhalss '\n",
      "\thyp 41/50 (CER=2.5%): 'for all offenses within its jurisdiction as are fbi agents and federal marsfhalss '\n",
      "\thyp 42/50 (CER=3.8%): 'for all ofenses within its jurisdiction as are fbi agents and federal marfhalst '\n",
      "\thyp 43/50 (CER=5.1%): 'for all ofences within its jurisdiction as are fbi agents and federal marfhalss '\n",
      "\thyp 44/50 (CER=3.8%): 'for all ofenses within its jurisdiction as are fbi agents and federal marhalss '\n",
      "\thyp 45/50 (CER=2.5%): 'for all offenses within its jurisdiction as are fbi agents and federal marfhalsc '\n",
      "\thyp 46/50 (CER=5.1%): 'for all ofenses within its jurisdiction as are fbi agents and federal martfhalss '\n",
      "\thyp 47/50 (CER=3.8%): 'for all offences within its jurisdiction as are fbi agents and federal marfhalst '\n",
      "\thyp 48/50 (CER=2.5%): 'for all offenses within its jurisdiction as are fbi agents and federal marhalst '\n",
      "\thyp 49/50 (CER=3.8%): 'for all offences within its jurisdiction as are fbi agents and federal marhalss '\n",
      "\thyp 50/50 (CER=3.8%): 'for all offenses within its jurisdition as are fbi agents and federal marfhalss '\n",
      "\t=== Mean CER: 2.9%, Std CER: 1.0% ===\n",
      "\n",
      "sample 4 - (LJ042-0234: 'quote except in the us the living standard is a little higher')\n",
      "\thyp 1/50 (CER=3.3%): 'quote except in the u s the living standard is a lidtle higher '\n",
      "\thyp 2/50 (CER=4.9%): 'quote except in the u s the living standard is a lidtle highere '\n",
      "\thyp 3/50 (CER=4.9%): 'quote except in the u s the living standard is a lidle higher '\n",
      "\thyp 4/50 (CER=6.6%): 'quote except in the u s the living standard is a lidle highere '\n",
      "\thyp 5/50 (CER=1.6%): 'quote except in the u s the living standard is a little higher '\n",
      "\thyp 6/50 (CER=3.3%): 'quote except in the u s the living standard is a little highere '\n",
      "\thyp 7/50 (CER=4.9%): 'quote except in the u s the living standard is a lidtle highr '\n",
      "\thyp 8/50 (CER=6.6%): 'quote except in the u s the living standard is a lidtle highre '\n",
      "\thyp 9/50 (CER=3.3%): 'quote except in the u s the living standard is a litle higher '\n",
      "\thyp 10/50 (CER=4.9%): 'quote except in the u s the living standard is a litle highere '\n",
      "\thyp 11/50 (CER=4.9%): 'quote except in the u s the living standard is a lidtle highe '\n",
      "\thyp 12/50 (CER=6.6%): 'quote except in the u s the living standard is a lidle highr '\n",
      "\thyp 13/50 (CER=8.2%): 'quote except in the u s the living standard is a lidle highre '\n",
      "\thyp 14/50 (CER=4.9%): 'quote except in the u s the living standard is a lidtl higher '\n",
      "\thyp 15/50 (CER=6.6%): 'quote except in the u s the living standard is a lidtl highere '\n",
      "\thyp 16/50 (CER=6.6%): 'quote except in the u s the living standard is a lidle highe '\n",
      "\thyp 17/50 (CER=3.3%): 'quote except in the u s the living standard is a little highr '\n",
      "\thyp 18/50 (CER=4.9%): 'quote except in the u s the living standard is a little highre '\n",
      "\thyp 19/50 (CER=6.6%): 'quote except in the u s the living standard is a lidl higher '\n",
      "\thyp 20/50 (CER=3.3%): 'quote except in the u s the living standard is a little highe '\n",
      "\thyp 21/50 (CER=8.2%): 'quote except in the u s the living standard is a lidl highere '\n",
      "\thyp 22/50 (CER=4.9%): 'quote except in the u s the living standard is a litle highr '\n",
      "\thyp 23/50 (CER=6.6%): 'quote except in the u s the living standard is a litle highre '\n",
      "\thyp 24/50 (CER=4.9%): 'quote except in the u s the living standard is a lidtle highrer '\n",
      "\thyp 25/50 (CER=3.3%): 'quote except in the u s the living standard is a littl higher '\n",
      "\thyp 26/50 (CER=4.9%): 'quote except in the u s the living standard is a littl highere '\n",
      "\thyp 27/50 (CER=4.9%): 'quote except in the u s the living standard is a litle highe '\n",
      "\thyp 28/50 (CER=6.6%): 'quote except in the u s the living standard is a lidtl highr '\n",
      "\thyp 29/50 (CER=6.6%): 'quote except in the u s the living standard is a lidle highrer '\n",
      "\thyp 30/50 (CER=8.2%): 'quote except in the u s the living standard is a lidtl highre '\n",
      "\thyp 31/50 (CER=4.9%): 'quote except in the u s the living standard is a litl higher '\n",
      "\thyp 32/50 (CER=6.6%): 'quote except in the u s the living standard is a litl highere '\n",
      "\thyp 33/50 (CER=6.6%): 'quote except in the u s the living standard is a lidtl highe '\n",
      "\thyp 34/50 (CER=3.3%): 'quote except in the u s the living standard is a little highrer '\n",
      "\thyp 35/50 (CER=8.2%): 'quote except in the u s the living standard is a lidl highr '\n",
      "\thyp 36/50 (CER=9.8%): 'quote except in the u s the living standard is a lidl highre '\n",
      "\thyp 37/50 (CER=8.2%): 'quote except in the u s the living standard is a lidl highe '\n",
      "\thyp 38/50 (CER=4.9%): 'quote except in the u s the living standard is a littl highr '\n",
      "\thyp 39/50 (CER=4.9%): 'quote except in the u s the living standard is a litle highrer '\n",
      "\thyp 40/50 (CER=6.6%): 'quote except in the u s the living standard is a littl highre '\n",
      "\thyp 41/50 (CER=4.9%): 'quote except in the u s the living standard is a littl highe '\n",
      "\thyp 42/50 (CER=6.6%): 'quote except in the u s the living standard is a litl highr '\n",
      "\thyp 43/50 (CER=8.2%): 'quote except in the u s the living standard is a litl highre '\n",
      "\thyp 44/50 (CER=6.6%): 'quote except in the u s the living standard is a lidtl highrer '\n",
      "\thyp 45/50 (CER=4.9%): 'quote except in the u s the livng standard is a lidtle higher '\n",
      "\thyp 46/50 (CER=6.6%): 'quote except in the u s the livng standard is a lidtle highere '\n",
      "\thyp 47/50 (CER=3.3%): 'quote except in the u s the living standard is a litdtle higher '\n",
      "\thyp 48/50 (CER=4.9%): 'quote except in the u s the living standard is a litdtle highere '\n",
      "\thyp 49/50 (CER=6.6%): 'quote except in the u s the living standard is a litl highe '\n",
      "\thyp 50/50 (CER=8.2%): 'quote except in the u s the living standard is a lidl highrer '\n",
      "\t=== Mean CER: 5.7%, Std CER: 1.7% ===\n",
      "\n",
      "sample 5 - (LJ014-0003: 'the cries of his victim a mister delarue')\n",
      "\thyp 1/31 (CER=0.0%): 'the cries of his victim a mister delarue '\n",
      "\thyp 2/31 (CER=2.5%): 'the cries of his victim a mister dellarue '\n",
      "\thyp 3/31 (CER=2.5%): 'the cries of his victim a mister delaru '\n",
      "\thyp 4/31 (CER=2.5%): 'the crie of his victim a mister delarue '\n",
      "\thyp 5/31 (CER=2.5%): 'the cries of his victim a mister delaruee '\n",
      "\thyp 6/31 (CER=2.5%): 'the cries of his victim a mister delaroe '\n",
      "\thyp 7/31 (CER=2.5%): 'the cries of his victim a mister delalrue '\n",
      "\thyp 8/31 (CER=2.5%): 'the cries of his victim a mister dela rue '\n",
      "\thyp 9/31 (CER=2.5%): 'the cries of his vict im a mister delarue '\n",
      "\thyp 10/31 (CER=2.5%): 'the cries of his victdim a mister delarue '\n",
      "\thyp 11/31 (CER=2.5%): 'the cries of his victim a mister delaroue '\n",
      "\thyp 12/31 (CER=2.5%): 'the cries of his victim a mister delaree '\n",
      "\thyp 13/31 (CER=2.5%): 'the cries of his victhim a mister delarue '\n",
      "\thyp 14/31 (CER=2.5%): 'the cries of his victim a mister delaruoe '\n",
      "\thyp 15/31 (CER=2.5%): 'the cries of his victim a mister delaruue '\n",
      "\thyp 16/31 (CER=2.5%): 'the cries of his victim a mister delare '\n",
      "\thyp 17/31 (CER=5.0%): 'the cries of his victim a mister dellaru '\n",
      "\thyp 18/31 (CER=2.5%): 'the cries of his victim a mister delaruwe '\n",
      "\thyp 19/31 (CER=2.5%): 'the cries of his victim a mister delawrue '\n",
      "\thyp 20/31 (CER=5.0%): 'the crie of his victim a mister dellarue '\n",
      "\thyp 21/31 (CER=5.0%): 'the crie of his victim a mister delaru '\n",
      "\thyp 22/31 (CER=2.5%): 'the cries of his victim a mister delearue '\n",
      "\thyp 23/31 (CER=2.5%): 'the cries of his victim ea mister delarue '\n",
      "\thyp 24/31 (CER=2.5%): 'the cries of his victim a mister delarrue '\n",
      "\thyp 25/31 (CER=5.0%): 'the cries of his victim a mister delelarue '\n",
      "\thyp 26/31 (CER=5.0%): 'the cries of his victim a mister dellaruee '\n",
      "\thyp 27/31 (CER=2.5%): 'the cries of his victim ia mister delarue '\n",
      "\thyp 28/31 (CER=0.0%): 'the cries of his victim a mister delarue '\n",
      "\thyp 29/31 (CER=2.5%): 'the cries of his victim a mister delareue '\n",
      "\thyp 30/31 (CER=5.0%): 'the crie of his victim a mister delaruee '\n",
      "\thyp 31/31 (CER=2.5%): 'the crises of his victim a mister delarue '\n",
      "\t=== Mean CER: 2.8%, Std CER: 1.2% ===\n",
      "\n",
      "sample 6 - (LJ009-0005: 'which persons under sentence of death obtain from all the officers of the prison')\n",
      "\thyp 1/48 (CER=1.2%): 'which persons under sentence of death obtain from allthe officers of the prison '\n",
      "\thyp 2/48 (CER=0.0%): 'which persons under sentence of death obtain from all the officers of the prison '\n",
      "\thyp 3/48 (CER=2.5%): 'which persons under sentence of death obtain from althe officers of the prison '\n",
      "\thyp 4/48 (CER=1.2%): 'which persons under sentence of death obtain from al the officers of the prison '\n",
      "\thyp 5/48 (CER=2.5%): 'which persons under sentence of death obtain from allte officers of the prison '\n",
      "\thyp 6/48 (CER=1.2%): 'which persons under sentence of death obtain from all he officers of the prison '\n",
      "\thyp 7/48 (CER=1.2%): 'which persons under sentence of death obtain from all te officers of the prison '\n",
      "\thyp 8/48 (CER=3.8%): 'which persons under sentence of death obtain from alte officers of the prison '\n",
      "\thyp 9/48 (CER=2.5%): 'which persons under sentence of death obtaine from allthe officers of the prison '\n",
      "\thyp 10/48 (CER=2.5%): 'which persons under sentence of death obtain from allth officers of the prison '\n",
      "\thyp 11/48 (CER=2.5%): 'which persons under sentence of death btain from allthe officers of the prison '\n",
      "\thyp 12/48 (CER=2.5%): 'which persons under sentence of deatht obtain from allthe officers of the prison '\n",
      "\thyp 13/48 (CER=2.5%): 'which persons under sentence of death obtain from al he officers of the prison '\n",
      "\thyp 14/48 (CER=2.5%): 'which persons under sentence of death obtain from al te officers of the prison '\n",
      "\thyp 15/48 (CER=1.2%): 'which persons under sentence of death obtaine from all the officers of the prison '\n",
      "\thyp 16/48 (CER=1.2%): 'which persons under sentence of death obtain from all th officers of the prison '\n",
      "\thyp 17/48 (CER=2.5%): 'which persons under sentence of death obtains from allthe officers of the prison '\n",
      "\thyp 18/48 (CER=1.2%): 'which persons under sentence of death btain from all the officers of the prison '\n",
      "\thyp 19/48 (CER=1.2%): 'which persons under sentence of deatht obtain from all the officers of the prison '\n",
      "\thyp 20/48 (CER=3.8%): 'which persons under sentence of death obtaine from althe officers of the prison '\n",
      "\thyp 21/48 (CER=3.8%): 'which persons under sentence of death obtain from alth officers of the prison '\n",
      "\thyp 22/48 (CER=3.8%): 'which persons under sentence of death btain from althe officers of the prison '\n",
      "\thyp 23/48 (CER=3.8%): 'which persons under sentence of deatht obtain from althe officers of the prison '\n",
      "\thyp 24/48 (CER=1.2%): 'which persons under sentence of death obtains from all the officers of the prison '\n",
      "\thyp 25/48 (CER=3.8%): 'which persons under sentence of death obtainen from allthe officers of the prison '\n",
      "\thyp 26/48 (CER=2.5%): 'which persons under sentence of death obtain from allthe officers of the prisons '\n",
      "\thyp 27/48 (CER=1.2%): 'which persons under sentence of death obtain from all the officers of the prisons '\n",
      "\thyp 28/48 (CER=2.5%): 'which persons under sentence of death obtain from allthe officers of the prisonr '\n",
      "\thyp 29/48 (CER=1.2%): 'which persons under sentence of death obtain from all the officers of the prisonr '\n",
      "\thyp 30/48 (CER=3.8%): 'which persons under sentence of death obtain from althe officers of the prisonr '\n",
      "\thyp 31/48 (CER=2.5%): 'which persons under sentence of death obtain from allthe officers of the prisonn '\n",
      "\thyp 32/48 (CER=2.5%): 'which persons under sentence of death obtain from al the officers of the prisonr '\n",
      "\thyp 33/48 (CER=3.8%): 'which persons under sentence of death obtain from allte officers of the prisonr '\n",
      "\thyp 34/48 (CER=1.2%): 'which persons under sentence of death obtain from all the officers of the prisonn '\n",
      "\thyp 35/48 (CER=3.8%): 'which persons under sentence of death obtain from althe officers of the prisons '\n",
      "\thyp 36/48 (CER=3.8%): 'which persons under sentence of death obtain from althe officers of the prisonn '\n",
      "\thyp 37/48 (CER=2.5%): 'which persons under sentence of death obtain from allthe officers of the prisond '\n",
      "\thyp 38/48 (CER=2.5%): 'which persons under sentence of death obtain from all he officers of the prisonr '\n",
      "\thyp 39/48 (CER=1.2%): 'which persons under sentence of death obtain from allthe officers of the prison '\n",
      "\thyp 40/48 (CER=2.5%): 'which persons under sentence of death obtain from all te officers of the prisonr '\n",
      "\thyp 41/48 (CER=2.5%): 'which persons under sentence of death obtain from al the officers of the prisons '\n",
      "\thyp 42/48 (CER=5.0%): 'which persons under sentence of death obtain from alte officers of the prisonr '\n",
      "\thyp 43/48 (CER=2.5%): 'which persons under sentence of death obtain from al the officers of the prisonn '\n",
      "\thyp 44/48 (CER=3.8%): 'which persons under sentence of death obtain from allte officers of the prisons '\n",
      "\thyp 45/48 (CER=3.8%): 'which persons under sentence of death obtaine from allthe officers of the prisonr '\n",
      "\thyp 46/48 (CER=3.8%): 'which persons under sentence of death obtain from allth officers of the prisonr '\n",
      "\thyp 47/48 (CER=3.8%): 'which persons under sentence of death obtain from allte officers of the prisonn '\n",
      "\thyp 48/48 (CER=1.2%): 'which persons under sentence of death obtain from all the officers of the prisond '\n",
      "\t=== Mean CER: 2.5%, Std CER: 1.1% ===\n",
      "\n",
      "sample 7 - (LJ014-0140: 'after judgment was passed she repeatedly cried out shame')\n",
      "\thyp 1/41 (CER=0.0%): 'after judgment was passed she repeatedly cried out shame '\n",
      "\thyp 2/41 (CER=1.8%): 'after judgment was passed she wrepeatedly cried out shame '\n",
      "\thyp 3/41 (CER=1.8%): 'after judgment was passed she repeatedly cried out shaime '\n",
      "\thyp 4/41 (CER=1.8%): 'after judgmant was passed she repeatedly cried out shame '\n",
      "\thyp 5/41 (CER=1.8%): 'after judgment was passed she repeatedly cried out shamme '\n",
      "\thyp 6/41 (CER=1.8%): 'after judgment was passed she repeatedly cried out shanme '\n",
      "\thyp 7/41 (CER=1.8%): 'after judgment was passed she repeatedly cried out sham '\n",
      "\thyp 8/41 (CER=1.8%): 'after judgment was passed she repeatedly cried out shamne '\n",
      "\thyp 9/41 (CER=3.6%): 'after judgment was passed she wrepeatedly cried out shaime '\n",
      "\thyp 10/41 (CER=1.8%): 'after judgment was pased she repeatedly cried out shame '\n",
      "\thyp 11/41 (CER=1.8%): 'after judgment was passed she repeatedly cried out shaame '\n",
      "\thyp 12/41 (CER=1.8%): 'after judgment was passed she repetedly cried out shame '\n",
      "\thyp 13/41 (CER=1.8%): 'after judgment was passed she repeatedly cried out schame '\n",
      "\thyp 14/41 (CER=1.8%): 'after judgment was passed she repeated ly cried out shame '\n",
      "\thyp 15/41 (CER=1.8%): 'after judgment was passed she repeatedly cried out shavme '\n",
      "\thyp 16/41 (CER=1.8%): 'after judgment was passed she repeatedly crid out shame '\n",
      "\thyp 17/41 (CER=1.8%): 'after judgment was passed she repeatedly cried out shamee '\n",
      "\thyp 18/41 (CER=1.8%): 'after judgment was passsed she repeatedly cried out shame '\n",
      "\thyp 19/41 (CER=1.8%): 'after joudgment was passed she repeatedly cried out shame '\n",
      "\thyp 20/41 (CER=1.8%): 'after judgment was passed she repeatedly crided out shame '\n",
      "\thyp 21/41 (CER=3.6%): 'after judgmant was passed she wrepeatedly cried out shame '\n",
      "\thyp 22/41 (CER=1.8%): 'after judgment was passed she repatedly cried out shame '\n",
      "\thyp 23/41 (CER=1.8%): 'after judgmeant was passed she repeatedly cried out shame '\n",
      "\thyp 24/41 (CER=3.6%): 'after judgment was passed she wrepeatedly cried out shamme '\n",
      "\thyp 25/41 (CER=1.8%): 'after judgment was passd she repeatedly cried out shame '\n",
      "\thyp 26/41 (CER=3.6%): 'after judgmant was passed she repeatedly cried out shaime '\n",
      "\thyp 27/41 (CER=1.8%): 'after judment was passed she repeatedly cried out shame '\n",
      "\thyp 28/41 (CER=1.8%): 'aftr judgment was passed she repeatedly cried out shame '\n",
      "\thyp 29/41 (CER=3.6%): 'after judgment was passed she repeatedly cried out shamnme '\n",
      "\thyp 30/41 (CER=0.0%): 'after judgment was passed she repeatedly cried out shame '\n",
      "\thyp 31/41 (CER=1.8%): 'after judgment was passed she repeatedly cried out shamed '\n",
      "\thyp 32/41 (CER=3.6%): 'after judgment was passed she wrepeatedly cried out shamee '\n",
      "\thyp 33/41 (CER=3.6%): 'after judgment was passed she repeatedly cried out shaimee '\n",
      "\thyp 34/41 (CER=1.8%): 'after judgment was passed she wrepeatedly cried out shame '\n",
      "\thyp 35/41 (CER=3.6%): 'after judgmant was passed she repeatedly cried out shamee '\n",
      "\thyp 36/41 (CER=3.6%): 'after judgment was passed she wrepeatedly cried out shamed '\n",
      "\thyp 37/41 (CER=3.6%): 'after judgment was passed she repeatedly cried out shammee '\n",
      "\thyp 38/41 (CER=1.8%): 'after judgment was passed she repeatedly cried out shaime '\n",
      "\thyp 39/41 (CER=3.6%): 'after judgment was passed she repeatedly cried out shaimed '\n",
      "\thyp 40/41 (CER=1.8%): 'after judgment was passed she repeatedly cried out shamen '\n",
      "\thyp 41/41 (CER=3.6%): 'after judgment was passed she repeatedly cried out shanmee '\n",
      "\t=== Mean CER: 2.2%, Std CER: 0.9% ===\n",
      "\n",
      "sample 8 - (LJ050-0017: 'to be able to provide effective continuing supervision')\n",
      "\thyp 1/47 (CER=0.0%): 'to be able to provide effective continuing supervision '\n",
      "\thyp 2/47 (CER=1.9%): 'to be able to provide affective continuing supervision '\n",
      "\thyp 3/47 (CER=1.9%): 'to be able to provide effective continuing upervision '\n",
      "\thyp 4/47 (CER=3.7%): 'to be able to provide affective continuing upervision '\n",
      "\thyp 5/47 (CER=1.9%): 'to behable to provide effective continuing supervision '\n",
      "\thyp 6/47 (CER=1.9%): 'to be able to provide e fective continuing supervision '\n",
      "\thyp 7/47 (CER=1.9%): 'to be able to provide effective continuing superbvision '\n",
      "\thyp 8/47 (CER=1.9%): 't be able to provide effective continuing supervision '\n",
      "\thyp 9/47 (CER=1.9%): 'to be able to provide offective continuing supervision '\n",
      "\thyp 10/47 (CER=1.9%): 'to be apble to provide effective continuing supervision '\n",
      "\thyp 11/47 (CER=3.7%): 'to behable to provide affective continuing supervision '\n",
      "\thyp 12/47 (CER=1.9%): 'to be avble to provide effective continuing supervision '\n",
      "\thyp 13/47 (CER=1.9%): 'to be able to provide efective continuing supervision '\n",
      "\thyp 14/47 (CER=1.9%): 'to be amble to provide effective continuing supervision '\n",
      "\thyp 15/47 (CER=1.9%): 'to be ablel to provide effective continuing supervision '\n",
      "\thyp 16/47 (CER=3.7%): 'to behable to provide effective continuing upervision '\n",
      "\thyp 17/47 (CER=1.9%): 'to be eble to provide effective continuing supervision '\n",
      "\thyp 18/47 (CER=3.7%): 'to be able to provide a fective continuing supervision '\n",
      "\thyp 19/47 (CER=1.9%): 'to be able to provide effective continuing supervbision '\n",
      "\thyp 20/47 (CER=1.9%): 'to be abe to provide effective continuing supervision '\n",
      "\thyp 21/47 (CER=1.9%): 'to be able to provide effective coninuing supervision '\n",
      "\thyp 22/47 (CER=3.7%): 'to be able to provide affective continuing superbvision '\n",
      "\thyp 23/47 (CER=1.9%): 'to b able to provide effective continuing supervision '\n",
      "\thyp 24/47 (CER=3.7%): 't be able to provide affective continuing supervision '\n",
      "\thyp 25/47 (CER=1.9%): 'to beable to provide effective continuing supervision '\n",
      "\thyp 26/47 (CER=1.9%): 'to be abple to provide effective continuing supervision '\n",
      "\thyp 27/47 (CER=0.0%): 'to be able to provide effective continuing supervision '\n",
      "\thyp 28/47 (CER=1.9%): 'to be able to provide affective continuing supervision '\n",
      "\thyp 29/47 (CER=1.9%): 'to be able to provide effective continuing upervision '\n",
      "\thyp 30/47 (CER=3.7%): 'to be able to provide affective continuing upervision '\n",
      "\thyp 31/47 (CER=1.9%): 'to behable to provide effective continuing supervision '\n",
      "\thyp 32/47 (CER=1.9%): 'to be able to provide effective continuing supervisionn '\n",
      "\thyp 33/47 (CER=1.9%): 'to be able to provide e fective continuing supervision '\n",
      "\thyp 34/47 (CER=1.9%): 'to be able to provide effective continuing superbvision '\n",
      "\thyp 35/47 (CER=1.9%): 't be able to provide effective continuing supervision '\n",
      "\thyp 36/47 (CER=1.9%): 'to be able to provide effective continuing supervisionh '\n",
      "\thyp 37/47 (CER=1.9%): 'to be able to provide offective continuing supervision '\n",
      "\thyp 38/47 (CER=1.9%): 'to be able to provide effective continuing supervisionr '\n",
      "\thyp 39/47 (CER=1.9%): 'to be apble to provide effective continuing supervision '\n",
      "\thyp 40/47 (CER=3.7%): 'to behable to provide affective continuing supervision '\n",
      "\thyp 41/47 (CER=1.9%): 'to be avble to provide effective continuing supervision '\n",
      "\thyp 42/47 (CER=3.7%): 'to be able to provide affective continuing supervisionn '\n",
      "\thyp 43/47 (CER=1.9%): 'to be able to provide efective continuing supervision '\n",
      "\thyp 44/47 (CER=1.9%): 'to be amble to provide effective continuing supervision '\n",
      "\thyp 45/47 (CER=1.9%): 'to be able to provide effective continuing supervisiong '\n",
      "\thyp 46/47 (CER=1.9%): 'to be able to provide effective continuing supervisions '\n",
      "\thyp 47/47 (CER=1.9%): 'to be ablel to provide effective continuing supervision '\n",
      "\t=== Mean CER: 2.1%, Std CER: 0.9% ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# generate transcriptions for all batches in test set\n",
    "def transcribe_dataset(asr_brain, dataset, greedy=False, num_batches_to_transcribe=None):\n",
    "    # Now we iterate over the dataset and we simply compute_forward and decode\n",
    "    with torch.no_grad():\n",
    "        transcripts = []\n",
    "        for batch in tqdm(list(dataset)[:num_batches_to_transcribe], dynamic_ncols=True):\n",
    "            orig_transcriptions = batch.words\n",
    "\n",
    "            # Make sure that your compute_forward returns the predictions !!!\n",
    "            # In the case of the template, when stage = TEST, a beam search is applied \n",
    "            # in compute_forward(). \n",
    "            predictions = asr_brain.compute_forward(batch, stage=sb.Stage.TEST)\n",
    "            \n",
    "            ctc_probs = predictions['ctc_logprobs'] # FOR DEBUG\n",
    "\n",
    "            if greedy:\n",
    "                predicted_ids = sb.decoders.ctc_greedy_decode(\n",
    "                    predictions[\"ctc_logprobs\"], asr_brain.feat_lens, blank_id=asr_brain.hparams.blank_index\n",
    "                )\n",
    "                predicted_words = [\n",
    "                    asr_brain.tokenizer.decode_ids(ids).split(\" \")\n",
    "                    for ids in predicted_ids\n",
    "                ]\n",
    "            else:\n",
    "                # get mel lens from wav len ratios since torch ctc decoder requires lens in frames\n",
    "                batch_max_len = predictions[\"ctc_logprobs\"].size(1)\n",
    "                bsz = predictions[\"ctc_logprobs\"].size(0)\n",
    "                mel_lens = torch.zeros(bsz)\n",
    "                for i, len_ratio in enumerate(asr_brain.feat_lens):\n",
    "                    mel_lens[i] = int(torch.round(len_ratio * batch_max_len))\n",
    "                \n",
    "                predicted_ids = ctc_beamsearch_decoder(\n",
    "                    predictions[\"ctc_logprobs\"], lengths=mel_lens\n",
    "                )\n",
    "\n",
    "                predicted_words = []\n",
    "                for i, (utt_id, orig_text, hyps) in enumerate(zip(batch.utt_id, orig_transcriptions, predicted_ids)):\n",
    "                    print(f\"\\nsample {i+1} - ({utt_id}: '{orig_text}')\")\n",
    "                    sample_cers = []\n",
    "                    for j, hyp in enumerate(hyps):\n",
    "                        words = asr_brain.hparams.tokenizer.decode_ids(hyp.tokens.tolist()) # .split(\"|\")\n",
    "                        # words = tokenizer.decode_ids(hyp.tokens.tolist()) # .split(\"|\")\n",
    "                        hyp_cer = 100 * cer(orig_text, words)\n",
    "                        sample_cers.append(hyp_cer)\n",
    "                        print(f\"\\thyp {j+1}/{len(hyps)} (CER={hyp_cer:.1f}%): '{words}'\")\n",
    "                        predicted_words.append((f\"sample {i+1}, hyp {j+1}/{len(hyps)}\", words))\n",
    "                        \n",
    "                    print(f\"\\t=== Mean CER: {np.mean(sample_cers):.1f}%, Std CER: {np.std(sample_cers):.1f}% ===\")\n",
    "\n",
    "            transcripts.append(predicted_words)\n",
    "\n",
    "    return transcripts, ctc_probs\n",
    "\n",
    "transcripts, ctc_probs = transcribe_dataset(asr_brain, test_set, greedy=False, num_batches_to_transcribe=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b822e8c1",
   "metadata": {},
   "source": [
    "# LOAD WORD ALIGNED MELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "40e05be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imitate CLAs\n",
    "import sys\n",
    "import argparse\n",
    "import math\n",
    "import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9dc7e6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = [\n",
    "    # speechbrain features\n",
    "    'train.py',\n",
    "    '--type', 'mel',\n",
    "    '--utt_id_list', '/home/s1785140/data/ljspeech_fastpitch/respeller_uttids.txt', \n",
    "    '--input_directory', '/home/s1785140/speechbrain/templates/speech_recognition_CharTokens_NoLM/data/ljspeech_dumped_feats',\n",
    "    '--alignments', '/home/s1785140/speechbrain/templates/speech_recognition_CharTokens_NoLM/data/LJSpeech-1.1/MFA_alignments_lowercase_nopunc', # newer alignments, lowercase no punctuation\n",
    "    '--output_directory', '/home/s1785140/speechbrain/templates/speech_recognition_CharTokens_NoLM/data/ljspeech_dumped_feats_word_aligned',\n",
    "    # '--mel-to-graphemes-ratio-lowest-threshold', '5.5',\n",
    "    # '--mel-to-graphemes-ratio-highest-threshold', '13.5',\n",
    "    '--clean-output-folder',\n",
    "]\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('-t', '--type', type=str, default='hubert',\n",
    "                    help='type of input speech reps that we are using, i.e. hubert wav2vec2 etc.')\n",
    "parser.add_argument('--padding_idx_offset', type=int, default=0,\n",
    "                    help='add 1 to token id of discrete reps in order to allow for padding_idx==0')\n",
    "parser.add_argument('--utt_id_list', type=str, required=False, default=\"\",\n",
    "                    help='path to text file that contains list of utterance ids that we extract from')\n",
    "parser.add_argument('-s', '--input_directory', type=str, required=True,\n",
    "                    help='path to single non-nested folder containing speech representations (.pt files) or txt file (hubert)')\n",
    "parser.add_argument('-a', '--alignments', type=str, required=True,\n",
    "                    help='path to single non-nested folder containing MFA alignments (.TextGrid files)')\n",
    "parser.add_argument('-o', '--output_directory', type=str, required=True,\n",
    "                    help='where to write word-level data')\n",
    "parser.add_argument('--max-utts-to-generate', type=int, default=None,\n",
    "                    help='How many utts to extract word aligned speech reps for. If None, extract all utts.')\n",
    "parser.add_argument('--mel-to-graphemes-ratio-lowest-threshold', type=float, default=0.0,\n",
    "                    help='Lowest mel-to-graphemes ratio to consider. (lower ratio means fewer mel frames per grapheme)')\n",
    "parser.add_argument('--mel-to-graphemes-ratio-highest-threshold', type=float, default=math.inf,\n",
    "                    help='Lowest mel-to-graphemes ratio to consider. (higher ratio means more mel frames per grapheme)')\n",
    "parser.add_argument('--clean-output-folder', action=\"store_true\",\n",
    "                    help='Clean output folder before writing new data')\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "89f170f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "globbed 62116 mels from /home/s1785140/speechbrain/templates/speech_recognition_CharTokens_NoLM/data/ljspeech_dumped_feats_word_aligned.\n"
     ]
    }
   ],
   "source": [
    "# grab all mels and words in the output directory\n",
    "'/home/s1785140/speechbrain/templates/speech_recognition_CharTokens_NoLM/data/ljspeech_dumped_feats_word_aligned',\n",
    "\n",
    "# glob pytorch tensors from nested folders in output directory\n",
    "mel_paths = glob.glob(f'{args.output_directory}/**/*.pt', recursive=True)\n",
    "print(f\"globbed {len(mel_paths)} mels from {args.output_directory}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "91e68d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "MAX_TOKENS_TO_TRANSCRIBE = 5\n",
    "\n",
    "# load mels into list\n",
    "mel_paths = []\n",
    "mels = []\n",
    "words = []\n",
    "for mel_path in tqdm(list(mel_paths)[:MAX_TOKENS_TO_TRANSCRIBE]):\n",
    "    mel_paths.append(mel_path)\n",
    "\n",
    "    mel = torch.load(mel_path)\n",
    "    mels.append(mel)\n",
    "\n",
    "    # also get word from path\n",
    "    word = mel_path.split('/')[-2]\n",
    "    words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7943dae2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "272fbeeb",
   "metadata": {},
   "source": [
    "# TRANSCRIBE WORD ALIGNED MELS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "6a8422eeb13ba8f92f71047f64b5c33152e234c2bbad3f45433feda7b6f3b4c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
