{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a0453510-71c2-4a70-960a-970940bfc5d5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "docstring = \"\"\"\n",
    "(Use fastpitch conda env)\n",
    "\n",
    "Helper script that takes a folder of speech reps (wav2vec2, mel-spec, etc.)\n",
    "and aligns them at word-level using MFA alignments.\n",
    "\n",
    "Speech reps corresponding to word tokens in the corpus are then saved individually to an output folder\n",
    "with the following structure:\n",
    "- data_path\n",
    "    - word1\n",
    "        - word1_LJ010-0292_001.pt\n",
    "        - word1_LJ010-0292_002.pt\n",
    "        - ...\n",
    "    - word2\n",
    "        - word2_LJ001-0012_001.pt\n",
    "        - word2_LJ002-0024_001.pt\n",
    "        - ...\n",
    "    - ...\n",
    "\n",
    "- word1, word2, ... subfolders refer to a particular wordtype in the corpus.\n",
    "- .pt files contain speech representations that map to a particular example of a wordtype.\n",
    "  It is named as:\n",
    "    <wordtype>_<utt id>_<numbered occurrence in the utterance>.pt\n",
    "\n",
    "Example usage:\n",
    "    #hubert w/ padding offset\n",
    "    cd ~/fairseq\n",
    "    python examples/lexicon_learner/wordalign_speechreps.py \\\n",
    "        -t hubert \\\n",
    "        --padding_idx_offset 1 \\\n",
    "        -s /home/s1785140/fairseq/examples/lexicon_learner/lj_speech_quantized.txt \\\n",
    "        -a /home/s1785140/data/ljspeech_MFA_alignments \\\n",
    "        -o /home/s1785140/data/ljspeech_hubert_reps/hubert-base/layer-6/word_level_with_padding_idx_offset\n",
    "\n",
    "    #hubert w/o padding offset\n",
    "    cd ~/fairseq\n",
    "    python examples/lexicon_learner/wordalign_speechreps.py \\\n",
    "        -t hubert \\\n",
    "        --padding_idx_offset 0 \\\n",
    "        -s /home/s1785140/fairseq/examples/lexicon_learner/lj_speech_quantized.txt \\\n",
    "        -a /home/s1785140/data/ljspeech_MFA_alignments \\\n",
    "        -o /home/s1785140/data/ljspeech_hubert_reps/hubert-base/layer-6/word_level_without_padding_idx_offset\n",
    "\n",
    "    #wav2vec2\n",
    "    cd ~/fairseq\n",
    "    python examples/lexicon_learner/wordalign_speechreps.py \\\n",
    "        -t wav2vec2 \\\n",
    "        -s /home/s1785140/data/ljspeech_wav2vec2_reps/wav2vec2-large-960h/layer-15/utt_level \\\n",
    "        -a /home/s1785140/data/ljspeech_MFA_alignments \\\n",
    "        -o /home/s1785140/data/ljspeech_wav2vec2_reps/wav2vec2-large-960h/layer-15/word_level\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95da2491",
   "metadata": {},
   "source": [
    "Command line args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6ed31824-8d7f-4e8c-a96b-937915cfc08f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# imitate CLAs\n",
    "import sys\n",
    "sys.argv = [\n",
    "    # fastpitch features\n",
    "    # 'train.py',\n",
    "    # '--type', 'mel',\n",
    "    # '--utt_id_list', '/home/s1785140/data/ljspeech_fastpitch/respeller_uttids.txt', \n",
    "    # '--input_directory', '/home/s1785140/data/ljspeech_fastpitch/mels',\n",
    "    # '--alignments', '/home/s1785140/data/ljspeech_fastpitch/aligns', \n",
    "    # '--output_directory', '/home/s1785140/data/ljspeech_fastpitch/wordaligned_mels',\n",
    "\n",
    "    # speechbrain features\n",
    "    'train.py',\n",
    "    '--type', 'mel',\n",
    "    '--utt_id_list', '/home/s1785140/data/ljspeech_fastpitch/respeller_uttids.txt', \n",
    "    '--input_directory', '/home/s1785140/speechbrain/templates/speech_recognition_CharTokens_NoLM/data/ljspeech_dumped_feats',\n",
    "    '--alignments', '/home/s1785140/data/ljspeech_fastpitch/aligns', \n",
    "    '--output_directory', '/home/s1785140/speechbrain/templates/speech_recognition_CharTokens_NoLM/data/ljspeech_dumped_feats_word_aligned',\n",
    "    \n",
    "    # FOR TESTING\n",
    "    # '--input_directory', '/home/s1785140/data/ljspeech_fastpitch/mels_test',\n",
    "    # '--alignments', '/home/s1785140/data/ljspeech_fastpitch/aligns_test', \n",
    "    # '--output_directory', '/home/s1785140/data/ljspeech_fastpitch/wordaligned_mels_test',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9a486af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /disk/nfs/ostrom/s1785140/miniconda3/envs/fastpitch/lib/python3.8/site-packages (3.8.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /disk/nfs/ostrom/s1785140/miniconda3/envs/fastpitch/lib/python3.8/site-packages (from nltk) (2022.10.31)\n",
      "Requirement already satisfied: click in /disk/nfs/ostrom/s1785140/miniconda3/envs/fastpitch/lib/python3.8/site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: tqdm in /disk/nfs/ostrom/s1785140/miniconda3/envs/fastpitch/lib/python3.8/site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: joblib in /disk/nfs/ostrom/s1785140/miniconda3/envs/fastpitch/lib/python3.8/site-packages (from nltk) (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "# install package from notebook\n",
    "import sys\n",
    "!{sys.executable} -m pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1186da",
   "metadata": {},
   "source": [
    "# imports and globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d3f0393f-64f2-4056-b219-a3e4f557516d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/s1785140/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import tgt\n",
    "import string\n",
    "import librosa\n",
    "import glob\n",
    "import random\n",
    "from IPython.display import Audio\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "SKIP_NON_ASCII = False\n",
    "WORDS_TO_SKIP = [\"wdsu-tv\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1439b58",
   "metadata": {},
   "source": [
    "# Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9ff2a0ad-4c05-476f-a430-ddd4e8e92e6e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('-t', '--type', type=str, default='hubert',\n",
    "                    help='type of input speech reps that we are using, i.e. hubert wav2vec2 etc.')\n",
    "parser.add_argument('--padding_idx_offset', type=int, default=0,\n",
    "                    help='add 1 to token id of discrete reps in order to allow for padding_idx==0')\n",
    "parser.add_argument('--utt_id_list', type=str, required=False, default=\"\",\n",
    "                    help='path to text file that contains list of utterance ids that we extract from')\n",
    "parser.add_argument('-s', '--input_directory', type=str, required=True,\n",
    "                    help='path to single non-nested folder containing speech representations (.pt files) or txt file (hubert)')\n",
    "parser.add_argument('-a', '--alignments', type=str, required=True,\n",
    "                    help='path to single non-nested folder containing MFA alignments (.TextGrid files)')\n",
    "parser.add_argument('-o', '--output_directory', type=str, required=True,\n",
    "                    help='where to write word-level data')\n",
    "args = parser.parse_args()\n",
    "\n",
    "if \"speechbrain\" in args.input_directory:\n",
    "    args.corpus_name = \"speechbrain\"\n",
    "    args.transpose_mel = False\n",
    "    SAMPLING_RATE = 16000 # hz\n",
    "    HOP_LENGTH_IN_MS = 10 # in ms\n",
    "    WIN_LENGTH_IN_MS = 25 # in ms\n",
    "    HOP_LENGTH = int(HOP_LENGTH_IN_MS * SAMPLING_RATE / 1000) # convert HOP_LENGTH to samples\n",
    "    WIN_LENGTH = int(WIN_LENGTH_IN_MS * SAMPLING_RATE / 1000) # convert WIN_LENGTH to samples\n",
    "elif \"ljspeech\" in args.input_directory:\n",
    "    args.corpus_name = \"ljspeech\"\n",
    "    args.transpose_mel = True\n",
    "    SAMPLING_RATE = 22050 # hz\n",
    "    HOP_LENGTH = 256 # in samples\n",
    "    \n",
    "args.max_utts_to_generate = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81205290",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "050c2ce5-b47b-4bf5-96a1-fd8bedc6330a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def save_to_disk(tensor, word, utt_id, count, output_directory):\n",
    "    output_directory = os.path.join(output_directory, word)\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    save_path = os.path.join(output_directory, f'{word}__{utt_id}__occ{count}.pt')\n",
    "    torch.save(tensor, save_path)\n",
    "    \n",
    "def allowed_word(word):\n",
    "    if len(word) <= 1:\n",
    "        return False\n",
    "    if word == '--':\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8affea0-41bb-4739-b9ee-496642017f14",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# load speech reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "225bb850-5a9e-4d90-bc1e-3c44c9d8048d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading mels from disk in dir /home/s1785140/speechbrain/templates/speech_recognition_CharTokens_NoLM/data/ljspeech_dumped_feats for 25 utts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:03<00:00,  8.18it/s]\n"
     ]
    }
   ],
   "source": [
    "debug = True\n",
    "if debug:\n",
    "    # load fewer utts\n",
    "    max_utts = args.max_utts_to_generate\n",
    "else:\n",
    "    max_utts = None\n",
    "\n",
    "    \n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "map_location = 'cuda' if cuda else 'cpu'\n",
    "\n",
    "if args.type == \"hubert\":\n",
    "    with open(args.input_directory, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    num_of_utts = len(lines)\n",
    "    utt_id2speechreps = {l.split('|')[0]:l.split('|')[1] for l in lines}\n",
    "    utt_ids = sorted(utt_id2speechreps.keys()) # ensure we always process utts in same alphabetical order\n",
    "elif args.type == \"wav2vec2\":\n",
    "    num_of_utts = len(os.listdir(args.input_directory))\n",
    "    utt_ids = sorted(file.split('.')[0] for file in os.listdir(args.input_directory))\n",
    "elif args.type == \"mel\":\n",
    "    if args.utt_id_list:\n",
    "        # we specified a subset of utt ids\n",
    "        with open(args.utt_id_list, 'r') as f:\n",
    "            utt_ids = f.read().splitlines()\n",
    "    else:\n",
    "        # all files in directory\n",
    "        utt_ids = list(sorted(file.split('.')[0] for file in os.listdir(args.input_directory)))\n",
    "    num_of_utts = len(utt_ids)\n",
    "    utt_ids = utt_ids[:max_utts]\n",
    "    utt_id2speechreps = {}\n",
    "    print(f\"loading mels from disk in dir {args.input_directory} for {len(utt_ids)} utts\")\n",
    "    for utt_id in tqdm(utt_ids):\n",
    "        # load mel data\n",
    "        mel_path = os.path.join(args.input_directory, f'{utt_id}.pt')\n",
    "        mel = torch.load(mel_path, map_location=map_location)\n",
    "        if args.transpose_mel:\n",
    "            mel = mel.transpose(0,1)\n",
    "\n",
    "        # mels should be of shape (T, D) now\n",
    "        utt_id2speechreps[utt_id] = mel\n",
    "else:\n",
    "    raise ValueError(f\"invalid input type {args.type}\")\n",
    "\n",
    "# sanity check - assert that each utt has a corresponding alignment\n",
    "alignment_files = set(os.listdir(args.alignments))\n",
    "for utt_id in utt_ids:\n",
    "    assert f\"{utt_id}.TextGrid\" in alignment_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a8a42a-79ba-468d-9cb8-cae8ef38cb95",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# perform splitting of mel specs using MFA alignments and save to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8392ea9e-a6ac-4084-9558-5e3c1921b96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_textgrid(tier, sampling_rate, hop_length, ignore_all_pauses=True):\n",
    "    # latest MFA replaces silence phones with \"\" in output TextGrids\n",
    "    sil_phones = [\"sil\", \"sp\", \"spn\", \"\"]\n",
    "    utt_start_time = tier[0].start_time\n",
    "    utt_end_time = tier[-1].end_time\n",
    "    phones = []\n",
    "    durations = [] # NOTE includes durations of silences\n",
    "    start_frames = []\n",
    "    end_frames = []\n",
    "    for i, t in enumerate(tier._objects):\n",
    "        s, e, p = t.start_time, t.end_time, t.text\n",
    "        if p not in sil_phones:\n",
    "            phones.append(p)\n",
    "            start_frames.append(int(np.ceil(s * sampling_rate / hop_length)))\n",
    "            end_frames.append(int(np.ceil(e * sampling_rate / hop_length)))\n",
    "            durations.append(int(np.ceil(e * sampling_rate / hop_length)\n",
    "                                 - np.ceil(s * sampling_rate / hop_length)))\n",
    "        else:\n",
    "            if not ignore_all_pauses:\n",
    "                if (i == 0) or (i == len(tier) - 1):\n",
    "                    # leading or trailing silence\n",
    "                    phones.append(\"sil\")\n",
    "                else:\n",
    "                    # short pause between words\n",
    "                    phones.append(\"sp\")\n",
    "\n",
    "    n_samples = utt_end_time * sampling_rate\n",
    "    n_frames = n_samples / hop_length\n",
    "    # fix occasional length mismatches at the end of utterances when\n",
    "    # duration in samples is an integer multiple of hop_length\n",
    "    if n_frames.is_integer():\n",
    "        durations[-1] += 1\n",
    "    return phones, durations, start_frames, end_frames, utt_start_time, utt_end_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ebf35796",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def extract_reprs_with_timestamps(total_num_frames, start_time, end_time, utt_duration):\n",
    "    \"\"\"\n",
    "    extract subsequence of 'repr' that corresponds to a particular word\n",
    "    function expects input to be of dimension 2: (timesteps, hidden_size)\n",
    "    \"\"\"\n",
    "    start_fraction = start_time / utt_duration\n",
    "    end_fraction = end_time / utt_duration\n",
    "    # start_idx = math.floor(start_fraction * total_num_frames)\n",
    "    # end_idx = math.ceil(end_fraction * total_num_frames)\n",
    "    start_idx = int(start_fraction * total_num_frames)\n",
    "    end_idx = int(end_fraction * total_num_frames)\n",
    "    # start_idx = math.floor(start_fraction * total_num_frames)\n",
    "    # end_idx = math.ceil(end_fraction * total_num_frames)\n",
    "    num_frames = end_idx - start_idx\n",
    "    return start_idx, end_idx, num_frames\n",
    "\n",
    "def parse_textgrid2(tier, mel_spectrogram, ignore_all_pauses=True):\n",
    "    # latest MFA replaces silence phones with \"\" in output TextGrids\n",
    "    total_num_frames = mel_spectrogram.size(0)\n",
    "    sil_phones = [\"sil\", \"sp\", \"spn\", \"\"]\n",
    "    utt_start_time = tier[0].start_time\n",
    "    utt_end_time = tier[-1].end_time\n",
    "    words = []\n",
    "    word_durations = [] \n",
    "    sil_durations = []\n",
    "    start_frames = []\n",
    "    end_frames = []\n",
    "    for i, t in enumerate(tier._objects):\n",
    "        start, end, token = t.start_time, t.end_time, t.text\n",
    "        start_idx, end_idx, num_frames = extract_reprs_with_timestamps(total_num_frames, start, end, utt_end_time)\n",
    "    \n",
    "        if token not in sil_phones:\n",
    "            words.append(token)\n",
    "            start_frames.append(start_idx)\n",
    "            end_frames.append(end_idx)\n",
    "            word_durations.append(num_frames)\n",
    "        else:\n",
    "            sil_durations.append(num_frames)\n",
    "\n",
    "    return words, word_durations, sil_durations, start_frames, end_frames, utt_start_time, utt_end_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5d30b8ce-c345-40e2-8ae5-bb1fc4f468bf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split speech reps using word alignments\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:40<00:00,  1.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wordtype with longest num of timesteps is 'surpassed' from LJ001-0008 with len 407\n",
      "you can set transformer max_source_positions to this\n",
      "Added 289 files to /home/s1785140/speechbrain/templates/speech_recognition_CharTokens_NoLM/data/ljspeech_dumped_feats_word_aligned, now contains 454 files, used to contain 165 files\n"
     ]
    }
   ],
   "source": [
    "longest_word = ''\n",
    "longest_word_utt_id = ''\n",
    "longest_word_num_frames = 0\n",
    "buffer_frames = 0\n",
    "\n",
    "# glob recursively number of torch tensor files in output directory\n",
    "orig_num_files = len(glob.glob(os.path.join(args.output_directory, '**', '*.pt'), recursive=True))\n",
    "\n",
    "# split each speech reps file using the word-level alignments\n",
    "print(\"split speech reps using word alignments\")\n",
    "for utt_id in tqdm(utt_ids):\n",
    "    # load speech reps\n",
    "    if args.type == \"hubert\":\n",
    "        reps = utt_id2speechreps[utt_id]\n",
    "        reps = [int(s)+args.padding_idx_offset for s in reps.split(' ')] # NOTE add 1 to each index so that 0 is available as a padding_idx\n",
    "        reps = torch.tensor(reps)\n",
    "        reps.requires_grad = False\n",
    "\n",
    "        # check dimensions\n",
    "        if reps.dim() == 1:\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(\"speech representations have an incorrect number of dimensions\")\n",
    "    elif args.type == \"mel\":\n",
    "        reps = utt_id2speechreps[utt_id]\n",
    "        reps.requires_grad = False\n",
    "\n",
    "        # check dimensions\n",
    "        if reps.dim() == 2:\n",
    "            if args.corpus_name == 'speechbrain' and reps.size(1) == 40:\n",
    "                pass\n",
    "            elif args.corpus_name == 'ljspeech' and reps.size(1) == 80:\n",
    "                pass\n",
    "            else:\n",
    "                raise ValueError(f\"feat dimension is wrong size for corpus {reps.size(1)=}\")    \n",
    "        else:\n",
    "            raise ValueError(f\"speech representations have an incorrect number of dimensions {reps.dim()=}\")\n",
    "    else:\n",
    "        raise ValueError(f\"invalid input type {args.type}\")\n",
    "\n",
    "    tg_path = f\"{args.alignments}/{utt_id}.TextGrid\"\n",
    "    tg = tgt.io.read_textgrid(tg_path, include_empty_intervals=True)\n",
    "    # words, word_durs, start_frames, end_frames, utt_start, utt_end = parse_textgrid(tg.get_tier_by_name('words'), SAMPLING_RATE, HOP_LENGTH)\n",
    "    words, word_durs, sil_durations, start_frames, end_frames, utt_start, utt_end = parse_textgrid2(tg.get_tier_by_name('words'), reps, ignore_all_pauses=True)\n",
    "    \n",
    "    word_occ_in_utt_counter = Counter()\n",
    "    mel = utt_id2speechreps[utt_id]\n",
    "    assert mel.size(0) == (sum(word_durs) + sum(sil_durations)), f\"{mel.size(0)=} != {sum(word_durs)=} + {sum(sil_durations)=}\" # verify that MFA frame durations match up with the extracted mels\n",
    "    # print(f\"{mel.size(0)=} == {sum(word_durs)=} + {sum(sil_durations)=}\")\n",
    "\n",
    "    for j, (word, dur, start_frame, end_frame) in enumerate(zip(words, word_durs, start_frames, end_frames)):\n",
    "        if allowed_word(word):\n",
    "            skip_word = False\n",
    "            normalise_non_ascii = False\n",
    "            for c in word:\n",
    "                if c not in string.ascii_lowercase:\n",
    "                    s = f'WARNING: char {c} in word {word}'\n",
    "                    if SKIP_NON_ASCII or word in WORDS_TO_SKIP:\n",
    "                        s += '. skipping!...'\n",
    "                        skip_word = True\n",
    "                    else:\n",
    "                        normalise_non_ascii = True\n",
    "\n",
    "                    print(s)\n",
    "                    \n",
    "            if not skip_word:\n",
    "                if normalise_non_ascii: # normalise word\n",
    "                    prenorm_word = word\n",
    "                    # remove trailing '-'\n",
    "                    word = word.rstrip('-')\n",
    "                    # convert diacritics to ascii\n",
    "                    word = unidecode.unidecode(word)\n",
    "                    print(f\"\\tnormalised '{prenorm_word}' to '{word}'\")\n",
    "                \n",
    "                # check if word is the longest word we have seen so far\n",
    "                word_dur = end_frame - start_frame \n",
    "                if word_dur > longest_word_num_frames:\n",
    "                    longest_word_num_frames = word_dur\n",
    "                    longest_word = word\n",
    "                    longest_word_utt_id = utt_id\n",
    "\n",
    "                # extract mel\n",
    "                a = max(0, start_frame - buffer_frames)\n",
    "                b = min(mel.size(0), end_frame + buffer_frames)\n",
    "                # print(mel.size(0), start_frame, end_frame, a, b)\n",
    "                wordaligned_mel = mel[a:b]\n",
    "\n",
    "                # save extracted mel to disk\n",
    "                word_occ_in_utt_counter[word] += 1\n",
    "                extracted_timesteps = wordaligned_mel.size(0)\n",
    "                # print(j, f\"{dur=}, {extracted_timesteps=}, {word_dur=}\")\n",
    "                assert dur == extracted_timesteps - (start_frame - a) - (b - end_frame) == word_dur, f\"{dur=}, {extracted_timesteps=}, {word_dur=}\"\n",
    "                save_to_disk(wordaligned_mel, word, utt_id, word_occ_in_utt_counter[word], args.output_directory)\n",
    "\n",
    "print(f\"wordtype with longest num of timesteps is '{longest_word}' from\", longest_word_utt_id, \"with len\", longest_word_num_frames)\n",
    "print(\"you can set transformer max_source_positions to this\")\n",
    "\n",
    "new_num_files = len(glob.glob(os.path.join(args.output_directory, '**', '*.pt'), recursive=True))\n",
    "\n",
    "print(f\"Added {new_num_files - orig_num_files} files to {args.output_directory}, now contains {new_num_files} files, used to contain {orig_num_files} files\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "91b402ed",
   "metadata": {},
   "source": [
    "## sanity check alignments by generating wordaligned spectrograms using griffin-lim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6b97e976",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 454/454 [00:09<00:00, 46.06it/s]\n"
     ]
    }
   ],
   "source": [
    "# glob pytorch tensors from nested folders in output directory\n",
    "mel_paths = glob.glob(f'{args.output_directory}/**/*.pt', recursive=True)\n",
    "\n",
    "# load mels into list\n",
    "mels = []\n",
    "words = []\n",
    "for mel_path in tqdm(mel_paths):\n",
    "    mel = torch.load(mel_path)\n",
    "    mels.append(mel)\n",
    "\n",
    "    # also get word from path\n",
    "    word = mel_path.split('/')[-2]\n",
    "    words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c77f83a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def griffin_lim_synthesise(mel, n_iter=100):\n",
    "    \"\"\"Synthesises audio from mel spectrogram using Griffin-Lim algorithm.\n",
    "    Args:\n",
    "        mel (torch.Tensor): Mel spectrogram (B, C, T).\n",
    "        n_iter (int): Number of iterations for Griffin-Lim algorithm.\n",
    "    Returns:\n",
    "        torch.Tensor: Audio waveform (B, T).\n",
    "    \"\"\"\n",
    "    mel = mel.detach().cpu().numpy()\n",
    "    mel = librosa.feature.inverse.mel_to_audio(\n",
    "        mel, sr=SAMPLING_RATE, n_fft=400, hop_length=HOP_LENGTH, win_length=WIN_LENGTH,\n",
    "        window='hamming', center=True, pad_mode='constant', power=1.0, n_iter=n_iter,\n",
    "        )\n",
    "    mel = torch.from_numpy(mel).float()\n",
    "    return mel\n",
    "\n",
    "def reshape_mel_for_librosa(mel):\n",
    "    mel = mel.unsqueeze(0) # make batch dimension\n",
    "    mel = mel.transpose(1, 2)\n",
    "    return mel\n",
    "\n",
    "def synthesise_and_play_Audio(mel, n_iter=100):\n",
    "    mel = reshape_mel_for_librosa(mel)\n",
    "    audio = griffin_lim_synthesise(mel, n_iter)\n",
    "    return Audio(audio, rate=SAMPLING_RATE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6415644b",
   "metadata": {},
   "source": [
    "## listen to generated audio for each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5f3276ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(stop_words)=179\n",
      "len(stop_words)=197\n",
      "['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'b', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'c', 'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'e', 'each', 'f', 'few', 'for', 'from', 'further', 'g', 'h', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', 'her', 'here', 'hers', 'herself', 'him', 'himself', 'his', 'how', 'i', 'if', 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it's\", 'its', 'itself', 'j', 'just', 'k', 'l', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'n', 'needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 'p', 'q', 'r', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she's\", 'should', \"should've\", 'shouldn', \"shouldn't\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', 'this', 'those', 'through', 'to', 'too', 'u', 'under', 'until', 'up', 'v', 've', 'very', 'w', 'was', 'wasn', \"wasn't\", 'we', 'were', 'weren', \"weren't\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'x', 'y', 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself', 'yourselves', 'z']\n"
     ]
    }
   ],
   "source": [
    "# get list of wordnet nltk stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "print(f\"{len(stop_words)=}\")\n",
    "\n",
    "# add to stop_words all letters in alphabet, since tokenisation might create these edge cases \n",
    "# for example, \"wasn't\" might get tokenized as \"wasn\" and \"t\"\n",
    "stop_words.update(string.ascii_lowercase)\n",
    "print(f\"{len(stop_words)=}\")\n",
    "print(sorted(stop_words))\n",
    "\n",
    "# words_to_synth = \"stopwords\"\n",
    "words_to_synth = \"functionwords\"\n",
    "\n",
    "tuples = list(zip(mels, words))\n",
    "# filter out words that are not in the wordnet nltk stopwords list\n",
    "if words_to_synth == \"stopwords\":\n",
    "    tuples = [t for t in tuples if t[1] in stop_words]\n",
    "# filter out words that are not in the function word list\n",
    "elif words_to_synth == \"functionwords\":\n",
    "    tuples = [t for t in tuples if t[1] not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "372bd11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating audio for following words: ('actually', 'aforesaid', 'ages', 'ages', 'also', 'although', 'always', 'arrangement', 'art', 'arts', 'basle', 'beautiful', 'beautiful', 'beautiful', 'beautiful', 'began', 'bible', 'bible', 'bible', 'birth', 'block', 'blocks', 'book', 'book', 'book', 'book', 'books', 'books', 'books', 'brought', 'called', 'calligraphy', 'care', 'case', 'casting', 'centuries', 'century', 'century', 'century', 'certainly', 'character', 'chinese', 'cities', 'come', 'comparatively', 'composed', 'concerned', 'considered', 'considered', 'consist', 'cost', 'course', 'crafts', 'craftsmen', 'dated', 'differs', 'earliest', 'earliest', 'easier', 'ecclesiastical', 'eleventh', 'engraved', 'especially', 'especially', 'etc', 'even', 'exact', 'example', 'exceedingly', 'exhibition', 'fact', 'far', 'fifteen', 'fifteenth', 'fifteenth', 'fifty', 'fine', 'first', 'five', 'five', 'form', 'form', 'formal', 'forms', 'forty', 'fourteen', 'fourteen', 'fourteen', 'france', 'freer', 'germany', 'gothic', 'gothic', 'gutenberg', 'gutenberg', 'hand', 'help', 'imitates', 'imitation', 'immediate', 'impressions', 'incurred', 'indeed', 'intended', 'invention', 'invention', 'italy', 'justly', 'kind', 'less', 'letter', 'letterpress', 'letters', 'letters', 'letters', 'letters', 'letters', 'letters', 'line', 'look', 'lower', 'lubeck', 'maintz', 'many', 'matter', 'may', 'may', 'mention', 'metal', 'middle', 'middle', 'middle', 'missal', 'missals', 'modern', 'monastery', 'movable', 'movable', 'movable', 'mss', 'much', 'must', 'natural', 'ne', 'near', 'netherlands', 'never', 'next', 'obtained', 'occupied', 'page', 'pannartz', 'paris', 'part', 'passing', 'perfection', 'peter', 'picture', 'pleasanter', 'plus', 'predecessors', 'present', 'primarily', 'principally', 'printed', 'printed', 'printed', 'printed', 'printed', 'printed', 'printers', 'printing', 'printing', 'printing', 'printing', 'printing', 'process', 'produced', 'produced', 'productions', 'psalters', 'read', 'reasonable', 'regards', 'relief', 'represented', 'roman', 'roman', 'rome', 'rounder', 'saw', 'schoeffer', 'schoeffer', 'sense', 'setting', 'shapeliness', 'similar', 'similar', 'simpler', 'since', 'sixty', 'sixty', 'spiky', 'splendid', 'strasburg', 'study', 'subiaco', 'surpassed', 'sweynheim', 'therefore', 'therefore', 'time', 'time', 'took', 'took', 'transition', 'true', 'twelfth', 'twenty', 'two', 'two', 'type', 'type', 'type', 'type', 'type', 'type', 'types', 'types', 'typography', 'ultra', 'used', 'used', 'used', 'whatever', 'whole', 'wood', 'woodcutters', 'worth', 'writing', 'year', 'years', 'years')\n"
     ]
    }
   ],
   "source": [
    "# NOTE these might sound very bad for two reasons\n",
    "# 1. stft -> mel spec is not lossless\n",
    "# 2. (speechbrain) ASR features are fewer bins (i.e. 40 rather than 80 mel spec bins)\n",
    "# but still good enough for sanity checking alignments!\n",
    "NUM_TO_LISTEN = None\n",
    "# NUM_TO_LISTEN = 20\n",
    "\n",
    "# generate wavs from mels and then concatenate them into a single wav separated by silences and play in notebook\n",
    "# NOTE this is not lossless, but still good enough for sanity checking alignments!\n",
    "def generate_wav_from_mel(mel, n_iter=100):\n",
    "    mel = reshape_mel_for_librosa(mel)\n",
    "    audio = griffin_lim_synthesise(mel, n_iter)\n",
    "    audio = audio.squeeze(0)\n",
    "    audio = audio.numpy()\n",
    "    return audio\n",
    "\n",
    "def generate_wav_from_mels_with_silences(mels, n_iter=100, silence_duration=0.5):\n",
    "    wavs = []\n",
    "    for mel in mels:\n",
    "        wavs.append(generate_wav_from_mel(mel, n_iter))\n",
    "        wavs.append(np.zeros(int(silence_duration * SAMPLING_RATE)))\n",
    "    wav = np.concatenate(wavs)\n",
    "    return wav\n",
    "\n",
    "def generate_wav_from_mels_with_silences_and_play(mels, n_iter=100, silence_duration=0.5):\n",
    "    wav = generate_wav_from_mels_with_silences(mels, n_iter, silence_duration)\n",
    "    return Audio(wav, rate=SAMPLING_RATE)\n",
    "\n",
    "random.shuffle(tuples)\n",
    "mels_to_gen = [t[0] for t in tuples[:NUM_TO_LISTEN]]\n",
    "words_to_gen = [t[1] for t in tuples[:NUM_TO_LISTEN]]\n",
    "\n",
    "# sort mels and words by alphabetical order of words\n",
    "mels_to_gen, words_to_gen = zip(*sorted(zip(mels_to_gen, words_to_gen), key=lambda x: x[1]))\n",
    "\n",
    "print(\"Generating audio for following words:\", words_to_gen)\n",
    "generate_wav_from_mels_with_silences_and_play(mels_to_gen, silence_duration=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cd935f97",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "stop before creating datasplits",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/s1785140/rlspeller/wordalign_features.ipynb Cell 23\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bescience6.inf.ed.ac.uk/home/s1785140/rlspeller/wordalign_features.ipynb#X45sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mstop before creating datasplits\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: stop before creating datasplits"
     ]
    }
   ],
   "source": [
    "raise ValueError(\"stop before creating datasplits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd5c7db-860e-4daf-aa2e-52f6d6a12cff",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# create train,dev,test datasplits for training respeller\n",
    "\n",
    "We hold out WORDTYPES from training for the dev and test splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1d3344-f2ed-44f3-bf87-0f0b038c0421",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835dc300-35a9-4f21-a5d3-584919022662",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "\n",
    "random.seed(1337)\n",
    "\n",
    "train_ratio, dev_ratio, test_ratio = [0.9, 0.05, 0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fc263e-51ae-4d31-b7c8-b5b75454bf24",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# get oov wordtypes list (words that are not seen in tts training)\n",
    "oov_wordlist_path = '/home/s1785140/data/ljspeech_fastpitch/oov_list.json'\n",
    "with open(oov_wordlist_path, 'r') as f:\n",
    "    oovs_and_freqs = json.load(f)\n",
    "    \n",
    "all_wordtypes = set(oovs_and_freqs.keys())\n",
    "print(f'original before cleaning/sampling {len(all_wordtypes)=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c6d733-557d-49bf-8ef2-63983caba003",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# clean/remove words that do not have speech reps\n",
    "words_with_aligned_mels = set(os.listdir(args.output_directory))\n",
    "words_no_mels = all_wordtypes - words_with_aligned_mels\n",
    "print(f'{len(words_no_mels)}=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a134aa68-17fb-425e-b5ee-0a4bd19407bd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"list of words to be excluded from respeller training as they do not have mels (likely due to how normalisation is different between mfa and our own data processing):\")\n",
    "words_no_mels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e5f5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cae348a-0333-484a-8245-383537c4877f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# remove these problematic words from respeller training dev test\n",
    "for w in words_no_mels:\n",
    "    del oovs_and_freqs[w]\n",
    "    \n",
    "all_wordtypes = set(oovs_and_freqs.keys())\n",
    "print(f'original after cleaning {len(all_wordtypes)=}')\n",
    "\n",
    "dev_N = int(dev_ratio * len(all_wordtypes))\n",
    "test_N = int(test_ratio * len(all_wordtypes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ce65fc-a973-4fbc-8b82-e63dd0131ee8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def sample_and_remove(s: set, N: int):\n",
    "    \"\"\"sample N words from set s\n",
    "    then remove these words from the set\"\"\"\n",
    "    sampled = random.sample(s, N)\n",
    "    for item in sampled:\n",
    "        s.remove(item)\n",
    "    return set(sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3e4eed-a336-43c1-8634-8b54707034fd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#get dev and test splits\n",
    "oov_singletons = set(wordtype for wordtype, freq in oovs_and_freqs.items() if freq == 1)\n",
    "assert len(oov_singletons) > dev_N + test_N, \"not enough OOV singletons to create dev and test sets\" \n",
    "print(f'before sampling dev and test {len(oov_singletons)=}')\n",
    "\n",
    "dev = sample_and_remove(oov_singletons, dev_N)\n",
    "print(f'after sampling dev {len(oov_singletons)=}, {len(dev)=}')\n",
    "\n",
    "test = sample_and_remove(oov_singletons, test_N)\n",
    "print(f'after sampling test {len(oov_singletons)=}, {len(test)=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69f58b0-b7c7-4c54-9333-adee647b291b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "list(dev)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb7c6d1-0c33-479d-8cbf-859fba31d7bd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "list(test)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01092fe6-fd9f-42db-a206-01097ef558e9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#get train split\n",
    "print(f'before removing dev and test wordtypes {len(all_wordtypes)=}')\n",
    "for word in dev | test:\n",
    "    all_wordtypes.remove(word)\n",
    "print(f'after removing dev and test wordtypes {len(all_wordtypes)=}')\n",
    "\n",
    "train = set(all_wordtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa0bce1-1baa-422d-a6eb-fb53e8d05964",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# sanity checks\n",
    "assert len(dev.intersection(test)) == 0\n",
    "assert len(train.intersection(dev)) == 0\n",
    "assert len(train.intersection(test)) == 0\n",
    "print(\"Good! No overlapping words between train, dev, and test!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455c0255-bf59-480b-9d83-6b43376125f0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# write to disk\n",
    "def save_wordlist(path, words):\n",
    "    with open(path, 'w') as f:\n",
    "        json.dump(sorted(list(words)), f, indent=4)\n",
    "        \n",
    "train_path = '/home/s1785140/data/ljspeech_fastpitch/respeller_train_words.json'\n",
    "dev_path = '/home/s1785140/data/ljspeech_fastpitch/respeller_dev_words.json'\n",
    "test_path = '/home/s1785140/data/ljspeech_fastpitch/respeller_test_words.json'\n",
    "\n",
    "save_wordlist(train_path, train)\n",
    "save_wordlist(dev_path, dev)\n",
    "save_wordlist(test_path, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61f2ebd-5d54-4e81-ae06-295add409a5e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## G2P selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c63569d-3f12-45c0-ba6a-a4379235d35f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "2ed8b345ca459c03f8526b7bad908d345c967956aebabae0df909223b22f2255"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
