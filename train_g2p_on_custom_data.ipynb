{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39e0f974-fdaa-4e78-bb39-ba91c3189f1a",
   "metadata": {},
   "source": [
    "# Goal of this notebook\n",
    "\n",
    "- use certain metrics (LM perplexity, G2P error) to identify wordtypes that are more likely to be mispronounced by our grapheme-input TTS system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa0fd09-7310-41b3-a86e-985037e0f5c0",
   "metadata": {},
   "source": [
    "# automatic reloading magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aeda9093-4c98-46c1-a7d7-0edad8bcb0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5b9302-7704-409e-b496-dab91dbac0a7",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "658c0e24-f88f-4f5d-a6fa-9e4e860e4a50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import jiwer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72abf8f6-bbed-401f-b160-5fd99426f4e8",
   "metadata": {},
   "source": [
    "# check if have correct type of node "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c1b6e438-88c6-4129-be4e-c67f7c45811f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "levi.inf.ed.ac.uk\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "\n",
    "# print hostname to make sure we are on correct node\n",
    "disallowed_nodes = ['escience6']\n",
    "hostname = socket.gethostname()\n",
    "print(hostname)\n",
    "node = hostname.split('.')[0]\n",
    "if node in disallowed_nodes:\n",
    "    raise ValueError(f\"Running on disallowed node {node}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9169c48f-261e-4e4c-9a26-33020fb901bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.is_available()\n",
    "assert torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97c2e95-0e24-4ea6-a902-350056452164",
   "metadata": {},
   "source": [
    "# Load OOV list\n",
    "\n",
    "(wordtypes not seen in the half of LJSpeech used to train TTS and ASR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "28a6ac11-1f51-44c1-abe2-2b026560d076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original before cleaning/sampling len(oovs)=8343\n"
     ]
    }
   ],
   "source": [
    "# get oov wordtypes list (words that are not seen in tts training)\n",
    "oov_wordlist_path = '/home/s1785140/data/ljspeech_fastpitch/oov_list.json'\n",
    "with open(oov_wordlist_path, 'r') as f:\n",
    "    oovs_and_freqs = json.load(f)\n",
    "    \n",
    "oovs = set(w.strip() for w in oovs_and_freqs.keys())\n",
    "print(f'original before cleaning/sampling {len(oovs)=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de77af14-466e-444d-a5bd-b76c9f4c140c",
   "metadata": {},
   "source": [
    "# Load G2P pronunciation lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a1cb1807-44bb-418b-835c-ba9992860703",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset librig2p-nostress (/home/s1785140/.cache/huggingface/datasets/flexthink___librig2p-nostress/default/0.0.0/95c204c6be42796a753ef410b5dfce2bfa21d61b51f0c3ffe85cf6e3a4dee65f)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53cf0ed3738149e18a2dff7174452925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load lexicon that G2P model was trained on\n",
    "dataset_dict = load_dataset(\"flexthink/librig2p-nostress\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "249eda8c-2d6b-48cf-9626-eda56f19d239",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.arrow_dataset.Dataset"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset_dict['lexicon_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e8aead54-bc3f-4530-847c-6a05eb3a8cfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# combine data splits in the lexicon \n",
    "# (as we are not training G2P, don't need train valid test splits)\n",
    "from datasets import concatenate_datasets\n",
    "datasets = [dataset_dict['lexicon_train'], dataset_dict['lexicon_valid'], dataset_dict['lexicon_test']]\n",
    "dataset = concatenate_datasets(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "70c388e9-2e51-422d-8b94-77b5fafbe853",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create dict of wordtype to pronunciation\n",
    "lexicon = {}\n",
    "for char, phn in zip(dataset['char'], dataset['phn']):\n",
    "    lexicon[char.lower().strip()] = phn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707abef2-051b-4bc0-bf86-5684c2833a58",
   "metadata": {},
   "source": [
    "# only consider the OOV words that are in the pronunciation lexicon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b72decc9-87b4-4eda-806e-5cef4f69383e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8343"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(oovs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "83a96a53-ed17-4a5c-aa60-c0bcab6e7d18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7966"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oovs_in_lexicon = oovs.intersection(lexicon.keys())\n",
    "len(oovs_in_lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f1aa82ff-84ca-4e60-87c0-3496aff8c1ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "377"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oovs_not_in_lexicon = oovs - oovs_in_lexicon\n",
    "len(oovs_not_in_lexicon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34dd0d5-2cdf-47f0-af4b-0d9b98ad960b",
   "metadata": {},
   "source": [
    "# Compare LibriG2P coverage against CMUdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bd87196e-338e-4689-9e7e-b5534de35811",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cmudict as cmudict_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f11b1079-a860-4dca-afce-8608328f9073",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cmudict = cmudict_module.dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b530de8-8fa4-439d-a381-c92b231b3e25",
   "metadata": {},
   "source": [
    "## normalise cmudict entries\n",
    "\n",
    "- key: all lowercase\n",
    "- values: phone strings should not hav any stress markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6126cb74-0db3-40a4-ad89-ffe80ddcc1f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys do not contain any capital letters\n"
     ]
    }
   ],
   "source": [
    "for wordtype in cmudict.keys():\n",
    "    if wordtype.isupper():\n",
    "        raise ValueError\n",
    "else:\n",
    "    print(\"Keys do not contain any capital letters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6af544c7-234c-4878-8229-b79982223d52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prons = cmudict['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a94850c0-8625-4e59-bfb2-68072d29c4ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['K', 'AA1', 'N', 'T', 'EH0', 'N', 'T'],\n",
       " ['K', 'AH0', 'N', 'T', 'EH1', 'N', 'T']]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e97b1308-08a8-4562-9576-146e361593cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['K', 'AA', 'N', 'T', 'EH', 'N', 'T']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def strip_stress(pron):\n",
    "    stripped_pron = []\n",
    "    for phn in pron:\n",
    "        stripped_pron.append(phn.strip('0123456789'))\n",
    "    return stripped_pron\n",
    "\n",
    "strip_stress(['K', 'AA1', 'N', 'T', 'EH0', 'N', 'T'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5f58fa18-1ed7-4713-87cf-ec9d7b05a4ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_cmudict = {}\n",
    "for wordtype, prons in cmudict.items():\n",
    "    new_prons = []\n",
    "    for pron in prons:\n",
    "        new_prons.append(strip_stress(pron))\n",
    "    new_cmudict[wordtype] = new_prons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bee5b91e-80c5-4768-a4ab-113443f57d38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cmudict = new_cmudict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3fea7d46-8a77-44d6-968c-88b0fb7e455f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['K', 'AA', 'N', 'T', 'EH', 'N', 'T'], ['K', 'AH', 'N', 'T', 'EH', 'N', 'T']]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmudict['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2647f2-ca47-4989-bafa-485e7b5a4a16",
   "metadata": {},
   "source": [
    "## find words in OOV list that are in CMUDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f752de63-9b0b-49e6-a368-5f148ac4dbad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8343"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(oovs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d4a56427-5032-492a-b3d9-d7c500db6125",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7233"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oovs_in_cmudict = oovs.intersection(cmudict.keys())\n",
    "len(oovs_in_cmudict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a7fc4864-d9ad-4bad-905f-d003cefbc1f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1110"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oovs_not_in_cmudict = oovs - oovs_in_cmudict\n",
    "len(oovs_not_in_cmudict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36042d3e-28bf-4031-8114-726b1b7bc8e5",
   "metadata": {},
   "source": [
    "## find OOVs not in LibriG2P or cmudict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6c81c154-225a-4e02-be9e-414dfa480ad6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "274"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oovs_not_in_cmudict_and_librig2p = oovs_not_in_cmudict.intersection(oovs_not_in_lexicon)\n",
    "len(oovs_not_in_cmudict_and_librig2p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9d5ad0d1-1c2a-400a-a667-cef66407a4c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accordez',\n",
       " 'adaptively',\n",
       " 'affectionless',\n",
       " 'afterwork',\n",
       " 'agardh',\n",
       " 'agencys',\n",
       " 'agonal',\n",
       " 'akermans',\n",
       " 'akkad',\n",
       " 'aldermens',\n",
       " 'alinement',\n",
       " 'aloman',\n",
       " 'amuhia',\n",
       " 'amylaceous',\n",
       " 'anabolism',\n",
       " 'arachtu',\n",
       " 'argool',\n",
       " 'arke',\n",
       " 'armys',\n",
       " 'arthor',\n",
       " 'askern',\n",
       " 'baddow',\n",
       " 'bagne',\n",
       " 'bamell',\n",
       " 'barbariously',\n",
       " 'bashour',\n",
       " 'batess',\n",
       " 'bbl',\n",
       " 'belian',\n",
       " 'billfolds',\n",
       " 'bodoni',\n",
       " 'bouhes',\n",
       " 'bradawls',\n",
       " 'bringuiers',\n",
       " 'bubbletop',\n",
       " 'buranelli',\n",
       " 'busdriver',\n",
       " 'buxtons',\n",
       " 'cabmans',\n",
       " 'caducibranchs',\n",
       " 'cannings',\n",
       " 'cardiotachyscope',\n",
       " 'catwalks',\n",
       " 'caunts',\n",
       " 'centurys',\n",
       " 'cerebrospinal',\n",
       " 'chaldasan',\n",
       " 'charae',\n",
       " 'chiselers',\n",
       " 'chromatin',\n",
       " 'chromatophores',\n",
       " 'chummage',\n",
       " 'cissian',\n",
       " 'citys',\n",
       " 'cleancutness',\n",
       " 'clipperton',\n",
       " 'collaborates',\n",
       " 'colsman',\n",
       " 'compters',\n",
       " 'conceptualisation',\n",
       " 'condigne',\n",
       " 'connallys',\n",
       " 'conveners',\n",
       " 'countrys',\n",
       " 'courtmartialed',\n",
       " 'crosshair',\n",
       " 'cutdowns',\n",
       " 'cyruss',\n",
       " 'daulby',\n",
       " 'daulbys',\n",
       " 'delarues',\n",
       " 'delustered',\n",
       " 'deoxidation',\n",
       " 'detre',\n",
       " 'diemens',\n",
       " 'dixblanc',\n",
       " 'dollimore',\n",
       " 'drittal',\n",
       " 'duranno',\n",
       " 'dustlike',\n",
       " 'dwyers',\n",
       " 'earthenwares',\n",
       " 'eightthirty',\n",
       " 'elevenfifty',\n",
       " 'eleventhirty',\n",
       " 'embryologists',\n",
       " 'endotracheal',\n",
       " 'entrapper',\n",
       " 'ervay',\n",
       " 'erythraean',\n",
       " 'experimentalize',\n",
       " 'fains',\n",
       " 'familiarization',\n",
       " 'familys',\n",
       " 'fassons',\n",
       " 'fenning',\n",
       " 'fivefifty',\n",
       " 'foregrip',\n",
       " 'fortyish',\n",
       " 'fourfifty',\n",
       " 'fourforty',\n",
       " 'fourthirty',\n",
       " 'ft',\n",
       " 'gardelle',\n",
       " 'gardelles',\n",
       " 'garotting',\n",
       " 'gatesmen',\n",
       " 'gobrias',\n",
       " 'godmanchester',\n",
       " 'gunmans',\n",
       " 'handprinting',\n",
       " 'hangmans',\n",
       " 'harlands',\n",
       " 'harrowbys',\n",
       " 'hematoma',\n",
       " 'henrichson',\n",
       " 'hidells',\n",
       " 'highchair',\n",
       " 'hindlimbs',\n",
       " 'histologist',\n",
       " 'hockers',\n",
       " 'huntons',\n",
       " 'hurchel',\n",
       " 'inanimated',\n",
       " 'intermediacy',\n",
       " 'jamess',\n",
       " 'jehoiakin',\n",
       " 'jensons',\n",
       " 'jermys',\n",
       " 'jumjuma',\n",
       " 'kellermans',\n",
       " 'kerp',\n",
       " 'ketchs',\n",
       " 'knurled',\n",
       " 'koldewey',\n",
       " 'kurrs',\n",
       " 'latonas',\n",
       " 'laverstock',\n",
       " 'lebizen',\n",
       " 'lecasser',\n",
       " 'leew',\n",
       " 'lennies',\n",
       " 'lerigos',\n",
       " 'linnie',\n",
       " 'liquorpond',\n",
       " 'lj',\n",
       " 'lld',\n",
       " 'lubbocks',\n",
       " 'lumpless',\n",
       " 'lyndal',\n",
       " 'macintoshs',\n",
       " 'manacling',\n",
       " 'marchesvan',\n",
       " 'marsolino',\n",
       " 'menobranchus',\n",
       " 'mentelin',\n",
       " 'meteyards',\n",
       " 'misemployment',\n",
       " 'misfires',\n",
       " 'misseurs',\n",
       " 'mohrenschildts',\n",
       " 'mps',\n",
       " 'murret',\n",
       " 'mvd',\n",
       " 'mwddy',\n",
       " 'neilds',\n",
       " 'nejef',\n",
       " 'newmans',\n",
       " 'ninethirty',\n",
       " 'nitrites',\n",
       " 'nonreferral',\n",
       " 'nutfield',\n",
       " 'officialy',\n",
       " 'omally',\n",
       " 'onefifteen',\n",
       " 'onefifty',\n",
       " 'oneforty',\n",
       " 'ontogenic',\n",
       " 'ordinarys',\n",
       " 'orientgesellschaft',\n",
       " 'orwells',\n",
       " 'oswaldskovitch',\n",
       " 'overconcentrated',\n",
       " 'pannartz',\n",
       " 'pegsworth',\n",
       " 'perennibranchs',\n",
       " 'phipoe',\n",
       " 'photosynthetic',\n",
       " 'phylogenic',\n",
       " 'piemen',\n",
       " 'plumule',\n",
       " 'praecipe',\n",
       " 'projectionist',\n",
       " 'propagandizing',\n",
       " 'prossa',\n",
       " 'protist',\n",
       " 'protista',\n",
       " 'protists',\n",
       " 'prusakova',\n",
       " 'pugnaciousness',\n",
       " 'punchmark',\n",
       " 'pushbutton',\n",
       " 'quigleys',\n",
       " 'reappropriate',\n",
       " 'recollectedness',\n",
       " 'redesdales',\n",
       " 'reemployed',\n",
       " 'reexpand',\n",
       " 'refaced',\n",
       " 'remands',\n",
       " 'romaness',\n",
       " 'roupells',\n",
       " 'rubeus',\n",
       " 'ryders',\n",
       " 'saffery',\n",
       " 'salsallat',\n",
       " 'satler',\n",
       " 'schizoid',\n",
       " 'schleidens',\n",
       " 'schwanns',\n",
       " 'selvages',\n",
       " 'sevenfifteen',\n",
       " 'seventhirty',\n",
       " 'sharings',\n",
       " 'shoestore',\n",
       " 'shroeder',\n",
       " 'sideposts',\n",
       " 'sinacherib',\n",
       " 'siredon',\n",
       " 'sixthirty',\n",
       " 'societys',\n",
       " 'spectrographic',\n",
       " 'stombaughs',\n",
       " 'stortford',\n",
       " 'stuckeys',\n",
       " 'swandown',\n",
       " 'sweynheim',\n",
       " 'tarpeys',\n",
       " 'taxonomic',\n",
       " 'tenforty',\n",
       " 'tenthirty',\n",
       " 'thistlewoods',\n",
       " 'thornleys',\n",
       " 'threetwenty',\n",
       " 'thurtells',\n",
       " 'toffana',\n",
       " 'toffania',\n",
       " 'tradescantia',\n",
       " 'treviranus',\n",
       " 'trisect',\n",
       " 'trotskyite',\n",
       " 'trulys',\n",
       " 'twelvefifteen',\n",
       " 'twofifteen',\n",
       " 'twoforty',\n",
       " 'twothirty',\n",
       " 'udalric',\n",
       " 'ultrarightists',\n",
       " 'unicellar',\n",
       " 'uninvested',\n",
       " 'unremedied',\n",
       " 'urological',\n",
       " 'vartos',\n",
       " 'vindelin',\n",
       " 'voebels',\n",
       " 'watto',\n",
       " 'wattss',\n",
       " 'weares',\n",
       " 'wiedersheim',\n",
       " 'wiedersheims',\n",
       " 'yardsman',\n",
       " 'zeiners',\n",
       " 'zoospores',\n",
       " 'zulueta'}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oovs_not_in_cmudict_and_librig2p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4c7cd34f-cd54-4587-b7ec-9e75934fd34a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import num2words\n",
    "from num2words import num2words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5c98f9d8-a5c5-4b5e-8add-07b5bc4cb9c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'twenty-five'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num2words(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2ed4a52a-dd92-4469-9306-f167b3b83fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = [num2words(i).strip('-') for i in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d42b6e66-6c20-482f-a98b-a30445d9dfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def does_not_contain_num(s):\n",
    "    for num in nums:\n",
    "        if num in s:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d490c1b7-b24d-43f6-8ff7-0fd7e3239a8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111 len(oovs_not_in_cmudict_and_librig2p)=274\n",
      "222 len(oovs_not_in_cmudict_and_librig2p)=268\n",
      "333 len(oovs_not_in_cmudict_and_librig2p)=246\n"
     ]
    }
   ],
   "source": [
    "## filter this list \n",
    "\n",
    "\n",
    "\n",
    "# word len\n",
    "print(f\"111 {len(oovs_not_in_cmudict_and_librig2p)=}\")\n",
    "oovs_not_in_cmudict_and_librig2p = set(w for w in oovs_not_in_cmudict_and_librig2p if len(w) >= 4)\n",
    "print(f\"222 {len(oovs_not_in_cmudict_and_librig2p)=}\")\n",
    "\n",
    "# not a number\n",
    "oovs_not_in_cmudict_and_librig2p = set(w for w in oovs_not_in_cmudict_and_librig2p if does_not_contain_num(w))\n",
    "print(f\"333 {len(oovs_not_in_cmudict_and_librig2p)=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d4ffe0-18e0-4303-b335-bb7d34e241be",
   "metadata": {},
   "source": [
    "# generate pronunciation for each word in the data used to train ASR/TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "38c9cdfa-868d-4cd2-8f1a-785305610298",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = '/home/s1785140/data/ljspeech_fastpitch/train_meta_half.txt'\n",
    "with open(train_data, 'r') as f:\n",
    "    train_data = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "eeb418f8-77b8-41f8-959f-1fcd5e93e465",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_utts = [l.split('|')[-1] for l in train_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a1c8b476-526c-41b5-89d1-c1d3c2bb52ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use text cleaner to clean each utt\n",
    "\n",
    "from fastpitch.common.text.cleaners import lowercase_no_punc as text_cleaner\n",
    "\n",
    "train_utts = [text_cleaner(utt) for utt in train_utts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bd2650cc-6de7-4dc5-9e0e-48a7e91d08c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5612"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_wordtypes = set()\n",
    "for utt in train_utts:\n",
    "    for token in utt.split(' '):\n",
    "        train_wordtypes.add(token)\n",
    "len(train_wordtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7e129cec-a993-4bdd-af32-cb0ae78f7592",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meanwhile',\n",
       " 'confronted',\n",
       " 'floors',\n",
       " 'ear',\n",
       " 'silence',\n",
       " 'pilot',\n",
       " 'residents',\n",
       " 'committal',\n",
       " 'ship',\n",
       " 'society',\n",
       " 'cuba',\n",
       " 'physiology',\n",
       " 'influences',\n",
       " 'successively',\n",
       " 'progress',\n",
       " 'proper',\n",
       " 'jail',\n",
       " 'convinced',\n",
       " 'rare',\n",
       " 'veil',\n",
       " 'school',\n",
       " 'accused',\n",
       " 'total',\n",
       " 'tablespoonful',\n",
       " 'excluded',\n",
       " 'communicate',\n",
       " 'contracted',\n",
       " 'stars',\n",
       " 'conceived',\n",
       " 'tyburn',\n",
       " 'mine',\n",
       " 'worked',\n",
       " 'talked',\n",
       " 'singing',\n",
       " 'short',\n",
       " 'delay',\n",
       " 'wait',\n",
       " 'rome',\n",
       " 'states',\n",
       " 'contemplated',\n",
       " 'connally',\n",
       " 'marksman',\n",
       " 'reply',\n",
       " 'holster',\n",
       " 'hall',\n",
       " 'revealed',\n",
       " 'july',\n",
       " 'sovereign',\n",
       " 'cooperate',\n",
       " 'highly',\n",
       " 'fines',\n",
       " 'prominently',\n",
       " 'colored',\n",
       " 'freedom',\n",
       " 'latest',\n",
       " 'connor',\n",
       " 'sport',\n",
       " 'pence',\n",
       " 'strangers',\n",
       " 'detain',\n",
       " 'safeguards',\n",
       " 'ground',\n",
       " 'negative',\n",
       " 'stone',\n",
       " 'infirmaries',\n",
       " 'learned',\n",
       " 'appeared',\n",
       " 'dioxide',\n",
       " 'realized',\n",
       " 'seemingly',\n",
       " 'killing',\n",
       " 'thereafter',\n",
       " 'defense',\n",
       " 'establishments',\n",
       " 'locate',\n",
       " 'greatest',\n",
       " 'gathered',\n",
       " 'missing',\n",
       " 'aperture',\n",
       " 'provides',\n",
       " 'hid',\n",
       " 'emerged',\n",
       " 'queen',\n",
       " 'cope',\n",
       " 'expect',\n",
       " 'accommodated',\n",
       " 'wholesale',\n",
       " 'categories',\n",
       " 'thirteen',\n",
       " 'liabilities',\n",
       " 'viewed',\n",
       " 'controlled',\n",
       " 'circulated',\n",
       " 'amateur',\n",
       " 'chaplain',\n",
       " 'protector',\n",
       " 'remaining',\n",
       " 'afford',\n",
       " 'characters',\n",
       " 'sift',\n",
       " 'least',\n",
       " 'gross',\n",
       " 'originated',\n",
       " 'r',\n",
       " 'neches',\n",
       " 'eighty',\n",
       " 'instruction',\n",
       " 'avenues',\n",
       " 'loses',\n",
       " 'adjusted',\n",
       " 'accommodation',\n",
       " 'as',\n",
       " 'attend',\n",
       " 'greer',\n",
       " 'act',\n",
       " 'urgent',\n",
       " 'quietly',\n",
       " 'eleventh',\n",
       " 'then',\n",
       " 'brought',\n",
       " 'axe',\n",
       " 'injurious',\n",
       " 'assurance',\n",
       " 'drove',\n",
       " 'precedent',\n",
       " 'neck',\n",
       " 'proceeding',\n",
       " 'cities',\n",
       " 'companys',\n",
       " 'shape',\n",
       " 'rash',\n",
       " 'concomitant',\n",
       " 'governor',\n",
       " 'equipment',\n",
       " 'difficult',\n",
       " 'cheap',\n",
       " 'written',\n",
       " 'legislative',\n",
       " 'lamar',\n",
       " 'practical',\n",
       " 'proof',\n",
       " 'training',\n",
       " 'arduous',\n",
       " 'scheduled',\n",
       " 'hartogs',\n",
       " 'oxenford',\n",
       " 'hanged',\n",
       " 'encouraged',\n",
       " 'faced',\n",
       " 'reforms',\n",
       " 'struggle',\n",
       " 'franklin',\n",
       " 'proportion',\n",
       " 'dwyer',\n",
       " 'happened',\n",
       " 'extremity',\n",
       " 'ikey',\n",
       " 'carter',\n",
       " 'work',\n",
       " 'matter',\n",
       " 'supposition',\n",
       " 'diagnosis',\n",
       " 'assume',\n",
       " 'cetera',\n",
       " 'seventy',\n",
       " 'knew',\n",
       " 'prevailing',\n",
       " 'points',\n",
       " 'court',\n",
       " 'absorbing',\n",
       " 'boston',\n",
       " 'dealt',\n",
       " 'extremely',\n",
       " 'chester',\n",
       " 'necessary',\n",
       " 'rule',\n",
       " 'doomed',\n",
       " 'reconstruct',\n",
       " 'simultaneously',\n",
       " 'habits',\n",
       " 'glad',\n",
       " 'anyone',\n",
       " 'meager',\n",
       " 'thou',\n",
       " 'austin',\n",
       " 'requiring',\n",
       " 'permanent',\n",
       " 'san',\n",
       " 'assassinate',\n",
       " 'personal',\n",
       " 'command',\n",
       " 'dropped',\n",
       " 'telescopic',\n",
       " 'begun',\n",
       " 'carefully',\n",
       " 'whose',\n",
       " 'resembled',\n",
       " 'well',\n",
       " 'appeal',\n",
       " 'corn',\n",
       " 'krapps',\n",
       " 'wakefield',\n",
       " 'didn',\n",
       " 'locomotive',\n",
       " 'watch',\n",
       " 'occasional',\n",
       " 'calmly',\n",
       " 'pension',\n",
       " 'warned',\n",
       " 'tending',\n",
       " 'northeast',\n",
       " 'redpaths',\n",
       " 'possible',\n",
       " 'voyage',\n",
       " 'stemmons',\n",
       " 'wages',\n",
       " 'keeping',\n",
       " 'pursued',\n",
       " 'movable',\n",
       " 'luxury',\n",
       " 'sort',\n",
       " 'presents',\n",
       " 'looking',\n",
       " 'approver',\n",
       " 'deeds',\n",
       " 'friends',\n",
       " 'crowds',\n",
       " 'location',\n",
       " 'alerted',\n",
       " 'story',\n",
       " 'markhams',\n",
       " 'duplicate',\n",
       " 'contamination',\n",
       " 'future',\n",
       " 'lift',\n",
       " 'committing',\n",
       " 'coupled',\n",
       " 'complicity',\n",
       " 'sebastian',\n",
       " 'autopsy',\n",
       " 'escaped',\n",
       " 'en',\n",
       " 'divine',\n",
       " 'probably',\n",
       " 'spoken',\n",
       " 'repulsive',\n",
       " 'arrested',\n",
       " 'manning',\n",
       " 'november',\n",
       " 'prime',\n",
       " 'agitated',\n",
       " 'watches',\n",
       " 'lads',\n",
       " 'always',\n",
       " 'murderers',\n",
       " 'walkers',\n",
       " 'began',\n",
       " 'immediate',\n",
       " 'specific',\n",
       " 'hang',\n",
       " 'precise',\n",
       " 'suggesting',\n",
       " 'fibers',\n",
       " 'encounter',\n",
       " 'operating',\n",
       " 'prs',\n",
       " 'cottage',\n",
       " 'writer',\n",
       " 'information',\n",
       " 'servants',\n",
       " 'superfluous',\n",
       " 'wilson',\n",
       " 'denial',\n",
       " 'saying',\n",
       " 'thigh',\n",
       " 'bar',\n",
       " 'imgur',\n",
       " 'recovered',\n",
       " 'accordance',\n",
       " 'inspired',\n",
       " 'disclosed',\n",
       " 'sharp',\n",
       " 'landed',\n",
       " 'putting',\n",
       " 'signed',\n",
       " 'shown',\n",
       " 'phenomena',\n",
       " 'thistlewood',\n",
       " 'exaggerated',\n",
       " 'severity',\n",
       " 'pictures',\n",
       " 'suggestions',\n",
       " 'delivered',\n",
       " 'payment',\n",
       " 'weigh',\n",
       " 'growth',\n",
       " 'lineup',\n",
       " 'call',\n",
       " 'robson',\n",
       " 'emphasized',\n",
       " 'answered',\n",
       " 'mounted',\n",
       " 'agency',\n",
       " 'fiber',\n",
       " 'firecracker',\n",
       " 'release',\n",
       " 'improvements',\n",
       " 'carcano',\n",
       " 'bankes',\n",
       " 'major',\n",
       " 'called',\n",
       " 'pledged',\n",
       " 'maintain',\n",
       " 'improved',\n",
       " 'opposite',\n",
       " 'care',\n",
       " 'brothers',\n",
       " 'practically',\n",
       " 'dock',\n",
       " 'referred',\n",
       " 'stripped',\n",
       " 'conception',\n",
       " 'carriage',\n",
       " 'replaced',\n",
       " 'follow',\n",
       " 'palmer',\n",
       " 'job',\n",
       " 'voebel',\n",
       " 'multitude',\n",
       " 'checked',\n",
       " 'different',\n",
       " 'watching',\n",
       " 'associations',\n",
       " 'inquired',\n",
       " 'presented',\n",
       " 'starchy',\n",
       " 'edgar',\n",
       " 'truck',\n",
       " 'departure',\n",
       " 'quote',\n",
       " 'base',\n",
       " 'corporation',\n",
       " 'keeper',\n",
       " 'sifted',\n",
       " 'spare',\n",
       " 'confident',\n",
       " 'confirmed',\n",
       " 'markham',\n",
       " 'stream',\n",
       " 'while',\n",
       " 'constituents',\n",
       " 'previous',\n",
       " 'dated',\n",
       " 'privy',\n",
       " 'policeman',\n",
       " 'trading',\n",
       " 'deliberate',\n",
       " 'arm',\n",
       " 'gibbet',\n",
       " 'recognized',\n",
       " 'hundreds',\n",
       " 'cut',\n",
       " 'remainder',\n",
       " 'actually',\n",
       " 'mainly',\n",
       " 'silent',\n",
       " 'digestive',\n",
       " 'severely',\n",
       " 'productive',\n",
       " 'told',\n",
       " 'issue',\n",
       " 'shaken',\n",
       " 'intensive',\n",
       " 'trigger',\n",
       " 'business',\n",
       " 'underlying',\n",
       " 'satisfied',\n",
       " 'recall',\n",
       " 'towers',\n",
       " 'serve',\n",
       " 'them',\n",
       " 'argued',\n",
       " 'gains',\n",
       " 'bare',\n",
       " 'special',\n",
       " 'it',\n",
       " 'approximately',\n",
       " 'zipper',\n",
       " 'shillings',\n",
       " 'threatened',\n",
       " 'withdrawn',\n",
       " 'must',\n",
       " 'likeness',\n",
       " 'reproduced',\n",
       " 'minute',\n",
       " 'questioned',\n",
       " 'frames',\n",
       " 'wallace',\n",
       " 'nation',\n",
       " 're',\n",
       " 'luck',\n",
       " 'fingerprint',\n",
       " 'offenders',\n",
       " 'hours',\n",
       " 'pulled',\n",
       " 'bel',\n",
       " 'scanned',\n",
       " 'dougherty',\n",
       " 'green',\n",
       " 'mandella',\n",
       " 'belonged',\n",
       " 'furnished',\n",
       " 'elimination',\n",
       " 'locally',\n",
       " 'discussions',\n",
       " 'depends',\n",
       " 'part',\n",
       " 'see',\n",
       " 'senate',\n",
       " 'moses',\n",
       " 'amongst',\n",
       " 'contempt',\n",
       " 'guy',\n",
       " 'getting',\n",
       " 'orphans',\n",
       " 'safety',\n",
       " 'conscience',\n",
       " 'tool',\n",
       " 'workers',\n",
       " 'broader',\n",
       " 'sixty',\n",
       " 'forging',\n",
       " 'narrative',\n",
       " 'broke',\n",
       " 'missed',\n",
       " 'scanning',\n",
       " 'shame',\n",
       " 'destiny',\n",
       " 'husbands',\n",
       " 'maintaining',\n",
       " 'succeed',\n",
       " 'brutal',\n",
       " 'acceptance',\n",
       " 'sheriffs',\n",
       " 'takes',\n",
       " 'plot',\n",
       " 'owner',\n",
       " 'penal',\n",
       " 'communist',\n",
       " 'plans',\n",
       " 'wild',\n",
       " 'ruins',\n",
       " 'reprieve',\n",
       " 'science',\n",
       " 'deprived',\n",
       " 'masters',\n",
       " 'submitted',\n",
       " 'charged',\n",
       " 'intelligence',\n",
       " 'conclusions',\n",
       " 'institutions',\n",
       " 'complaint',\n",
       " 'interview',\n",
       " 'suitable',\n",
       " 'overpasses',\n",
       " 'resting',\n",
       " 'quickly',\n",
       " 'fate',\n",
       " 'victims',\n",
       " 'supporting',\n",
       " 'whaley',\n",
       " 'conveniently',\n",
       " 'sources',\n",
       " 'escort',\n",
       " 'donnell',\n",
       " 'service',\n",
       " 'requested',\n",
       " 'corners',\n",
       " 'rely',\n",
       " 'completed',\n",
       " 'motivation',\n",
       " 'admission',\n",
       " 'persons',\n",
       " 'unemployment',\n",
       " 'zopyrus',\n",
       " 'civil',\n",
       " 'separate',\n",
       " 'northern',\n",
       " 'advising',\n",
       " 'separated',\n",
       " 'codes',\n",
       " 'accounted',\n",
       " 'through',\n",
       " 'yellow',\n",
       " 'sporting',\n",
       " 'verify',\n",
       " 'affecting',\n",
       " 'circulation',\n",
       " 'amounted',\n",
       " 'directly',\n",
       " 'post',\n",
       " 'administered',\n",
       " 'soviet',\n",
       " 'remain',\n",
       " 'calculated',\n",
       " 'function',\n",
       " 'controversy',\n",
       " 'once',\n",
       " 'added',\n",
       " 'bread',\n",
       " 'privilege',\n",
       " 'thy',\n",
       " 'agree',\n",
       " 'recently',\n",
       " 'closest',\n",
       " 'peaceful',\n",
       " 'commons',\n",
       " 'objective',\n",
       " 'remarks',\n",
       " 'classification',\n",
       " 'genuine',\n",
       " 'chatham',\n",
       " 'manager',\n",
       " 'revision',\n",
       " 'concrete',\n",
       " 'heaviest',\n",
       " 'framers',\n",
       " 'judges',\n",
       " 'outside',\n",
       " 'circumstance',\n",
       " 'supposed',\n",
       " 'dignity',\n",
       " 'hair',\n",
       " 'perennibranch',\n",
       " 'january',\n",
       " 'remarkable',\n",
       " 'theatre',\n",
       " 'purchases',\n",
       " 'appropriate',\n",
       " 'plate',\n",
       " 'museum',\n",
       " 'whereabouts',\n",
       " 'non',\n",
       " 'whereupon',\n",
       " 'rights',\n",
       " 'effect',\n",
       " 'instruments',\n",
       " 'packing',\n",
       " 'statements',\n",
       " 'reconstructed',\n",
       " 'highest',\n",
       " 'arms',\n",
       " 'prayer',\n",
       " 'protested',\n",
       " 'hideel',\n",
       " 'deemed',\n",
       " 'cell',\n",
       " 'diffusion',\n",
       " 'extraordinary',\n",
       " 'surgeon',\n",
       " 'substantially',\n",
       " 'bedroom',\n",
       " 'heart',\n",
       " 'operation',\n",
       " 'visited',\n",
       " 'dining',\n",
       " 'administration',\n",
       " 'compelled',\n",
       " 'diamonds',\n",
       " 'provide',\n",
       " 'considering',\n",
       " 'embark',\n",
       " 'rod',\n",
       " 'took',\n",
       " 'fault',\n",
       " 'foregoing',\n",
       " 'inspector',\n",
       " 'everyone',\n",
       " 'allow',\n",
       " 'transportation',\n",
       " 'slowly',\n",
       " 'live',\n",
       " 'risen',\n",
       " 'help',\n",
       " 'included',\n",
       " 'lie',\n",
       " 'hunt',\n",
       " 'edmunds',\n",
       " 'intoxicating',\n",
       " 'albert',\n",
       " 'riotous',\n",
       " 'compared',\n",
       " 'boys',\n",
       " 'basic',\n",
       " 'owners',\n",
       " 'pointed',\n",
       " 'prolonged',\n",
       " 'conclusion',\n",
       " 'trot',\n",
       " 'stombaugh',\n",
       " 'rises',\n",
       " 'indication',\n",
       " 'plates',\n",
       " 'manufactured',\n",
       " 'crank',\n",
       " 'constituted',\n",
       " 'quantity',\n",
       " 'honestly',\n",
       " 'ride',\n",
       " 'promptly',\n",
       " 'expensive',\n",
       " 'speculations',\n",
       " 'arthur',\n",
       " 'slack',\n",
       " 'hostile',\n",
       " 'allotment',\n",
       " 'at',\n",
       " 'sorts',\n",
       " 'exact',\n",
       " 'yeoman',\n",
       " 'buxton',\n",
       " 'blank',\n",
       " 'thoroughly',\n",
       " 'unknown',\n",
       " 'stopped',\n",
       " 'comes',\n",
       " 'father',\n",
       " 'that',\n",
       " 'result',\n",
       " 'further',\n",
       " 'kellerman',\n",
       " 'consecutive',\n",
       " 'vital',\n",
       " 'hosty',\n",
       " 'weekend',\n",
       " 'rent',\n",
       " 'living',\n",
       " 'commissions',\n",
       " 'parade',\n",
       " 'assumed',\n",
       " 'leader',\n",
       " 'taking',\n",
       " 'present',\n",
       " 'often',\n",
       " 'vertebrates',\n",
       " 'ventilation',\n",
       " 'inquest',\n",
       " 'capacity',\n",
       " 'abroad',\n",
       " 'attendant',\n",
       " 'vestibule',\n",
       " 'defection',\n",
       " 'fellows',\n",
       " 'majesty',\n",
       " 'cavity',\n",
       " 'marylebone',\n",
       " 'minds',\n",
       " 'stairwell',\n",
       " 'has',\n",
       " 'burning',\n",
       " 'presidential',\n",
       " 'readers',\n",
       " 'buildings',\n",
       " 'callaway',\n",
       " 'companion',\n",
       " 'boxes',\n",
       " 'sermon',\n",
       " 'expecting',\n",
       " 'premises',\n",
       " 'quick',\n",
       " 'file',\n",
       " 'clarence',\n",
       " 'land',\n",
       " 'insure',\n",
       " 'fascist',\n",
       " 'confession',\n",
       " 'names',\n",
       " 'simply',\n",
       " 'mark',\n",
       " 'likely',\n",
       " 'triangle',\n",
       " 'palmprint',\n",
       " 'strength',\n",
       " 'kennedy',\n",
       " 'study',\n",
       " 'christian',\n",
       " 'traffic',\n",
       " 'underpass',\n",
       " 'seven',\n",
       " 'undergone',\n",
       " 'perform',\n",
       " 'regard',\n",
       " 'thence',\n",
       " 'solitary',\n",
       " 'presence',\n",
       " 'natural',\n",
       " 'indignation',\n",
       " 'steam',\n",
       " 'married',\n",
       " 'witness',\n",
       " 'objected',\n",
       " 'freely',\n",
       " 'estate',\n",
       " 'wainwright',\n",
       " 'insolvent',\n",
       " 'value',\n",
       " 'roles',\n",
       " 'take',\n",
       " 'large',\n",
       " 'willing',\n",
       " 'increased',\n",
       " 'indexed',\n",
       " 'suspicious',\n",
       " 'colony',\n",
       " 'fund',\n",
       " 'handkerchief',\n",
       " 'span',\n",
       " 'beds',\n",
       " 'disturbed',\n",
       " 'visitors',\n",
       " 'gained',\n",
       " 'devotion',\n",
       " 'century',\n",
       " 'tend',\n",
       " 'numbers',\n",
       " 'gunshot',\n",
       " 'night',\n",
       " 'wesley',\n",
       " 'equipped',\n",
       " 'employers',\n",
       " 'deny',\n",
       " 'overcrowding',\n",
       " 'reid',\n",
       " 'fellow',\n",
       " 'seriousness',\n",
       " 'do',\n",
       " 'custom',\n",
       " 'exchanged',\n",
       " 'diverse',\n",
       " 'improperly',\n",
       " 'occupants',\n",
       " 'japan',\n",
       " 'leicester',\n",
       " 'complex',\n",
       " 'malcolm',\n",
       " 'murders',\n",
       " 'publications',\n",
       " 'traders',\n",
       " 'identical',\n",
       " 'shotgun',\n",
       " 'visits',\n",
       " 'upon',\n",
       " 'muscles',\n",
       " 'liquid',\n",
       " 'bouck',\n",
       " 'failing',\n",
       " 'clerks',\n",
       " 'cold',\n",
       " 'sheriff',\n",
       " 'impregnable',\n",
       " 'parallel',\n",
       " 'stretcher',\n",
       " 'alleged',\n",
       " 'york',\n",
       " 'pale',\n",
       " 'enormous',\n",
       " 'qualifications',\n",
       " 'creditors',\n",
       " 'fry',\n",
       " 'fast',\n",
       " 'buell',\n",
       " 'events',\n",
       " 'various',\n",
       " 'burglary',\n",
       " 'chest',\n",
       " 'turning',\n",
       " 'or',\n",
       " 'indicate',\n",
       " 'chance',\n",
       " 'beaten',\n",
       " 'generally',\n",
       " 'uniformity',\n",
       " 'horsemonger',\n",
       " 'fees',\n",
       " 'confederate',\n",
       " 'explained',\n",
       " 'experienced',\n",
       " 'gin',\n",
       " 'responded',\n",
       " 'bedsteads',\n",
       " 'repeat',\n",
       " 'wrapped',\n",
       " 'profit',\n",
       " 'chose',\n",
       " 'impress',\n",
       " 'acting',\n",
       " 'leaf',\n",
       " 'score',\n",
       " 'stolen',\n",
       " 'heavily',\n",
       " 'pushed',\n",
       " 'more',\n",
       " 'foothold',\n",
       " 'acquitted',\n",
       " 'formed',\n",
       " 'lap',\n",
       " 'caliber',\n",
       " 'goes',\n",
       " 'coin',\n",
       " 'plants',\n",
       " 'notion',\n",
       " 'reputed',\n",
       " 'contract',\n",
       " 'thin',\n",
       " 'impenitent',\n",
       " 'faith',\n",
       " 'exempted',\n",
       " 'blanket',\n",
       " 'regulations',\n",
       " 'poverty',\n",
       " 'print',\n",
       " 'stain',\n",
       " 'before',\n",
       " 'custody',\n",
       " 'adlai',\n",
       " 'wales',\n",
       " 'varied',\n",
       " 'latona',\n",
       " 'receipt',\n",
       " 'afterwards',\n",
       " 'burkley',\n",
       " 'abolished',\n",
       " 'beings',\n",
       " 'suppress',\n",
       " 'regular',\n",
       " 'marina',\n",
       " 'extended',\n",
       " 'hopeless',\n",
       " 'background',\n",
       " 'lawn',\n",
       " 'apparent',\n",
       " 'amount',\n",
       " 'suspended',\n",
       " 'placement',\n",
       " 'division',\n",
       " 'series',\n",
       " 'identity',\n",
       " 'concluded',\n",
       " 'drawing',\n",
       " 'subscription',\n",
       " 'uneasy',\n",
       " 'culpable',\n",
       " 'pronounced',\n",
       " 'ruth',\n",
       " 'knocked',\n",
       " 'deplorable',\n",
       " 'parades',\n",
       " 'prohibited',\n",
       " 'rapid',\n",
       " 'cummings',\n",
       " 'lets',\n",
       " 'clubs',\n",
       " 'sailor',\n",
       " 'potential',\n",
       " 'misdemeanants',\n",
       " 'flight',\n",
       " 'bleeding',\n",
       " 'maximum',\n",
       " 'preceding',\n",
       " 'fist',\n",
       " 'associate',\n",
       " 'rose',\n",
       " 'talk',\n",
       " 'complain',\n",
       " 'contributed',\n",
       " 'pressure',\n",
       " 'fish',\n",
       " 'light',\n",
       " 'american',\n",
       " 'organizations',\n",
       " 'decided',\n",
       " 'miles',\n",
       " 'coming',\n",
       " 'plainly',\n",
       " 'traced',\n",
       " 'fabrication',\n",
       " 'falsely',\n",
       " 'southwesterly',\n",
       " 'registrar',\n",
       " 'twenty',\n",
       " 'pair',\n",
       " 'habit',\n",
       " 'miscreant',\n",
       " 'rifling',\n",
       " 'phone',\n",
       " 'patient',\n",
       " 'sorry',\n",
       " 'visit',\n",
       " 'calling',\n",
       " 'completely',\n",
       " 'distribution',\n",
       " 'dirty',\n",
       " 'turns',\n",
       " 'complexion',\n",
       " 'running',\n",
       " 'inclined',\n",
       " 'anything',\n",
       " 'held',\n",
       " 'certainly',\n",
       " 'accepted',\n",
       " 'cooperation',\n",
       " 'calcrafts',\n",
       " 'dasset',\n",
       " 'positively',\n",
       " 'millions',\n",
       " 'sixpence',\n",
       " 'operates',\n",
       " 'shortly',\n",
       " 'prescribed',\n",
       " 'gun',\n",
       " 'federal',\n",
       " 'rebuilt',\n",
       " 'surveys',\n",
       " 'mature',\n",
       " 'solomons',\n",
       " 'exercised',\n",
       " 'chimney',\n",
       " 'minimum',\n",
       " 'paines',\n",
       " 'adequacy',\n",
       " 'discipline',\n",
       " 'uttered',\n",
       " 'strychnia',\n",
       " 'lead',\n",
       " 'males',\n",
       " 'without',\n",
       " 'city',\n",
       " 'cartons',\n",
       " 'interviewed',\n",
       " 'line',\n",
       " 'anywhere',\n",
       " 'sweep',\n",
       " 'official',\n",
       " 'declaration',\n",
       " 'requirements',\n",
       " 'easily',\n",
       " 'wise',\n",
       " 'straw',\n",
       " 'beckley',\n",
       " 'infantry',\n",
       " 'eyes',\n",
       " 'offenses',\n",
       " 'chambers',\n",
       " 'three',\n",
       " 'thwart',\n",
       " 'sealed',\n",
       " 'unfair',\n",
       " 'joined',\n",
       " 'passive',\n",
       " 'parked',\n",
       " 'protecting',\n",
       " 'planning',\n",
       " 'accompanied',\n",
       " 'system',\n",
       " 'actively',\n",
       " 'excess',\n",
       " 'informal',\n",
       " 'relief',\n",
       " 'distinctive',\n",
       " 'step',\n",
       " 'jumped',\n",
       " 'stating',\n",
       " 'fain',\n",
       " 'trauma',\n",
       " 'interim',\n",
       " 'exposure',\n",
       " 'body',\n",
       " 'warren',\n",
       " 'designated',\n",
       " 'awaiting',\n",
       " 'magazines',\n",
       " 'can',\n",
       " 'opportunities',\n",
       " 'us',\n",
       " 'assist',\n",
       " 'wainwrights',\n",
       " 'wrote',\n",
       " 'intimate',\n",
       " 'euins',\n",
       " 'conditions',\n",
       " 'shipped',\n",
       " 'fight',\n",
       " 'impelled',\n",
       " 'substitute',\n",
       " 'bent',\n",
       " 'shoulder',\n",
       " 'life',\n",
       " 'inserted',\n",
       " 'adjacent',\n",
       " 'validity',\n",
       " ...}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_wordtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "feff57cc-0706-422c-a508-a405b989d608",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are  5431  training wordtypes in cmudict\n"
     ]
    }
   ],
   "source": [
    "print(\"there are \", len(train_wordtypes.intersection(set(cmudict.keys()))),\" training wordtypes in cmudict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f3513b9d-e990-4630-b30d-cc44d0ad9026",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use cmudict to get pronunciation for train wordtypes\n",
    "\n",
    "train_wordtype2pron = {}\n",
    "for w in train_wordtypes.intersection(set(cmudict.keys())):\n",
    "    train_wordtype2pron[w] = cmudict[w][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3945c495-fd86-4738-ad93-dcbbbf8d68cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use G2P to predict pronunciations for wordtypes in training set but not in cmudict\n",
    "\n",
    "from speechbrain.pretrained import GraphemeToPhoneme\n",
    "g2p = GraphemeToPhoneme.from_hparams(\"speechbrain/soundchoice-g2p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5646b2b5-00ae-49e5-9621-bea7479db5ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                             | 0/181 [00:00<?, ?it/s]Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|| 181/181 [00:50<00:00,  3.58it/s]\n"
     ]
    }
   ],
   "source": [
    "for w in tqdm(train_wordtypes - set(cmudict.keys())):\n",
    "    train_wordtype2pron[w] = g2p(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d166cb-c951-423a-ad02-7be349eb179b",
   "metadata": {},
   "source": [
    "##save pron dict to disk\n",
    "\n",
    "in two formats\n",
    "- generic\n",
    "- for training G2P model (https://pypi.org/project/phonetisaurus/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b8b742af-4180-47c6-bf9b-7ba227ae3814",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generic\n",
    "with open('/home/s1785140/data/ljspeech_fastpitch/train_meta_half_pron_dict.json', 'w') as f:\n",
    "    json.dump(train_wordtype2pron, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c943b94a-c16a-45df-a598-dc3e406aa8fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for G2P training\n",
    "#/path/to/lexicon.dict\n",
    "#lexicon format:\n",
    "#word1 phoneme1 phoneme2 ...\n",
    "#word2 phoneme1 phoneme2 phoneme3 ...\n",
    "g2p_training_lexicon_lines = []\n",
    "for w, pron in train_wordtype2pron.items():\n",
    "    l = f\"{w} {' '.join(pron)}\"\n",
    "    g2p_training_lexicon_lines.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "672819e3-f81a-4467-b902-fcfb2305d509",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'meanwhile M IY N W AY L'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g2p_training_lexicon_lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a2e62ae8-4475-493e-b659-7f942e86d0a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('/home/s1785140/data/ljspeech_fastpitch/train_meta_half_prons_for_training_g2p.dict', 'w') as f:\n",
    "    f.write('\\n'.join(g2p_training_lexicon_lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a8019a-dc36-4aa5-ac32-3519f308d347",
   "metadata": {},
   "source": [
    "# Train G2P model using only wordtypes contained in data used to train TTS/ASR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a73d6103-4958-47c3-9c40-36050386c7e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[94mINFO:phonetisaurus-train:2023-03-16 12:02:32\u001b[0m:  Checking command configuration...\n",
      "\u001b[94mDEBUG:phonetisaurus-train:2023-03-16 12:02:32\u001b[0m:  Directory does not exist.  Trying to create.\n",
      "\u001b[94mINFO:phonetisaurus-train:2023-03-16 12:02:32\u001b[0m:  Checking lexicon for reserved characters: '}', '|', '_'...\n",
      "\u001b[94mDEBUG:phonetisaurus-train:2023-03-16 12:02:32\u001b[0m:  arpa_path:  train/model.o8.arpa\n",
      "\u001b[94mDEBUG:phonetisaurus-train:2023-03-16 12:02:32\u001b[0m:  corpus_path:  train/model.corpus\n",
      "\u001b[94mDEBUG:phonetisaurus-train:2023-03-16 12:02:32\u001b[0m:  dir_prefix:  train\n",
      "\u001b[94mDEBUG:phonetisaurus-train:2023-03-16 12:02:32\u001b[0m:  grow:  False\n",
      "\u001b[94mDEBUG:phonetisaurus-train:2023-03-16 12:02:32\u001b[0m:  lexicon_file:  /tmp/tmp3u_61cdi.txt\n",
      "\u001b[94mDEBUG:phonetisaurus-train:2023-03-16 12:02:32\u001b[0m:  logger:  <Logger phonetisaurus-train (DEBUG)>\n",
      "\u001b[94mDEBUG:phonetisaurus-train:2023-03-16 12:02:32\u001b[0m:  makeJointNgramCommand:  <bound method G2PModelTrainer._mitlm of <__main__.G2PModelTrainer object at 0x7f5112c47580>>\n",
      "\u001b[94mDEBUG:phonetisaurus-train:2023-03-16 12:02:32\u001b[0m:  model_path:  train/model.fst\n",
      "\u001b[94mDEBUG:phonetisaurus-train:2023-03-16 12:02:32\u001b[0m:  model_prefix:  model\n",
      "\u001b[94mDEBUG:phonetisaurus-train:2023-03-16 12:02:32\u001b[0m:  ngram_order:  8\n",
      "\u001b[94mDEBUG:phonetisaurus-train:2023-03-16 12:02:32\u001b[0m:  seq1_del:  False\n",
      "\u001b[94mDEBUG:phonetisaurus-train:2023-03-16 12:02:32\u001b[0m:  seq1_max:  2\n",
      "\u001b[94mDEBUG:phonetisaurus-train:2023-03-16 12:02:32\u001b[0m:  seq2_del:  True\n",
      "\u001b[94mDEBUG:phonetisaurus-train:2023-03-16 12:02:32\u001b[0m:  seq2_max:  2\n",
      "\u001b[94mDEBUG:phonetisaurus-train:2023-03-16 12:02:32\u001b[0m:  verbose:  True\n",
      "\u001b[94mDEBUG:phonetisaurus-train:2023-03-16 12:02:32\u001b[0m:  phonetisaurus-align --input=/tmp/tmp3u_61cdi.txt --ofile=train/model.corpus --seq1_del=false --seq2_del=true --seq1_max=2 --seq2_max=2 --grow=false\n",
      "\u001b[94mINFO:phonetisaurus-train:2023-03-16 12:02:32\u001b[0m:  Aligning lexicon...\n",
      "GitRevision: package\n",
      "Loading input file: /tmp/tmp3u_61cdi.txt\n",
      "Alignment failed: e t c\n",
      "Alignment failed: w\n",
      "Alignment failed: x\n",
      "Starting EM...\n",
      "Finished first iter...\n",
      "Iteration: 1 Change: 2.71209\n",
      "Iteration: 2 Change: 0.0541773\n",
      "Iteration: 3 Change: 0.0442581\n",
      "Iteration: 4 Change: 0.0254421\n",
      "Iteration: 5 Change: 0.0151958\n",
      "Iteration: 6 Change: 0.00968266\n",
      "Iteration: 7 Change: 0.00611591\n",
      "Iteration: 8 Change: 0.00387478\n",
      "Iteration: 9 Change: 0.00291252\n",
      "Iteration: 10 Change: 0.00222397\n",
      "Iteration: 11 Change: 0.00181007\n",
      "Last iteration: \n",
      "\u001b[94mDEBUG:phonetisaurus-train:2023-03-16 12:02:43\u001b[0m:  estimate-ngram -o 8 -t train/model.corpus -wl train/model.o8.arpa\n",
      "\u001b[94mINFO:phonetisaurus-train:2023-03-16 12:02:43\u001b[0m:  Training joint ngram model...\n",
      "0.001\tLoading corpus train/model.corpus...\n",
      "0.040\tSmoothing[1] = ModKN\n",
      "0.040\tSmoothing[2] = ModKN\n",
      "0.040\tSmoothing[3] = ModKN\n",
      "0.040\tSmoothing[4] = ModKN\n",
      "0.040\tSmoothing[5] = ModKN\n",
      "0.040\tSmoothing[6] = ModKN\n",
      "0.040\tSmoothing[7] = ModKN\n",
      "0.040\tSmoothing[8] = ModKN\n",
      "0.040\tSet smoothing algorithms...\n",
      "0.040\tY 6.069364e-01\n",
      "0.040\tY 5.840928e-01\n",
      "0.040\tY 6.877445e-01\n",
      "0.041\tY 7.750290e-01\n",
      "0.041\tY 8.287713e-01\n",
      "0.041\tY 8.705026e-01\n",
      "0.042\tY 8.972407e-01\n",
      "0.042\tY 8.423971e-01\n",
      "0.042\tEstimating full n-gram model...\n",
      "0.044\tSaving LM to train/model.o8.arpa...\n",
      "\u001b[94mDEBUG:phonetisaurus-train:2023-03-16 12:02:43\u001b[0m:  phonetisaurus-arpa2wfst --lm=train/model.o8.arpa --ofile=train/model.fst\n",
      "\u001b[94mINFO:phonetisaurus-train:2023-03-16 12:02:43\u001b[0m:  Converting ARPA format joint n-gram model to WFST format...\n",
      "GitRevision: package\n",
      "Initializing...\n",
      "Converting...\n",
      "\u001b[94mINFO:phonetisaurus-train:2023-03-16 12:02:44\u001b[0m:  G2P training succeeded: \u001b[92mtrain/model.fst\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['phonetisaurus', 'train', '--model', '/home/s1785140/data/ljspeech_fastpitch/train_meta_half_phonetisaurusG2P_model.fst', '/home/s1785140/data/ljspeech_fastpitch/train_meta_half_prons_for_training_g2p.dict'], returncode=0)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "subprocess.run([\"phonetisaurus\",\n",
    "                \"train\",\n",
    "                \"--model\", \n",
    "                \"/home/s1785140/data/ljspeech_fastpitch/train_meta_half_phonetisaurusG2P_model.fst\",\n",
    "                \"/home/s1785140/data/ljspeech_fastpitch/train_meta_half_prons_for_training_g2p.dict\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da5bab3-547c-418d-a680-f2d2234d2ab6",
   "metadata": {},
   "source": [
    "# demonstrate how to run trained G2P model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b22bee4c-9383-46c0-b913-b3966eb2fb6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# to stop warning\n",
    "import os\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "\n",
    "shell_cmd = [\n",
    "    \"phonetisaurus\",\n",
    "    \"predict\",\n",
    "    \"--model\", \n",
    "    \"/home/s1785140/data/ljspeech_fastpitch/train_meta_half_phonetisaurusG2P_model.fst\"\n",
    "]\n",
    "words = ['hello', 'world']\n",
    "shell_result = subprocess.run(shell_cmd + words, capture_output=True, text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d816cd94-b4e9-48e8-a082-41ddd0365dc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lines = shell_result.stdout.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "aecc0f48-a0ef-4807-a0ee-45f8d0ddeb6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove any empty strings\n",
    "lines = [l for l in lines if l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "bbe9f591-6f14-443f-8909-740f32de11ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spelling2g2p_pron = {}\n",
    "for l in lines:\n",
    "    spelling = l.split(\" \")[0]\n",
    "    phones = l.split(\" \")[1:]\n",
    "    spelling2g2p_pron[spelling] = phones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fb6158bd-0352-4b39-82ed-d443320a3fd4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HH', 'EH', 'L', 'OW']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'hello HH EH L OW'.split(\" \")[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "63ce0aa9-6b4a-490d-96d7-dde3ad98a5c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hello': ['HH', 'EH', 'L', 'OW'], 'world': ['W', 'ER', 'L', 'D']}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spelling2g2p_pron"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
