{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "417d79b7-ac5c-45be-938a-03b417fbdeee",
   "metadata": {},
   "source": [
    "Input: \n",
    "* folder of url lists. one url list per system. each line is a url of a wav file\n",
    "\n",
    "Output:\n",
    "* for each subtest create a list of \"a\" urls, a list of \"b\" urls, and a list of \"target words\"\n",
    "* when these lists are zipped they are a \"AB\" stimuli in the AB test\n",
    "* save to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "64e26a55-9025-4434-a886-00e73c32f605",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b4a95fe9-9648-42cb-a07c-fc891d7067a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_urls(txtfile):\n",
    "    with open(txtfile, 'r') as f:\n",
    "        urls = f.readlines()\n",
    "    urls = [line.rstrip('\\n') for line in urls]\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c1414f3b-28f8-4d42-a932-a7cbf2717d58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EXCLUDE_URL_LISTS = [\n",
    "    'groundtruth.txt'\n",
    "]\n",
    "\n",
    "INPUT_DIR = \"/home/s1785140/rlspeller/listening_tests/experiment1/url_lists\"\n",
    "OUTPUT_DIR = \"url_lists_ab_exp1\"\n",
    "NUM_SUBLISTS = 10 # determines how big an individual test will be\n",
    "wav_files_expected_to_have_same_name = False\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bd4d5d5b-373d-4c81-afe8-16218b683e27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url_list_files = sorted(file for file in os.listdir(INPUT_DIR) if file.endswith(\".txt\") and file not in EXCLUDE_URL_LISTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2de8987f-5a03-4166-b587-d83e57eb5109",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hubert-discrete-centroid==Distance(Cosine).txt',\n",
       " 'hubert-discrete-code==Distance(Levenshtein).txt',\n",
       " 'hubert-raw==Distance(Cosine).txt',\n",
       " 'hubert-soft==Distance(Cosine).txt',\n",
       " 'mfcc==Distance(Euclidean).txt']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_list_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4b9f68cf-6825-4a6c-9355-975611af1576",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create dict from system to url list\n",
    "system2url_list = {}\n",
    "for url_list_file in url_list_files:\n",
    "    system_name = os.path.splitext(url_list_file)[0]\n",
    "    url_list = load_urls(os.path.join(INPUT_DIR, url_list_file))\n",
    "    system2url_list[system_name] = url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "658e8b57-ce88-4d4b-a97a-ed192c4eb1c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gt_url_list = load_urls(os.path.join(INPUT_DIR, 'groundtruth.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f68058ed-f10a-4361-9c88-3a100763e81c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All url lists are of len 100\n"
     ]
    }
   ],
   "source": [
    "# sanity check that url lists are as expected\n",
    "\n",
    "url_lists = list(system2url_list.values())\n",
    "\n",
    "num_urls = len(url_lists[0])\n",
    "for url_list in url_lists[1:]:\n",
    "    assert num_urls == len(url_list)\n",
    "print(\"All url lists are of len\", num_urls)\n",
    "\n",
    "def url_list2files(url_list):\n",
    "    # get filenames (exclude path upto the file)\n",
    "    files = [url.split('/')[-1] for url in url_list]\n",
    "    return files\n",
    "\n",
    "if wav_files_expected_to_have_same_name:\n",
    "    files = url_list2files(url_lists[0])\n",
    "    for url_list in url_lists[1:]:\n",
    "        for f1, f2 in zip(files, url_list2files(url_list)):\n",
    "            assert f1 == f2, f\"{f1} != {f2}\"\n",
    "    print(\"All url lists have same files (but not the same urls!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1e0d67-c036-4a06-bcaa-8da2a2966c7d",
   "metadata": {},
   "source": [
    "# split url lists into subsets\n",
    "\n",
    "78 total words, we want to create 6 tests each with 13 words from each pair of conditions. using latin square to keep balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "eed5e6df-fe09-418c-b2f9-a26a52002605",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import islice, combinations\n",
    "\n",
    "def create_sublists(lst, n):\n",
    "    # lst is the list to split\n",
    "    # n is the length of each sublist\n",
    "    # returns a list of sublists\n",
    "    if len(lst) % n != 0:\n",
    "        raise ValueError(\"each resulting sublist will not be same length\")\n",
    "    \n",
    "    result = []\n",
    "    it = iter(lst) # create an iterator from the list\n",
    "    while True:\n",
    "        # slice the iterator into a sublist of length n\n",
    "        sublist = list(islice(it, n))\n",
    "        if not sublist:\n",
    "            # if the sublist is empty, break the loop\n",
    "            break\n",
    "        # append the sublist to the result list\n",
    "        result.append(sublist)\n",
    "    return result\n",
    "\n",
    "sublist_len = int(num_urls / NUM_SUBLISTS)\n",
    "sublists = create_sublists(range(0,num_urls), n=sublist_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f4ad9441-eaea-4e7e-b3cb-5a24200ce48d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 10),\n",
       " (10, 20),\n",
       " (20, 30),\n",
       " (30, 40),\n",
       " (40, 50),\n",
       " (50, 60),\n",
       " (60, 70),\n",
       " (70, 80),\n",
       " (80, 90),\n",
       " (90, 100)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get ranges from sublists\n",
    "ranges = [(sublist[0], sublist[-1]+1) for sublist in sublists]\n",
    "ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5ced23b7-0ea5-404c-bdc0-2078c6642ebd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def list_to_dict_using_ranges(l):\n",
    "    \"\"\"split list according to ranges\"\"\"\n",
    "    dict_with_ranges = defaultdict(list)\n",
    "    for start, end in ranges:\n",
    "        for i in range(start, end):\n",
    "            dict_with_ranges[(start, end)].append(l[i])\n",
    "    return dict_with_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "16006c03-d87f-45f4-b259-ff01f1e67543",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "system2url_dict = {}\n",
    "\n",
    "for system, url_list in system2url_list.items():\n",
    "    system2url_dict[system] = list_to_dict_using_ranges(url_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3977ebe2-dae5-4c1b-8fa6-47b08ab7f907",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['hubert-discrete-centroid==Distance(Cosine)', 'hubert-discrete-code==Distance(Levenshtein)', 'hubert-raw==Distance(Cosine)', 'hubert-soft==Distance(Cosine)', 'mfcc==Distance(Euclidean)'])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system2url_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830b57b8-5f8a-40be-86c2-bf3063d5768f",
   "metadata": {},
   "source": [
    "# pair up conditions and assign letters to each pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "98103d75-9216-4e57-88ee-4797bedf7832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ABCDEFGHIJKLMNOPQRSTUVWXYZ'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.ascii_uppercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "49e8204e-d05c-48c2-9b80-d19908ac849f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "letter='A', sys1='hubert-discrete-centroid==Distance(Cosine)', sys2='hubert-discrete-code==Distance(Levenshtein)'\n",
      "letter='B', sys1='hubert-discrete-centroid==Distance(Cosine)', sys2='hubert-raw==Distance(Cosine)'\n",
      "letter='C', sys1='hubert-discrete-centroid==Distance(Cosine)', sys2='hubert-soft==Distance(Cosine)'\n",
      "letter='D', sys1='hubert-discrete-centroid==Distance(Cosine)', sys2='mfcc==Distance(Euclidean)'\n",
      "letter='E', sys1='hubert-discrete-code==Distance(Levenshtein)', sys2='hubert-raw==Distance(Cosine)'\n",
      "letter='F', sys1='hubert-discrete-code==Distance(Levenshtein)', sys2='hubert-soft==Distance(Cosine)'\n",
      "letter='G', sys1='hubert-discrete-code==Distance(Levenshtein)', sys2='mfcc==Distance(Euclidean)'\n",
      "letter='H', sys1='hubert-raw==Distance(Cosine)', sys2='hubert-soft==Distance(Cosine)'\n",
      "letter='I', sys1='hubert-raw==Distance(Cosine)', sys2='mfcc==Distance(Euclidean)'\n",
      "letter='J', sys1='hubert-soft==Distance(Cosine)', sys2='mfcc==Distance(Euclidean)'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'A': {'sys1': 'hubert-discrete-centroid==Distance(Cosine)',\n",
       "  'sys2': 'hubert-discrete-code==Distance(Levenshtein)'},\n",
       " 'B': {'sys1': 'hubert-discrete-centroid==Distance(Cosine)',\n",
       "  'sys2': 'hubert-raw==Distance(Cosine)'},\n",
       " 'C': {'sys1': 'hubert-discrete-centroid==Distance(Cosine)',\n",
       "  'sys2': 'hubert-soft==Distance(Cosine)'},\n",
       " 'D': {'sys1': 'hubert-discrete-centroid==Distance(Cosine)',\n",
       "  'sys2': 'mfcc==Distance(Euclidean)'},\n",
       " 'E': {'sys1': 'hubert-discrete-code==Distance(Levenshtein)',\n",
       "  'sys2': 'hubert-raw==Distance(Cosine)'},\n",
       " 'F': {'sys1': 'hubert-discrete-code==Distance(Levenshtein)',\n",
       "  'sys2': 'hubert-soft==Distance(Cosine)'},\n",
       " 'G': {'sys1': 'hubert-discrete-code==Distance(Levenshtein)',\n",
       "  'sys2': 'mfcc==Distance(Euclidean)'},\n",
       " 'H': {'sys1': 'hubert-raw==Distance(Cosine)',\n",
       "  'sys2': 'hubert-soft==Distance(Cosine)'},\n",
       " 'I': {'sys1': 'hubert-raw==Distance(Cosine)',\n",
       "  'sys2': 'mfcc==Distance(Euclidean)'},\n",
       " 'J': {'sys1': 'hubert-soft==Distance(Cosine)',\n",
       "  'sys2': 'mfcc==Distance(Euclidean)'}}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "systems = system2url_dict.keys()\n",
    "url_dicts = system2url_dict.values()\n",
    "\n",
    "letter2url_dicts = {}\n",
    "letter2systempair = {}\n",
    "for i, (sys1, sys2) in enumerate(combinations(systems, 2)):\n",
    "    cond1, cond2 = system2url_dict[sys1], system2url_dict[sys2]\n",
    "    letter = string.ascii_uppercase[i]\n",
    "    letter2url_dicts[letter] = (cond1, cond2)\n",
    "    print(f\"{letter=}, {sys1=}, {sys2=}\")\n",
    "    letter2systempair[letter] = {'sys1': sys1, 'sys2': sys2}\n",
    "letters = list(letter2url_dicts.keys())\n",
    "letter2systempair"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6b3c8a-723d-43f3-ba0f-59b3dac87e27",
   "metadata": {},
   "source": [
    "# create latin square "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f0cea57d-717e-458c-9239-f035d2ea63e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ABCDEFGHIJ', 'BCDEFGHIJA', 'CDEFGHIJAB', 'DEFGHIJABC', 'EFGHIJABCD', 'FGHIJABCDE', 'GHIJABCDEF', 'HIJABCDEFG', 'IJABCDEFGH', 'JABCDEFGHI']\n"
     ]
    }
   ],
   "source": [
    "def create_latin_square_letters(n):\n",
    "    letters = string.ascii_uppercase[:n]\n",
    "    return [letters[i:] + letters[:i] for i in range(n)]\n",
    "\n",
    "print(create_latin_square_letters(len(letters)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3fe4f1ca-549a-49d9-98a9-1a6415e971a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "testnum2letters = {}\n",
    "for i, test_pair_letters in enumerate(create_latin_square_letters(len(letters))):\n",
    "    testnum2letters[i+1] = tuple(test_pair_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "23b36448-7e16-4359-a334-8159e7f2e6e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: ('A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J'),\n",
       " 2: ('B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'A'),\n",
       " 3: ('C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'A', 'B'),\n",
       " 4: ('D', 'E', 'F', 'G', 'H', 'I', 'J', 'A', 'B', 'C'),\n",
       " 5: ('E', 'F', 'G', 'H', 'I', 'J', 'A', 'B', 'C', 'D'),\n",
       " 6: ('F', 'G', 'H', 'I', 'J', 'A', 'B', 'C', 'D', 'E'),\n",
       " 7: ('G', 'H', 'I', 'J', 'A', 'B', 'C', 'D', 'E', 'F'),\n",
       " 8: ('H', 'I', 'J', 'A', 'B', 'C', 'D', 'E', 'F', 'G'),\n",
       " 9: ('I', 'J', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H'),\n",
       " 10: ('J', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I')}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testnum2letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1c8b86fe-0420-4d84-a7d3-cc7999fe66f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a test config that can be saved to disk so that we can reliably recover the question to system orderings\n",
    "\n",
    "assert len(ranges) == len(letters)\n",
    "\n",
    "testconfig = {\n",
    "    'ranges': ranges,\n",
    "    'testnum2letters': testnum2letters,\n",
    "    'letter2systempair': letter2systempair,\n",
    "    'letter2url_dicts': letter2url_dicts,\n",
    "}\n",
    "\n",
    "outpath = 'exp1_testconfig.pkl'\n",
    "\n",
    "if not os.path.exists(outpath):\n",
    "    pickle.dump(testconfig, open(outpath, 'wb'))\n",
    "else:\n",
    "    # print(f\"WARNING!!! did not save to {outpath} as file already exists. Change outpath name or delete existing file manually to save.\")\n",
    "    raise ValueError(f\"WARNING!!! did not save to {outpath} as file already exists. Change outpath name or delete existing file manually to save.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beaa6b15-c5bf-46d7-ad3e-5356d00d5bfb",
   "metadata": {},
   "source": [
    "# create each test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f534b44c-355b-4d24-bbe9-ed8ff4f051bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # IS2022 SAC\n",
    "# def extract_word(url):\n",
    "#     \"\"\"extract target word from url\"\"\"\n",
    "#     if \"vanillatts\" in url:\n",
    "#         w = url.split(\"vanillatts\")[-1].lstrip('-').split('.wav')[0]\n",
    "#     elif '<' in url:\n",
    "#         # speech codes\n",
    "#         w = url.split(\"<\")[-1].split('>')[0]\n",
    "#     else:\n",
    "#         # sac model graphemes\n",
    "#         w = url.split('how is ')[-1].split(' pronounced')[0]\n",
    "#     return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "aed91eae-1438-4ecb-b678-52cb187952f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SSW 2023\n",
    "def extract_word(url):\n",
    "    filename = url.split('/')[-1]\n",
    "    w = filename.split('_')[1]\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ba4394e0-d3b0-417c-8f92-efbcd710380d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LOCAL_QUALTREATS_URLS_PATH = \"/Users/jonojace/github/qualtreats/SSW2023_ab_urls/\"\n",
    "\n",
    "cmds_to_run = []\n",
    "\n",
    "cmds_to_run.append(\"conda activate is2022\")\n",
    "cmds_to_run.append(\"cd /Users/jonojace/github/qualtreats\")\n",
    "\n",
    "for test_num, test_pair_letters in testnum2letters.items():\n",
    "    cmds_to_run.append(f\"\\n### test === {test_num} ===\")\n",
    "    all_a_urls = []\n",
    "    all_b_urls = []\n",
    "    # for each test\n",
    "    # each pair of conditions only provides a certain number of stimuli according to \"ranges\"\n",
    "    # e.g. test 1, A gets 1-13, B gets 14-26, F gets 27-39\n",
    "    assert len(ranges) == len(test_pair_letters)\n",
    "    for idx_range, test_pair_letter in zip(ranges, test_pair_letters):\n",
    "        # extract urls according to range for the test_pair\n",
    "        condition_a_url_dict, condition_b_url_dict =  letter2url_dicts[test_pair_letter]\n",
    "        a_urls = condition_a_url_dict[idx_range]\n",
    "        b_urls = condition_b_url_dict[idx_range]\n",
    "\n",
    "        all_a_urls.extend(a_urls)\n",
    "        all_b_urls.extend(b_urls)\n",
    "\n",
    "    # double check that urls are properly aligned\n",
    "    target_words = []\n",
    "    for a_url, b_url in zip(all_a_urls, all_b_urls):\n",
    "        # print(f\"test {test_num}\",a_url,b_url)\n",
    "        assert a_url != b_url\n",
    "        assert extract_word(a_url) == extract_word(b_url)\n",
    "        target_words.append(extract_word(a_url))\n",
    "\n",
    "    # save to disk url list for a and b\n",
    "    def write_url_list_to_disk(test_num, urls, a_or_b):\n",
    "        lines = []\n",
    "        for url in urls:\n",
    "            lines.append(f\"test{test_num}_{a_or_b} {url}\")\n",
    "        outpath = os.path.join(OUTPUT_DIR, f\"ab-urls-test{test_num}_{a_or_b}.txt\")\n",
    "        with open(outpath, 'w') as f:\n",
    "            f.write(\"\\n\".join(lines))\n",
    "        return outpath\n",
    "\n",
    "    ab_file1_outpath = write_url_list_to_disk(test_num, all_a_urls, \"a\")\n",
    "    ab_file2_outpath = write_url_list_to_disk(test_num, all_b_urls, \"b\")\n",
    "    \n",
    "    def write_target_words(test_num, target_words):\n",
    "        lines = []\n",
    "        for w in target_words:\n",
    "            lines.append(f\"test{test_num} {w}\")\n",
    "        outpath = os.path.join(OUTPUT_DIR, f\"ab-urls-test{test_num}_targetwords.txt\")\n",
    "        with open(outpath, 'w') as f:\n",
    "            f.write(\"\\n\".join(lines))\n",
    "        return outpath\n",
    "    \n",
    "    targetwords_outpath = write_target_words(test_num, target_words)\n",
    "    \n",
    "    # save url list for GT audios\n",
    "    lines = []\n",
    "    for url in gt_url_list:\n",
    "        lines.append(f\"test{test_num} {url}\")\n",
    "    ab_gt_outpath = os.path.join(OUTPUT_DIR, f\"ab-urls-test{test_num}_GT.txt\")\n",
    "    with open(ab_gt_outpath, 'w') as f:\n",
    "        f.write(\"\\n\".join(lines))\n",
    "    \n",
    "    # print command to run to create tests here\n",
    "    cmd = f\"python testmaker.py -ab \" \\\n",
    "    f\"-ab-file1 {os.path.join(LOCAL_QUALTREATS_URLS_PATH, os.path.basename(ab_file1_outpath))} \" \\\n",
    "    f\"-ab-file2 {os.path.join(LOCAL_QUALTREATS_URLS_PATH, os.path.basename(ab_file2_outpath))} \" \\\n",
    "    f\"-ab-fileGT {os.path.join(LOCAL_QUALTREATS_URLS_PATH, os.path.basename(ab_gt_outpath))} \" \\\n",
    "    f\"-ab-targetwords {os.path.join(LOCAL_QUALTREATS_URLS_PATH, os.path.basename(targetwords_outpath))} \" \\\n",
    "    f\"-outfile test{test_num}.qsf \" \\\n",
    "    f\"-survey-name SSW2023_exp1_test{test_num}\"\n",
    "    cmds_to_run.append(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16705c5b-0bc8-4b39-b9b4-76bffed8a125",
   "metadata": {},
   "source": [
    "# run the following command in bash from your laptop to transfer files to your local mac\n",
    "```bash\n",
    "SOURCE=s1785140@escience6.inf.ed.ac.uk:/home/s1785140/rlspeller/ab_test/url_lists_ab_exp1/\n",
    "DEST=/Users/jonojace/github/qualtreats/SSW2023_ab_urls/\n",
    "mkdir -p $DEST\n",
    "rsync -avu $SOURCE $DEST\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1d251c-109e-4250-af0a-45224ad74615",
   "metadata": {},
   "source": [
    "# run following commands to create listening tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cd8d8183-4fec-4ffa-914b-a73384d20d8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conda activate is2022\n",
      "cd /Users/jonojace/github/qualtreats\n",
      "\n",
      "### test === 1 ===\n",
      "python testmaker.py -ab -ab-file1 /Users/jonojace/github/qualtreats/SSW2023_ab_urls/ab-urls-test1_a.txt -ab-file2 /Users/jonojace/github/qualtreats/SSW2023_ab_urls/ab-urls-test1_b.txt -ab-fileGT /Users/jonojace/github/qualtreats/SSW2023_ab_urls/ab-urls-test1_GT.txt -ab-targetwords /Users/jonojace/github/qualtreats/SSW2023_ab_urls/ab-urls-test1_targetwords.txt -outfile test1.qsf -survey-name SSW2023_exp1_test1\n",
      "\n",
      "### test === 2 ===\n",
      "python testmaker.py -ab -ab-file1 /Users/jonojace/github/qualtreats/SSW2023_ab_urls/ab-urls-test2_a.txt -ab-file2 /Users/jonojace/github/qualtreats/SSW2023_ab_urls/ab-urls-test2_b.txt -ab-fileGT /Users/jonojace/github/qualtreats/SSW2023_ab_urls/ab-urls-test2_GT.txt -ab-targetwords /Users/jonojace/github/qualtreats/SSW2023_ab_urls/ab-urls-test2_targetwords.txt -outfile test2.qsf -survey-name SSW2023_exp1_test2\n",
      "\n",
      "### test === 3 ===\n",
      "python testmaker.py -ab -ab-file1 /Users/jonojace/github/qualtreats/SSW2023_ab_urls/ab-urls-test3_a.txt -ab-file2 /Users/jonojace/github/qualtreats/SSW2023_ab_urls/ab-urls-test3_b.txt -ab-fileGT /Users/jonojace/github/qualtreats/SSW2023_ab_urls/ab-urls-test3_GT.txt -ab-targetwords /Users/jonojace/github/qualtreats/SSW2023_ab_urls/ab-urls-test3_targetwords.txt -outfile test3.qsf -survey-name SSW2023_exp1_test3\n",
      "\n",
      "### test === 4 ===\n",
      "python testmaker.py -ab -ab-file1 /Users/jonojace/github/qualtreats/SSW2023_ab_urls/ab-urls-test4_a.txt -ab-file2 /Users/jonojace/github/qualtreats/SSW2023_ab_urls/ab-urls-test4_b.txt -ab-fileGT /Users/jonojace/github/qualtreats/SSW2023_ab_urls/ab-urls-test4_GT.txt -ab-targetwords /Users/jonojace/github/qualtreats/SSW2023_ab_urls/ab-urls-test4_targetwords.txt -outfile test4.qsf -survey-name SSW2023_exp1_test4\n",
      "\n",
      "### test === 5 ===\n",
      "python testmaker.py -ab -ab-file1 /Users/jonojace/github/qualtreats/SSW2023_ab_urls/ab-urls-test5_a.txt -ab-file2 /Users/jonojace/github/qualtreats/SSW2023_ab_urls/ab-urls-test5_b.txt -ab-fileGT /Users/jonojace/github/qualtreats/SSW2023_ab_urls/ab-urls-test5_GT.txt -ab-targetwords /Users/jonojace/github/qualtreats/SSW2023_ab_urls/ab-urls-test5_targetwords.txt -outfile test5.qsf -survey-name SSW2023_exp1_test5\n",
      "\n",
      "### test === 6 ===\n",
      "python testmaker.py -ab -ab-file1 /Users/jonojace/github/qualtreats/SSW2023_ab_urls/ab-urls-test6_a.txt -ab-file2 /Users/jonojace/github/qualtreats/SSW2023_ab_urls/ab-urls-test6_b.txt -ab-fileGT /Users/jonojace/github/qualtreats/SSW2023_ab_urls/ab-urls-test6_GT.txt -ab-targetwords /Users/jonojace/github/qualtreats/SSW2023_ab_urls/ab-urls-test6_targetwords.txt -outfile test6.qsf -survey-name SSW2023_exp1_test6\n",
      "\n",
      "### test === 7 ===\n",
      "python testmaker.py -ab -ab-file1 /Users/jonojace/github/qualtreats/SSW2023_ab_urls/ab-urls-test7_a.txt -ab-file2 /Users/jonojace/github/qualtreats/SSW2023_ab_urls/ab-urls-test7_b.txt -ab-fileGT /Users/jonojace/github/qualtreats/SSW2023_ab_urls/ab-urls-test7_GT.txt -ab-targetwords /Users/jonojace/github/qualtreats/SSW2023_ab_urls/ab-urls-test7_targetwords.txt -outfile test7.qsf -survey-name SSW2023_exp1_test7\n",
      "\n",
      "### test === 8 ===\n",
      "python testmaker.py -ab -ab-file1 /Users/jonojace/github/qualtreats/SSW2023_ab_urls/ab-urls-test8_a.txt -ab-file2 /Users/jonojace/github/qualtreats/SSW2023_ab_urls/ab-urls-test8_b.txt -ab-fileGT /Users/jonojace/github/qualtreats/SSW2023_ab_urls/ab-urls-test8_GT.txt -ab-targetwords /Users/jonojace/github/qualtreats/SSW2023_ab_urls/ab-urls-test8_targetwords.txt -outfile test8.qsf -survey-name SSW2023_exp1_test8\n",
      "\n",
      "### test === 9 ===\n",
      "python testmaker.py -ab -ab-file1 /Users/jonojace/github/qualtreats/SSW2023_ab_urls/ab-urls-test9_a.txt -ab-file2 /Users/jonojace/github/qualtreats/SSW2023_ab_urls/ab-urls-test9_b.txt -ab-fileGT /Users/jonojace/github/qualtreats/SSW2023_ab_urls/ab-urls-test9_GT.txt -ab-targetwords /Users/jonojace/github/qualtreats/SSW2023_ab_urls/ab-urls-test9_targetwords.txt -outfile test9.qsf -survey-name SSW2023_exp1_test9\n",
      "\n",
      "### test === 10 ===\n",
      "python testmaker.py -ab -ab-file1 /Users/jonojace/github/qualtreats/SSW2023_ab_urls/ab-urls-test10_a.txt -ab-file2 /Users/jonojace/github/qualtreats/SSW2023_ab_urls/ab-urls-test10_b.txt -ab-fileGT /Users/jonojace/github/qualtreats/SSW2023_ab_urls/ab-urls-test10_GT.txt -ab-targetwords /Users/jonojace/github/qualtreats/SSW2023_ab_urls/ab-urls-test10_targetwords.txt -outfile test10.qsf -survey-name SSW2023_exp1_test10\n"
     ]
    }
   ],
   "source": [
    "for cmd in cmds_to_run:\n",
    "    print(cmd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
