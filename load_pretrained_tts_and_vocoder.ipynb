{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# develop code to load fastpitch and/or hifigan from pretrained checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python3 -m ipykernel install --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "load_fastpitch = False\n",
    "load_hifigan = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "levi.inf.ed.ac.uk\n"
     ]
    }
   ],
   "source": [
    "# print hostname to make sure we are on correct node\n",
    "disallowed_nodes = ['escience6']\n",
    "import socket\n",
    "hostname = socket.gethostname()\n",
    "print(hostname)\n",
    "node = hostname.split('.')[0]\n",
    "if node in disallowed_nodes:\n",
    "    raise ValueError(f\"Running on disallowed node {node}!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import argparse\n",
    "from fastpitch import models as fastpitch_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# change some args through CLAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.1\n",
    "lr = 0.1 # def for lamb optimizer is 0.001\n",
    "dist_metric = 'l1'\n",
    "\n",
    "# wandb_project_name = \"respeller-training\"\n",
    "exp_name = f\"test_development\"\n",
    "# fastpitch_chkpt = 'fastpitch/exps/halved_ljspeech_data_nospaces_noeos/FastPitch_checkpoint_1000.pt' # 'fastpitch/exps/halved_ljspeech_data/FastPitch_checkpoint_1000.pt',\n",
    "fastpitch_chkpt = '/home/s1785140/respeller/fastpitch/exps/halved_ljspeech_data_nospaces_noeos_pad_lowercase_nopunc/FastPitch_checkpoint_1000.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imitate CLAs\n",
    "import sys\n",
    "sys.argv = [\n",
    "    'train.py',\n",
    "#     '--wandb-project-name', wandb_project_name,\n",
    "    '--chkpt-save-dir', f'/home/s1785140/respeller/exps/{exp_name}', \n",
    "    '--fastpitch-chkpt', fastpitch_chkpt,\n",
    "    '--input-type', 'char',\n",
    "    '--symbol-set', 'english_pad_lowercase_nopunc',\n",
    "    # '--text-cleaners', 'lowercase_no_punc',\n",
    "    '--use-mas',\n",
    "    '--cuda',\n",
    "    '--n-speakers', '1',\n",
    "    '--use-sepconv',\n",
    "    # '--add-spaces',\n",
    "    # '--eos-symbol', '$',\n",
    "    '--batch-size', '2',\n",
    "    '--val-num-to-gen', '2',\n",
    "    '--softdtw-temp', str(gamma),\n",
    "    '--dist-func', dist_metric,\n",
    "    '--learning-rate', str(lr),\n",
    "    \n",
    "    # NB for real training!\n",
    "    # '--epochs', '10000', \n",
    "    # '--val-log-interval', '10',\n",
    "    # '--resume', # resume from latest checkpoint\n",
    "    \n",
    "    # # NB for development!\n",
    "    '--epochs', '2', # NB for development!\n",
    "    '--val-log-interval', '1', # NB for development!\n",
    "    '--max-iters-per-epoch', '5', # NB for development!\n",
    "    # '--skip-before-train-loop-validation', # NB for development!\n",
    "    # '--freeze-embedding-table',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parse args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def parse_args(parser):\n",
    "    \"\"\"Parse commandline arguments\"\"\"\n",
    "    parser.add_argument('-o', '--chkpt-save-dir', type=str, # required=True,\n",
    "                        help='Directory to save checkpoints')\n",
    "    parser.add_argument('-d', '--dataset-path', type=str, default='./',\n",
    "                        help='Path to dataset')\n",
    "    train = parser.add_argument_group('training setup')\n",
    "    train.add_argument('--cuda', action='store_true',\n",
    "                       help='Enable GPU training')\n",
    "    train.add_argument('--num-cpus', type=int, default=1,\n",
    "                       help='Num of cpus on node. Used to optimise number of dataloader workers during training.')\n",
    "    train.add_argument('--batch-size', type=int, default=16,\n",
    "                       help='Batchsize (this is divided by number of GPUs if running Data Distributed Parallel Training)')\n",
    "    train.add_argument('--val-num-to-gen', type=int, default=32,\n",
    "                      help='Number of samples to generate in validation (determines how many samples show up in wandb')\n",
    "    train.add_argument('--seed', type=int, default=1337,\n",
    "                       help='Seed for PyTorch random number generators')\n",
    "    train.add_argument('--grad-accumulation', type=int, default=1,\n",
    "                       help='Training steps to accumulate gradients for')\n",
    "    train.add_argument('--epochs', type=int, default=100,  # required=True,\n",
    "                       help='Number of total epochs to run')\n",
    "    train.add_argument('--max-iters-per-epoch', type=int, default=None,\n",
    "                       help='Number of total batches to iterate through each epoch (reduce this to small number to quickly test whole training loop)')\n",
    "    train.add_argument('--epochs-per-checkpoint', type=int, default=10,\n",
    "                       help='Number of epochs per checkpoint')\n",
    "    train.add_argument('--checkpoint-path', type=str, default=None,\n",
    "                       help='Checkpoint path to resume train')\n",
    "    train.add_argument('--resume', action='store_true',\n",
    "                       help='Resume train from the last available checkpoint')\n",
    "    train.add_argument('--val-log-interval', type=int, default=5,\n",
    "                       help='How often to generate melspecs/audio for respellings and log to wandb')\n",
    "    train.add_argument('--speech-length-penalty-training', action='store_true',\n",
    "                       help='Whether or not to encourage model to output similar length outputs\\\n",
    "                       as the ground truth. Idea from V2C: Visual Voice Cloning (Chen et al. 2021)')\n",
    "    train.add_argument('--skip-before-train-loop-validation', action='store_true',\n",
    "                       help='Skip running validation before model training begins (mostly for speeding up testing of actual training loop)')\n",
    "    train.add_argument('--avg-loss-by-speech_lens', action='store_true',\n",
    "                       help='Average the softdtw loss according to number of timesteps in predicted sequence')\n",
    "    train.add_argument('--softdtw-temp', type=float, default=0.01,\n",
    "                       help='How hard/soft to make min operation. Minimum is recovered by setting this to 0.')\n",
    "    train.add_argument('--softdtw-bandwidth', type=int, default=120,\n",
    "                       help='Bandwidth for pruning paths in alignment matrix when calculating SoftDTW')\n",
    "    train.add_argument('--dist-func', type=str, default=\"l1\",\n",
    "                       help='What distance function to use in softdtw loss calculation')\n",
    "    train.add_argument('--cross-entropy-loss', action='store_true',\n",
    "                       help='Whether to ONLY train the model with cross entropy using grapheme based targets'\n",
    "                            'will not use fastpitch TTS acoustic loss')\n",
    "\n",
    "    opt = parser.add_argument_group('optimization setup')\n",
    "    opt.add_argument('--optimizer', type=str, default='lamb', choices=['adam', 'lamb'],\n",
    "                     help='Optimization algorithm')\n",
    "    opt.add_argument('-lr', '--learning-rate', default=0.1, type=float,\n",
    "                     help='Learning rate')\n",
    "    opt.add_argument('--weight-decay', default=1e-6, type=float,\n",
    "                     help='Weight decay')\n",
    "    opt.add_argument('--grad-clip-thresh', default=1000.0, type=float,\n",
    "                     help='Clip threshold for gradients')\n",
    "    opt.add_argument('--warmup-steps', type=int, default=1000,\n",
    "                     help='Number of steps for lr warmup')\n",
    "\n",
    "    arch = parser.add_argument_group('architecture')\n",
    "    arch.add_argument('--dropout-inputs', type=float, default=0.0,\n",
    "                      help='Dropout prob to apply to sum of word embeddings '\n",
    "                           'and positional encodings')\n",
    "    arch.add_argument('--dropout-layers', type=float, default=0.1,\n",
    "                      help='Dropout prob to apply to each layer of Tranformer')\n",
    "    arch.add_argument('--d-model', type=int, default=128,\n",
    "                      help='Hidden dimension of tranformer')\n",
    "    arch.add_argument('--d-feedforward', type=int, default=512,\n",
    "                      help='Hidden dimension of tranformer')\n",
    "    arch.add_argument('--num-layers', type=int, default=4,\n",
    "                      help='Number of layers for transformer')\n",
    "    arch.add_argument('--nheads', type=int, default=4,\n",
    "                      help='Hidden dimension of tranformer')\n",
    "    arch.add_argument('--embedding-dim', type=int, default=384, # 384 is default value for fastpitch embedding table\n",
    "                      help='Hidden dimension of grapheme embedding table')\n",
    "    arch.add_argument('--pretrained-embedding-table', action='store_true',\n",
    "                      help='Whether or not to initialise embedding table from fastpitchs')\n",
    "    arch.add_argument('--freeze-embedding-table', action='store_true',\n",
    "                      help='Whether or not to allow grapheme embedding input table for EncoderRespeller to be updated.')\n",
    "    arch.add_argument('--gumbel-temp', nargs=3, type=float, default=(2, 0.5, 0.999995),\n",
    "                      help='Temperature annealling parameters for Gumbel-Softmax (start, end, decay)')\n",
    "    arch.add_argument('--no-src-key-padding-mask', dest='src_key_padding_mask', action='store_false',\n",
    "                      help='Whether or not to provide padding attention mask to Transformer Encoder layers')\n",
    "    arch.add_argument('--respelling-len-modifier', type=int, default=0, # 384 is default value for fastpitch embedding table\n",
    "                      help='How many letters to remove from or add to original spelling.')\n",
    "    arch.add_argument('--use-respelling-len-embeddings', action='store_true', # 384 is default value for fastpitch embedding table\n",
    "                      help='Whether or not to incorporate to respeller input additional embeddings that indicate how long'\n",
    "                           'the desired respelling should be.')\n",
    "    arch.add_argument('--concat-pos-encoding', action='store_true',\n",
    "                      help='Whether or not to concatenate pos encodings to inputs or sum')\n",
    "    arch.add_argument('--pos-encoding-dim', type=int, default=128,\n",
    "                      help='Dim of positional encoding module')\n",
    "    arch.add_argument('--dont-only-predict-alpha', dest='only_predict_alpha', action='store_false',\n",
    "                      help='Allow gumbel softmax to predict whitespace, padding, and other punctuation symbols')\n",
    "\n",
    "    pretrained_tts = parser.add_argument_group('pretrained tts model')\n",
    "    # pretrained_tts.add_argument('--fastpitch-with-mas', type=bool, default=True,\n",
    "    #                   help='Whether or not fastpitch was trained with Monotonic Alignment Search (MAS)')\n",
    "    pretrained_tts.add_argument('--fastpitch-chkpt', type=str, # required=True,\n",
    "                                help='Path to pretrained fastpitch checkpoint')\n",
    "    pretrained_tts.add_argument('--input-type', type=str, default='char',\n",
    "                                choices=['char', 'phone', 'pf', 'unit'],\n",
    "                                help='Input symbols used, either char (text), phone, pf '\n",
    "                                     '(phonological feature vectors) or unit (quantized acoustic '\n",
    "                                     'representation IDs)')\n",
    "    pretrained_tts.add_argument('--symbol-set', type=str, default='english_basic_lowercase',\n",
    "                                help='Define symbol set for input sequences. For quantized '\n",
    "                                     'unit inputs, pass the size of the vocabulary.')\n",
    "    pretrained_tts.add_argument('--n-speakers', type=int, default=1,\n",
    "                                help='Condition on speaker, value > 1 enables trainable '\n",
    "                                     'speaker embeddings.')\n",
    "    # pretrained_tts.add_argument('--use-sepconv', type=bool, default=True,\n",
    "    #                   help='Use depthwise separable convolutions')\n",
    "\n",
    "    audio = parser.add_argument_group('log generated audio')\n",
    "    audio.add_argument('--hifigan', type=str,\n",
    "                       default='/home/s1785140/pretrained_models/hifigan/ljspeech/LJ_V1/generator_v1',\n",
    "                       help='Path to HiFi-GAN audio checkpoint')\n",
    "    audio.add_argument('--hifigan-config', type=str,\n",
    "                       default='/home/s1785140/pretrained_models/hifigan/ljspeech/LJ_V1/config.json',\n",
    "                       help='Path to HiFi-GAN audio config file')\n",
    "    audio.add_argument('--sampling-rate', type=int, default=22050,\n",
    "                       help='Sampling rate for output audio')\n",
    "    audio.add_argument('--hop-length', type=int, default=256,\n",
    "                       help='STFT hop length for estimating audio length from mel size')\n",
    "\n",
    "    data = parser.add_argument_group('dataset parameters')\n",
    "    data.add_argument('--wordaligned-speechreps', type=str,\n",
    "                      default='/home/s1785140/data/ljspeech_fastpitch/wordaligned_mels',\n",
    "                      help='Path to directory of wordaligned speechreps/mels. Inside are folders\\\n",
    "                       each named as a wordtype and containing tensors of word aligned speechreps for each example')\n",
    "    data.add_argument('--train-wordlist', type=str,\n",
    "                      default='/home/s1785140/data/ljspeech_fastpitch/respeller_train_words.json',\n",
    "                      help='Path to words that are used to train respeller')\n",
    "    data.add_argument('--val-wordlist', type=str,\n",
    "                      default='/home/s1785140/data/ljspeech_fastpitch/respeller_dev_words.json',\n",
    "                      help='Path to words that are used to report validation metrics for respeller')\n",
    "    data.add_argument('--max-examples-per-wordtype', type=int, default=1,\n",
    "                      help='Path to words that are used to report validation metrics for respeller')\n",
    "    data.add_argument('--text-cleaners', type=str, nargs='+',\n",
    "                      default=(),\n",
    "                      help='What text cleaners to apply to text in order to preproces it before'\n",
    "                           'its fed to respeller.')\n",
    "\n",
    "    cond = parser.add_argument_group('conditioning on additional attributes')\n",
    "    dist = parser.add_argument_group('distributed training setup')\n",
    "\n",
    "    wandb_logging = parser.add_argument_group('wandb logging')\n",
    "    data.add_argument('--wandb-project-name', type=str,\n",
    "                      # required=True,\n",
    "                      help=\"The name of the wandb project to add this experiment's logs to\")\n",
    "    wandb_logging.add_argument('--keys-to-add-to-exp-name', type=str, nargs='+',\n",
    "                      default=(),\n",
    "                      help='Command line arguments that we add their info to the wandb experiment name')\n",
    "\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch Respeller Training', allow_abbrev=False)\n",
    "parser = parse_args(parser)\n",
    "args, _unk_args = parser.parse_known_args()\n",
    "\n",
    "parser = fastpitch_model.parse_model_args('FastPitch', parser)\n",
    "args, unk_args = parser.parse_known_args()\n",
    "if len(unk_args) > 0:\n",
    "    print(f'WARNING - Invalid options {unk_args}')\n",
    "\n",
    "if args.cuda:\n",
    "    args.num_gpus = torch.cuda.device_count()\n",
    "    args.distributed_run = args.num_gpus > 1\n",
    "    args.batch_size = int(args.batch_size / args.num_gpus)\n",
    "else:\n",
    "    args.distributed_run = False\n",
    "\n",
    "device = torch.device('cuda' if args.cuda else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load pretrained HifiGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def load_vocoder(args, device):\n",
    "    \"\"\"Load HiFi-GAN vocoder from checkpoint\"\"\"\n",
    "    checkpoint_data = torch.load(args.hifigan)\n",
    "    vocoder_config = fastpitch_model.get_model_config('HiFi-GAN', args)\n",
    "    vocoder = fastpitch_model.get_model('HiFi-GAN', vocoder_config, device)\n",
    "    vocoder.load_state_dict(checkpoint_data['generator'])\n",
    "    vocoder.remove_weight_norm()\n",
    "    vocoder.eval()\n",
    "    return vocoder\n",
    "\n",
    "# load pretrained hifigan\n",
    "vocoder = load_vocoder(args, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (conv_pre): Conv1d(80, 512, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "  (ups): ModuleList(\n",
       "    (0): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))\n",
       "    (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))\n",
       "    (2): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))\n",
       "    (3): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))\n",
       "  )\n",
       "  (resblocks): ModuleList(\n",
       "    (0): ResBlock1(\n",
       "      (convs1): ModuleList(\n",
       "        (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "        (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "      )\n",
       "      (convs2): ModuleList(\n",
       "        (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      )\n",
       "    )\n",
       "    (1): ResBlock1(\n",
       "      (convs1): ModuleList(\n",
       "        (0): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "        (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "        (2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
       "      )\n",
       "      (convs2): ModuleList(\n",
       "        (0): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "        (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "        (2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "      )\n",
       "    )\n",
       "    (2): ResBlock1(\n",
       "      (convs1): ModuleList(\n",
       "        (0): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "        (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
       "        (2): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
       "      )\n",
       "      (convs2): ModuleList(\n",
       "        (0): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "        (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "        (2): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "      )\n",
       "    )\n",
       "    (3): ResBlock1(\n",
       "      (convs1): ModuleList(\n",
       "        (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "        (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "      )\n",
       "      (convs2): ModuleList(\n",
       "        (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      )\n",
       "    )\n",
       "    (4): ResBlock1(\n",
       "      (convs1): ModuleList(\n",
       "        (0): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "        (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "        (2): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
       "      )\n",
       "      (convs2): ModuleList(\n",
       "        (0): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "        (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "        (2): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "      )\n",
       "    )\n",
       "    (5): ResBlock1(\n",
       "      (convs1): ModuleList(\n",
       "        (0): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "        (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
       "        (2): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
       "      )\n",
       "      (convs2): ModuleList(\n",
       "        (0): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "        (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "        (2): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "      )\n",
       "    )\n",
       "    (6): ResBlock1(\n",
       "      (convs1): ModuleList(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "        (2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "      )\n",
       "      (convs2): ModuleList(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      )\n",
       "    )\n",
       "    (7): ResBlock1(\n",
       "      (convs1): ModuleList(\n",
       "        (0): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "        (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "        (2): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
       "      )\n",
       "      (convs2): ModuleList(\n",
       "        (0): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "        (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "        (2): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "      )\n",
       "    )\n",
       "    (8): ResBlock1(\n",
       "      (convs1): ModuleList(\n",
       "        (0): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "        (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
       "        (2): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
       "      )\n",
       "      (convs2): ModuleList(\n",
       "        (0): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "        (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "        (2): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "      )\n",
       "    )\n",
       "    (9): ResBlock1(\n",
       "      (convs1): ModuleList(\n",
       "        (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "        (2): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "      )\n",
       "      (convs2): ModuleList(\n",
       "        (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (2): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      )\n",
       "    )\n",
       "    (10): ResBlock1(\n",
       "      (convs1): ModuleList(\n",
       "        (0): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "        (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "        (2): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
       "      )\n",
       "      (convs2): ModuleList(\n",
       "        (0): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "        (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "        (2): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "      )\n",
       "    )\n",
       "    (11): ResBlock1(\n",
       "      (convs1): ModuleList(\n",
       "        (0): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "        (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
       "        (2): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
       "      )\n",
       "      (convs2): ModuleList(\n",
       "        (0): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "        (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "        (2): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv_post): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load pretrained fastpitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading fastpitch checkpoint from /home/s1785140/respeller/fastpitch/exps/halved_ljspeech_data_nospaces_noeos_pad_lowercase_nopunc/FastPitch_checkpoint_1000.pt\n"
     ]
    }
   ],
   "source": [
    "def load_checkpoint(args, model, filepath):\n",
    "    checkpoint = torch.load(filepath, map_location='cpu')\n",
    "    sd = {k.replace('module.', ''): v\n",
    "          for k, v in checkpoint['state_dict'].items()}\n",
    "    getattr(model, 'module', model).load_state_dict(sd)\n",
    "    return model\n",
    "\n",
    "def load_pretrained_fastpitch(args):\n",
    "    # load chkpt\n",
    "    device = torch.device('cuda' if args.cuda else 'cpu')\n",
    "    model_config = fastpitch_model.get_model_config('FastPitch', args)\n",
    "    fastpitch = fastpitch_model.get_model('FastPitch', model_config, device, forward_is_infer=True)\n",
    "    load_checkpoint(args, fastpitch, args.fastpitch_chkpt)\n",
    "    n_symbols = fastpitch.encoder.word_emb.weight.size(0)\n",
    "    grapheme_embedding_dim = fastpitch.encoder.word_emb.weight.size(1)\n",
    "    return fastpitch, n_symbols, grapheme_embedding_dim, model_config\n",
    "\n",
    "if args.fastpitch_chkpt is None:\n",
    "    raise ValueError(\"No fastpitch checkpoint supplied at command line.\")\n",
    "else:\n",
    "    print(f\"Loading fastpitch checkpoint from {args.fastpitch_chkpt}\")\n",
    "    tts_model, n_symbols, grapheme_embedding_dim, model_config = load_pretrained_fastpitch(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FastPitch(\n",
       "  (encoder): FFTransformer(\n",
       "    (word_emb): Embedding(28, 384, padding_idx=0)\n",
       "    (pos_emb): PositionalEmbedding()\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerLayer(\n",
       "        (dec_attn): MultiHeadAttn(\n",
       "          (qkv_net): Linear(in_features=384, out_features=192, bias=True)\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "          (dropatt): Dropout(p=0.1, inplace=False)\n",
       "          (o_net): Linear(in_features=64, out_features=384, bias=False)\n",
       "          (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ff): PositionwiseConvFF(\n",
       "          (CoreNet): Sequential(\n",
       "            (0): SeparableConv(\n",
       "              (depthwise): Conv1d(384, 384, kernel_size=(3,), stride=(1,), padding=(1,), groups=384)\n",
       "              (pointwise): Conv1d(384, 1536, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (1): ReLU()\n",
       "            (2): SeparableConv(\n",
       "              (depthwise): Conv1d(1536, 1536, kernel_size=(3,), stride=(1,), padding=(1,), groups=1536)\n",
       "              (pointwise): Conv1d(1536, 384, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (1): TransformerLayer(\n",
       "        (dec_attn): MultiHeadAttn(\n",
       "          (qkv_net): Linear(in_features=384, out_features=192, bias=True)\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "          (dropatt): Dropout(p=0.1, inplace=False)\n",
       "          (o_net): Linear(in_features=64, out_features=384, bias=False)\n",
       "          (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ff): PositionwiseConvFF(\n",
       "          (CoreNet): Sequential(\n",
       "            (0): SeparableConv(\n",
       "              (depthwise): Conv1d(384, 384, kernel_size=(3,), stride=(1,), padding=(1,), groups=384)\n",
       "              (pointwise): Conv1d(384, 1536, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (1): ReLU()\n",
       "            (2): SeparableConv(\n",
       "              (depthwise): Conv1d(1536, 1536, kernel_size=(3,), stride=(1,), padding=(1,), groups=1536)\n",
       "              (pointwise): Conv1d(1536, 384, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (2): TransformerLayer(\n",
       "        (dec_attn): MultiHeadAttn(\n",
       "          (qkv_net): Linear(in_features=384, out_features=192, bias=True)\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "          (dropatt): Dropout(p=0.1, inplace=False)\n",
       "          (o_net): Linear(in_features=64, out_features=384, bias=False)\n",
       "          (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ff): PositionwiseConvFF(\n",
       "          (CoreNet): Sequential(\n",
       "            (0): SeparableConv(\n",
       "              (depthwise): Conv1d(384, 384, kernel_size=(3,), stride=(1,), padding=(1,), groups=384)\n",
       "              (pointwise): Conv1d(384, 1536, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (1): ReLU()\n",
       "            (2): SeparableConv(\n",
       "              (depthwise): Conv1d(1536, 1536, kernel_size=(3,), stride=(1,), padding=(1,), groups=1536)\n",
       "              (pointwise): Conv1d(1536, 384, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (3): TransformerLayer(\n",
       "        (dec_attn): MultiHeadAttn(\n",
       "          (qkv_net): Linear(in_features=384, out_features=192, bias=True)\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "          (dropatt): Dropout(p=0.1, inplace=False)\n",
       "          (o_net): Linear(in_features=64, out_features=384, bias=False)\n",
       "          (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ff): PositionwiseConvFF(\n",
       "          (CoreNet): Sequential(\n",
       "            (0): SeparableConv(\n",
       "              (depthwise): Conv1d(384, 384, kernel_size=(3,), stride=(1,), padding=(1,), groups=384)\n",
       "              (pointwise): Conv1d(384, 1536, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (1): ReLU()\n",
       "            (2): SeparableConv(\n",
       "              (depthwise): Conv1d(1536, 1536, kernel_size=(3,), stride=(1,), padding=(1,), groups=1536)\n",
       "              (pointwise): Conv1d(1536, 384, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (4): TransformerLayer(\n",
       "        (dec_attn): MultiHeadAttn(\n",
       "          (qkv_net): Linear(in_features=384, out_features=192, bias=True)\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "          (dropatt): Dropout(p=0.1, inplace=False)\n",
       "          (o_net): Linear(in_features=64, out_features=384, bias=False)\n",
       "          (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ff): PositionwiseConvFF(\n",
       "          (CoreNet): Sequential(\n",
       "            (0): SeparableConv(\n",
       "              (depthwise): Conv1d(384, 384, kernel_size=(3,), stride=(1,), padding=(1,), groups=384)\n",
       "              (pointwise): Conv1d(384, 1536, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (1): ReLU()\n",
       "            (2): SeparableConv(\n",
       "              (depthwise): Conv1d(1536, 1536, kernel_size=(3,), stride=(1,), padding=(1,), groups=1536)\n",
       "              (pointwise): Conv1d(1536, 384, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (5): TransformerLayer(\n",
       "        (dec_attn): MultiHeadAttn(\n",
       "          (qkv_net): Linear(in_features=384, out_features=192, bias=True)\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "          (dropatt): Dropout(p=0.1, inplace=False)\n",
       "          (o_net): Linear(in_features=64, out_features=384, bias=False)\n",
       "          (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ff): PositionwiseConvFF(\n",
       "          (CoreNet): Sequential(\n",
       "            (0): SeparableConv(\n",
       "              (depthwise): Conv1d(384, 384, kernel_size=(3,), stride=(1,), padding=(1,), groups=384)\n",
       "              (pointwise): Conv1d(384, 1536, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (1): ReLU()\n",
       "            (2): SeparableConv(\n",
       "              (depthwise): Conv1d(1536, 1536, kernel_size=(3,), stride=(1,), padding=(1,), groups=1536)\n",
       "              (pointwise): Conv1d(1536, 384, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (duration_predictor): TemporalPredictor(\n",
       "    (layers): Sequential(\n",
       "      (0): ConvReLUNorm(\n",
       "        (conv): SeparableConv(\n",
       "          (depthwise): Conv1d(384, 384, kernel_size=(3,), stride=(1,), padding=(1,), groups=384)\n",
       "          (pointwise): Conv1d(384, 256, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): ConvReLUNorm(\n",
       "        (conv): SeparableConv(\n",
       "          (depthwise): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "          (pointwise): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (fc): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       "  (decoder): FFTransformer(\n",
       "    (pos_emb): PositionalEmbedding()\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerLayer(\n",
       "        (dec_attn): MultiHeadAttn(\n",
       "          (qkv_net): Linear(in_features=384, out_features=192, bias=True)\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "          (dropatt): Dropout(p=0.1, inplace=False)\n",
       "          (o_net): Linear(in_features=64, out_features=384, bias=False)\n",
       "          (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ff): PositionwiseConvFF(\n",
       "          (CoreNet): Sequential(\n",
       "            (0): SeparableConv(\n",
       "              (depthwise): Conv1d(384, 384, kernel_size=(3,), stride=(1,), padding=(1,), groups=384)\n",
       "              (pointwise): Conv1d(384, 1536, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (1): ReLU()\n",
       "            (2): SeparableConv(\n",
       "              (depthwise): Conv1d(1536, 1536, kernel_size=(3,), stride=(1,), padding=(1,), groups=1536)\n",
       "              (pointwise): Conv1d(1536, 384, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (1): TransformerLayer(\n",
       "        (dec_attn): MultiHeadAttn(\n",
       "          (qkv_net): Linear(in_features=384, out_features=192, bias=True)\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "          (dropatt): Dropout(p=0.1, inplace=False)\n",
       "          (o_net): Linear(in_features=64, out_features=384, bias=False)\n",
       "          (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ff): PositionwiseConvFF(\n",
       "          (CoreNet): Sequential(\n",
       "            (0): SeparableConv(\n",
       "              (depthwise): Conv1d(384, 384, kernel_size=(3,), stride=(1,), padding=(1,), groups=384)\n",
       "              (pointwise): Conv1d(384, 1536, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (1): ReLU()\n",
       "            (2): SeparableConv(\n",
       "              (depthwise): Conv1d(1536, 1536, kernel_size=(3,), stride=(1,), padding=(1,), groups=1536)\n",
       "              (pointwise): Conv1d(1536, 384, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (2): TransformerLayer(\n",
       "        (dec_attn): MultiHeadAttn(\n",
       "          (qkv_net): Linear(in_features=384, out_features=192, bias=True)\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "          (dropatt): Dropout(p=0.1, inplace=False)\n",
       "          (o_net): Linear(in_features=64, out_features=384, bias=False)\n",
       "          (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ff): PositionwiseConvFF(\n",
       "          (CoreNet): Sequential(\n",
       "            (0): SeparableConv(\n",
       "              (depthwise): Conv1d(384, 384, kernel_size=(3,), stride=(1,), padding=(1,), groups=384)\n",
       "              (pointwise): Conv1d(384, 1536, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (1): ReLU()\n",
       "            (2): SeparableConv(\n",
       "              (depthwise): Conv1d(1536, 1536, kernel_size=(3,), stride=(1,), padding=(1,), groups=1536)\n",
       "              (pointwise): Conv1d(1536, 384, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (3): TransformerLayer(\n",
       "        (dec_attn): MultiHeadAttn(\n",
       "          (qkv_net): Linear(in_features=384, out_features=192, bias=True)\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "          (dropatt): Dropout(p=0.1, inplace=False)\n",
       "          (o_net): Linear(in_features=64, out_features=384, bias=False)\n",
       "          (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ff): PositionwiseConvFF(\n",
       "          (CoreNet): Sequential(\n",
       "            (0): SeparableConv(\n",
       "              (depthwise): Conv1d(384, 384, kernel_size=(3,), stride=(1,), padding=(1,), groups=384)\n",
       "              (pointwise): Conv1d(384, 1536, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (1): ReLU()\n",
       "            (2): SeparableConv(\n",
       "              (depthwise): Conv1d(1536, 1536, kernel_size=(3,), stride=(1,), padding=(1,), groups=1536)\n",
       "              (pointwise): Conv1d(1536, 384, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (4): TransformerLayer(\n",
       "        (dec_attn): MultiHeadAttn(\n",
       "          (qkv_net): Linear(in_features=384, out_features=192, bias=True)\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "          (dropatt): Dropout(p=0.1, inplace=False)\n",
       "          (o_net): Linear(in_features=64, out_features=384, bias=False)\n",
       "          (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ff): PositionwiseConvFF(\n",
       "          (CoreNet): Sequential(\n",
       "            (0): SeparableConv(\n",
       "              (depthwise): Conv1d(384, 384, kernel_size=(3,), stride=(1,), padding=(1,), groups=384)\n",
       "              (pointwise): Conv1d(384, 1536, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (1): ReLU()\n",
       "            (2): SeparableConv(\n",
       "              (depthwise): Conv1d(1536, 1536, kernel_size=(3,), stride=(1,), padding=(1,), groups=1536)\n",
       "              (pointwise): Conv1d(1536, 384, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (5): TransformerLayer(\n",
       "        (dec_attn): MultiHeadAttn(\n",
       "          (qkv_net): Linear(in_features=384, out_features=192, bias=True)\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "          (dropatt): Dropout(p=0.1, inplace=False)\n",
       "          (o_net): Linear(in_features=64, out_features=384, bias=False)\n",
       "          (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ff): PositionwiseConvFF(\n",
       "          (CoreNet): Sequential(\n",
       "            (0): SeparableConv(\n",
       "              (depthwise): Conv1d(384, 384, kernel_size=(3,), stride=(1,), padding=(1,), groups=384)\n",
       "              (pointwise): Conv1d(384, 1536, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (1): ReLU()\n",
       "            (2): SeparableConv(\n",
       "              (depthwise): Conv1d(1536, 1536, kernel_size=(3,), stride=(1,), padding=(1,), groups=1536)\n",
       "              (pointwise): Conv1d(1536, 384, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pitch_predictor): TemporalPredictor(\n",
       "    (layers): Sequential(\n",
       "      (0): ConvReLUNorm(\n",
       "        (conv): SeparableConv(\n",
       "          (depthwise): Conv1d(384, 384, kernel_size=(3,), stride=(1,), padding=(1,), groups=384)\n",
       "          (pointwise): Conv1d(384, 256, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): ConvReLUNorm(\n",
       "        (conv): SeparableConv(\n",
       "          (depthwise): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "          (pointwise): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (fc): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       "  (pitch_emb): SeparableConv(\n",
       "    (depthwise): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (pointwise): Conv1d(1, 384, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (proj): Linear(in_features=384, out_features=80, bias=True)\n",
       "  (attention): ConvAttention(\n",
       "    (softmax): Softmax(dim=3)\n",
       "    (log_softmax): LogSoftmax(dim=3)\n",
       "    (query_proj): Sequential(\n",
       "      (0): ConvNorm(\n",
       "        (conv): Conv1d(80, 160, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      )\n",
       "      (1): ReLU()\n",
       "      (2): ConvNorm(\n",
       "        (conv): Conv1d(160, 80, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (3): ReLU()\n",
       "      (4): ConvNorm(\n",
       "        (conv): Conv1d(80, 80, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (key_proj): Sequential(\n",
       "      (0): ConvNorm(\n",
       "        (conv): Conv1d(384, 768, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      )\n",
       "      (1): ReLU()\n",
       "      (2): ConvNorm(\n",
       "        (conv): Conv1d(768, 80, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tts_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "6a8422eeb13ba8f92f71047f64b5c33152e234c2bbad3f45433feda7b6f3b4c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
