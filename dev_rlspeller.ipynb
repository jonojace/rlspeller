{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4207e21b-d910-485b-8b9c-3fc7d5a59c5a",
   "metadata": {},
   "source": [
    "# Goal of this notebook\n",
    "\n",
    "Develop a training loop for finetuning ASR models using TTS loss by recreating RL training found in RL4LMs/rl4lms/envs/text_generation/training_utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70687ad-9f13-4cdf-8ef7-07eecb34f496",
   "metadata": {},
   "source": [
    "# automatic reloading magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9618cff7-0dc3-4a44-a4f7-7dbe732ded51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738aac35-fdd1-4452-aff0-92caa77ec5ab",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c8a89c2-38ea-4778-8028-0c7854152301",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import List, Dict, Tuple, Any"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b236619f-6c04-44b1-a697-a342417a6694",
   "metadata": {},
   "source": [
    "# HPARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8a11879-640c-433e-a192-9c8b551d8ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    \"softdtw_temp\": 0.01,\n",
    "    \"softdtw_bandwidth\": 120,\n",
    "    \"dist_func\": \"l1\",\n",
    "    \"sentencepiece_model_path\": \"/home/s1785140/speechbrain/templates/speech_recognition_CharTokens_NoLM/Tokenizer/save/0_char.model\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e877615-a6ff-4755-a7e4-e6f72e542432",
   "metadata": {},
   "source": [
    "# TOKENIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0505c38d-bc92-4f84-9f1f-cfc942ad337d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "# load pretrained tokenizer used to tokenizer ASR training inputs \n",
    "import sentencepiece as spm \n",
    "spm_path = hparams[\"sentencepiece_model_path\"]\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(spm_path)\n",
    "print(sp.vocab_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4af21be-9224-4c45-87f6-b86a8d7c63ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 10 2 12 12 4 1 17 4 9 12 11 1 16 20 1 6 5 16 2 1 7 8 1 26 5 8 4 6\n"
     ]
    }
   ],
   "source": [
    "# test tokenizer\n",
    "s = \"hello world my name is jason\"\n",
    "# TODO pass string through text cleaners? \n",
    "encoded = sp.EncodeAsIds(s)\n",
    "assert 0 not in encoded, \"tried to encode an unknown character\"\n",
    "print(\" \".join(str(idx) for idx in encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe3c6048-79c5-47b4-9524-88d2e36ad8d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello world my name is jason'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.DecodeIds(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a387be4-9390-459d-92a5-2389ae883ed4",
   "metadata": {},
   "source": [
    "# DATAPOOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13ff58d-9f56-4c45-aed4-85ed9ddddff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(init=True)\n",
    "class Sample:\n",
    "    id: str # \n",
    "    gt_mel_path: str # full path to mel spectrogram\n",
    "    gt_text: str # original spelling of word\n",
    "    meta_data: Dict[str, Any] = None\n",
    "\n",
    "\n",
    "class ASRPool:\n",
    "    def __init__(self, samples: List[Sample]):\n",
    "        self._samples = samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._samples)\n",
    "\n",
    "    def __getitem__(self, ix: int) -> Sample:\n",
    "        if ix >= len(self):\n",
    "            raise StopIteration\n",
    "        sample = self._samples[ix]\n",
    "        return sample, 1.0\n",
    "\n",
    "    def sample(self) -> Sample:\n",
    "        random_sample = random.choice(self._samples)\n",
    "        return random_sample\n",
    "\n",
    "    @abstractclassmethod\n",
    "    def prepare(cls, **args) -> 'TextGenPool':\n",
    "        \"\"\"\n",
    "        A factory method to instantiate data pool\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def split(self, split_ratios: List[float]) -> List['TextGenPool']:\n",
    "        start_ix = 0\n",
    "        pools = []\n",
    "        for ratio in split_ratios:\n",
    "            count = int(len(self) * ratio)\n",
    "            end_ix = start_ix + count\n",
    "            pools.append(type(self)(self._samples[start_ix: end_ix]))\n",
    "            start_ix = end_ix\n",
    "        return pools\n",
    "    \n",
    "class LJSpeech(ASRPool):\n",
    "    @classmethod\n",
    "    def prepare(cls, split: str,\n",
    "                representation: str = 'subtable',\n",
    "                **args) -> 'ASRPool':\n",
    "        \n",
    "        ds = load_dataset('LJSpeech')\n",
    "        samples = []\n",
    "        split_id = LJSpeech.gen_split_name(split)\n",
    "        n_samples = len(ds[split_id])\n",
    "        for ix, item in tqdm(enumerate(ds[split_id]),\n",
    "            sample = Sample(id=f\"{split}_{ix}\",\n",
    "                            prompt_or_input_text=prompt,\n",
    "                            references=targets,\n",
    "                            meta_data={\n",
    "                                \"raw_table\": item\n",
    "                            }\n",
    "                            )\n",
    "            samples.append(sample)\n",
    "\n",
    "        pool_instance = cls(samples)\n",
    "        return pool_instance\n",
    "                             \n",
    "    @staticmethod\n",
    "    def gen_split_name(split: str):\n",
    "        if split == \"train\":\n",
    "            split_name = \"train\"\n",
    "        elif split == \"val\":\n",
    "            split_name = \"validation\"\n",
    "        elif split == \"test\":\n",
    "            split_name = \"test\"\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        return split_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe55d99-e0c0-4208-9020-2b297517972d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datapool = _get_datapool_by_split(\"train\")\n",
    "val_datapool = _get_datapool_by_split(\"val\")\n",
    "test_datapool = _get_datapool_by_split(\"test\")\n",
    "\n",
    "samples_by_split = {\n",
    "    \"train\": [(sample, weight)\n",
    "              for sample, weight in train_datapool],\n",
    "    \"val\": [sample for sample, _ in val_datapool],\n",
    "    \"test\": [sample for sample, _ in test_datapool]\n",
    "}\n",
    "return samples_by_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674722a6-d6ee-4feb-9f63-d8b8b893e619",
   "metadata": {},
   "source": [
    "# REWARD FUNCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835c2708-462e-46a8-a945-bda08b859ed8",
   "metadata": {},
   "source": [
    "## funcs to load pretrained fastpitch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "945147f5-5dc5-4367-affe-08ae0291e6d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "from fastpitch import models as fastpitch_model\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Fastpitch Model Config Parser', allow_abbrev=False)\n",
    "parser = fastpitch_model.parse_model_args('FastPitch', parser)\n",
    "args, unk_args = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a1df11c-91d2-4aeb-b966-1dbc9e465def",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING unknown args: ['-f', '/disk/nfs/ostrom/s1785140/.local/share/jupyter/runtime/kernel-24870030-07ff-4c9f-ad70-a5ba8ee77cc9.json']\n"
     ]
    }
   ],
   "source": [
    "print(\"WARNING!!! unknown args:\", unk_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ce3ef1-1359-4f8e-bfae-ee91a6bc3a54",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Training command for no punctuation fastpitch:\n",
    "\n",
    "```bash\n",
    "cd \n",
    "source activate_respeller.sh\n",
    "\n",
    "cd ~/respeller/fastpitch\n",
    "\n",
    "EXP_NAME=halved_ljspeech_data_nospaces_noeos_pad_lowercase_nopunc\n",
    "\n",
    "DATA_ROOT=~/data/ljspeech_fastpitch\n",
    "CHECKPOINT_DIR=exps\n",
    "mkdir $CHECKPOINT_DIR\n",
    "HIFIGAN_CHKPT=~/pretrained_models/hifigan/ljspeech/LJ_V1/generator_v1\n",
    "HIFIGAN_CFG=~/pretrained_models/hifigan/ljspeech/LJ_V1/config.json\n",
    "MASTER_ADDR=`hostname -s`\n",
    "FILELIST_STEM=wav_text_filelist\n",
    "\n",
    "./sbatch.sh python train.py \\\n",
    "  --dataset-path $DATA_ROOT \\\n",
    "  --output $CHECKPOINT_DIR/$EXP_NAME \\\n",
    "  --training-files $DATA_ROOT/train_meta_half.txt \\\n",
    "  --validation-files $DATA_ROOT/val_meta_half.txt \\\n",
    "  --pitch-mean-std-file $DATA_ROOT/pitches_stats__${FILELIST_STEM}.json \\\n",
    "  --input-type char \\\n",
    "  --symbol-set english_pad_lowercase_nopunc \\\n",
    "  --text-cleaners lowercase_no_punc \\\n",
    "  --epochs 1000 \\\n",
    "  --epochs-per-checkpoint 10 \\\n",
    "  --batch-size 16 \\\n",
    "  --use-mas \\\n",
    "  --cuda \\\n",
    "  --hifigan $HIFIGAN_CHKPT \\\n",
    "  --hifigan-config $HIFIGAN_CFG \\\n",
    "  --use-sepconv \\\n",
    "  --master-addr $MASTER_ADDR \\\n",
    "  --checkpoint-path /home/s1785140/respeller/fastpitch/exps/halved_ljspeech_data_nospaces_noeos_pad_lowercase_nopunc/FastPitch_checkpoint_290.pt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e59671f-126c-46a1-899c-e3ff81adb541",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# change values of some args to match the config of the pretrained model \n",
    "args.local_rank = 0\n",
    "args.use_mas = True\n",
    "args.use_sepconv = True\n",
    "args.cuda = torch.cuda.is_available()\n",
    "args.input_type = 'char'\n",
    "args.symbol_set = 'english_pad_lowercase_nopunc'\n",
    "args.n_speakers = 1\n",
    "args.fastpitch_chkpt = \"/home/s1785140/respeller/fastpitch/exps/halved_ljspeech_data_nospaces_noeos_pad_lowercase_nopunc/FastPitch_checkpoint_1000.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e53c29d-d9ce-4e99-ae38-cac96fd5b007",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model and optimizer state from /home/s1785140/respeller/fastpitch/exps/halved_ljspeech_data_nospaces_noeos_pad_lowercase_nopunc/FastPitch_checkpoint_1000.pt\n",
      "Finished loading TTS model!\n"
     ]
    }
   ],
   "source": [
    "def load_checkpoint(args, model, filepath):\n",
    "    if args.local_rank == 0:\n",
    "        print(f'Loading model and optimizer state from {filepath}')\n",
    "    checkpoint = torch.load(filepath, map_location='cpu')\n",
    "    sd = {k.replace('module.', ''): v\n",
    "          for k, v in checkpoint['state_dict'].items()}\n",
    "    getattr(model, 'module', model).load_state_dict(sd)\n",
    "    return model\n",
    "\n",
    "def load_pretrained_fastpitch(args):\n",
    "    # load chkpt\n",
    "    device = torch.device('cuda' if args.cuda else 'cpu')\n",
    "    model_config = fastpitch_model.get_model_config('FastPitch', args)\n",
    "    fastpitch = fastpitch_model.get_model('FastPitch', model_config, device, forward_is_infer=True)\n",
    "    load_checkpoint(args, fastpitch, args.fastpitch_chkpt)\n",
    "    # get information about grapheme embedding table\n",
    "    n_symbols = fastpitch.encoder.word_emb.weight.size(0)\n",
    "    embedding_dim = fastpitch.encoder.word_emb.weight.size(1)\n",
    "    return fastpitch, model_config, n_symbols, embedding_dim\n",
    "\n",
    "# from fastpitch.fastpitch.transformer import FFTransformer\n",
    "fastpitch, model_config, n_symbols, embedding_dim = load_pretrained_fastpitch(args)\n",
    "print(\"Finished loading TTS model!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46e4101-61dc-4e18-8ab2-40ee587d2a64",
   "metadata": {},
   "source": [
    "## TTSMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8540b6e0-950c-4c46-ade2-07870b934c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TTSMetric:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_path,\n",
    "    ):\n",
    "        self.tts_model = load_fastpitch(model_path)\n",
    "        self.softdtw_loss = criterion = SoftDTW(\n",
    "            use_cuda=torch.cuda.is_available(), \n",
    "            gamma=hparams[\"softdtw_temp\"], \n",
    "            bandwidth=hparams[\"softdtw_bandwidth\"],\n",
    "            dist_func=hparams[\"dist_func\"],\n",
    "        )\n",
    "    \n",
    "    def __call__(\n",
    "        self,\n",
    "        predicted_texts: List[str], # [bsz]\n",
    "        reference_mels: torch.Tensor, # [bsz, seqlen, dim]\n",
    "    ) -> float:\n",
    "        \"\"\"return softdtw loss between two batches of mel-spectrograms\n",
    "        averaged across batch dimension\"\"\"\n",
    "        predicted_mels = self.tts_model(predicted_texts)\n",
    "        return self.softdtw_loss(predicted_mels, reference_mels).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e306d2-b402-4974-977f-a5205ab7f3ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ttsmetric = TTSMetric(hparams[\"tts_model_path\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def187a5-028a-42a6-8684-b05975969dbd",
   "metadata": {},
   "source": [
    "## TTSRewardFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e002d148-d914-49c8-8569-de1e7e86134d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TTSRewardFunction:\n",
    "    \"\"\"TTS reward function\"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        model_path: str,\n",
    "        shaping_fn: str = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self._metric = TTSMetric(model_path)\n",
    "        \n",
    "    def __call__(\n",
    "        self,\n",
    "        current_observation: Observation,\n",
    "        action: int,\n",
    "        next_observation: Observation,\n",
    "        done: bool,\n",
    "        meta_info: Dict[str, Any] = None,\n",
    "    ):\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcffa0fb-8585-42ba-a462-2fd42ce3af17",
   "metadata": {},
   "source": [
    "# ENVIRONMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1166f6f4-446f-4b6b-9960-28add60e8705",
   "metadata": {},
   "source": [
    "## create custom env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd7ecda-44d0-4d9c-8940-65c707b4916b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from gym import spaces\n",
    "\n",
    "class ASREnv(gym.Env):\n",
    "    \"\"\"Custom Environment that follows gym interface.\"\"\"\n",
    "    \n",
    "    # below taken from Gym code https://github.com/openai/gym/blob/master/gym/core.py\n",
    "    r\"\"\"The main OpenAI Gym class.\n",
    "    It encapsulates an environment with arbitrary behind-the-scenes dynamics.\n",
    "    An environment can be partially or fully observed.\n",
    "    The main API methods that users of this class need to know are:\n",
    "    - :meth:`step` - Takes a step in the environment using an action returning the next observation, reward,\n",
    "      if the environment terminated and observation information.\n",
    "    - :meth:`reset` - Resets the environment to an initial state, returning the initial observation and observation information.\n",
    "    - :meth:`render` - Renders the environment observation with modes depending on the output\n",
    "    - :meth:`close` - Closes the environment, important for rendering where pygame is imported\n",
    "    And set the following attributes:\n",
    "    - :attr:`action_space` - The Space object corresponding to valid actions\n",
    "    - :attr:`observation_space` - The Space object corresponding to valid observations\n",
    "    - :attr:`reward_range` - A tuple corresponding to the minimum and maximum possible rewards\n",
    "    - :attr:`spec` - An environment spec that contains the information used to initialise the environment from `gym.make`\n",
    "    - :attr:`metadata` - The metadata of the environment, i.e. render modes\n",
    "    - :attr:`np_random` - The random number generator for the environment\n",
    "    Note: a default reward range set to :math:`(-\\infty,+\\infty)` already exists. Set it if you want a narrower range.\n",
    "    \"\"\"\n",
    "\n",
    "    metadata = {\"render.modes\": [\"human\"]}\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        tokenizer, \n",
    "        reward_function,\n",
    "        samples,\n",
    "        \n",
    "    ):\n",
    "        \"\"\"Generic RL environment to generate ASR hypotheses from input audio\"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self._vocab_size = tokenizer.vocab_size\n",
    "        self.reward_function = reward_function\n",
    "        for sample, weight in samples:\n",
    "            self.sampler_for_replaying.add(sample, weight)\n",
    "        \n",
    "        # Define action and observation space\n",
    "        # They must be gym.spaces objects\n",
    "        self.action_space = spaces.Discrete(n=self._vocab_size)\n",
    "        self.observation_space = DictSpace(\n",
    "            {\n",
    "                # we have to provide fixed sized inputs (padded) because sb3 support for DictObsersevation is limited\n",
    "                # while creating rollout buffers, observations are concatenated for each key\n",
    "                \"prompt_or_input_encoded_pt\": spaces.Box(\n",
    "                    low=0, high=self._vocab_size, shape=(self._max_text_length,)\n",
    "                ),\n",
    "                \"prompt_or_input_attention_mask_pt\": spaces.Box(\n",
    "                    low=0, high=1, shape=(self._max_text_length,)\n",
    "                ),\n",
    "                \"context_encoded_pt\": spaces.Box(\n",
    "                    low=0, high=self._vocab_size, shape=(self.max_steps,)\n",
    "                ),\n",
    "                \"context_attention_mask_pt\": spaces.Box(\n",
    "                    low=0, high=1, shape=(self.max_steps,)\n",
    "                ),\n",
    "                \"input_encoded_pt\": spaces.Box(\n",
    "                    low=0,\n",
    "                    high=self._vocab_size,\n",
    "                    shape=(self._max_text_length + self.max_steps,),\n",
    "                ),\n",
    "                \"input_attention_mask_pt\": spaces.Box(\n",
    "                    low=0, high=1, shape=(self._max_text_length + self.max_steps,)\n",
    "                ),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def step(self, action):\n",
    "        self.__time_step += 1\n",
    "\n",
    "        # previous obs\n",
    "        previous_obs = self.__current_obs\n",
    "\n",
    "        # just update the context tensor and gets the new observation\n",
    "        self.__current_obs = self.__current_obs.update(action, self.tokenizer)\n",
    "\n",
    "        # decide if the episode is finished or not\n",
    "        done = (action == self.tokenizer.eos_token_id and self._terminate_on_eos) or (\n",
    "            self.__time_step == self.max_steps\n",
    "        )\n",
    "\n",
    "        # compute reward\n",
    "        if not isinstance(self.reward_function, BatchedRewardFunction):\n",
    "            reward = (\n",
    "                None\n",
    "                if self.reward_function is None\n",
    "                else self.reward_function(\n",
    "                    previous_obs,\n",
    "                    action,\n",
    "                    self.__current_obs,\n",
    "                    done,\n",
    "                    self.__current_obs.meta_info,\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            reward = -inf  # will be overridden later\n",
    "\n",
    "        # populate additional info\n",
    "        info = {\n",
    "            \"output\": self.__current_obs.context_text,\n",
    "            \"action_history\": self.__current_obs.action_history,\n",
    "            \"reference_text\": self.__current_obs.target_or_reference_texts,\n",
    "            \"prompt_text\": self.__current_obs.prompt_or_input_text,\n",
    "            \"prev_output\": previous_obs.context_text,\n",
    "            \"meta_info\": previous_obs.meta_info,\n",
    "        }\n",
    "\n",
    "        dict_observation = self.__current_obs.to_dict()\n",
    "        return dict_observation, reward, done, info\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Resets the environment and starts a new episode\n",
    "        \"\"\"\n",
    "        # gets a new sample if not provided\n",
    "        if sample is None:\n",
    "            sample = self.sampler_for_replaying.sample(size=1)[0]\n",
    "        self.__current_sample = sample\n",
    "\n",
    "        # init the observation\n",
    "        self.__current_obs = Observation.init_from_sample(\n",
    "            sample,\n",
    "            self.tokenizer,\n",
    "            self._max_text_length,\n",
    "            self.max_steps,\n",
    "            self._prompt_truncation_side,\n",
    "            self._context_start_token,\n",
    "            sample.meta_data,\n",
    "        )\n",
    "\n",
    "        # start the time step counter\n",
    "        self.__time_step = 0\n",
    "\n",
    "        dict_observation = self.__current_obs.to_dict()\n",
    "        return dict_observation\n",
    "\n",
    "    def render(self):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6497b419-fadb-4e3e-a546-d4effe989983",
   "metadata": {
    "tags": []
   },
   "source": [
    "## check that env follows Gym interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525eacca-aed7-4ef9-b7dc-f9c3aa6719e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.env_checker import check_env\n",
    "\n",
    "env = CustomEnv(arg1, ...)\n",
    "# It will check your custom environment and output additional warnings if needed\n",
    "check_env(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dece3d-9a3b-49dc-a5c3-a6edfaf1d366",
   "metadata": {},
   "source": [
    "# POLICY/ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12d79c3-b288-40b5-9d19-8d5c504ef21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Dict, List, Optional, Tuple, Type, Union\n",
    "\n",
    "from gym import spaces\n",
    "import torch as th\n",
    "from torch import nn\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.policies import ActorCriticPolicy\n",
    "\n",
    "\n",
    "class PPO(OnPolicyAlgorithm):\n",
    "    \"\"\"\n",
    "    Created with reference to Seq2SeqLMActorCriticPolicy\n",
    "    \n",
    "    Custom network for policy and value function.\n",
    "    It receives as input the features extracted by the features extractor.\n",
    "\n",
    "    :param feature_dim: dimension of the features extracted with the features_extractor (e.g. features from a CNN)\n",
    "    :param last_layer_dim_pi: (int) number of units for the last layer of the policy network\n",
    "    :param last_layer_dim_vf: (int) number of units for the last layer of the value network\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        feature_dim: int,\n",
    "        last_layer_dim_pi: int = 64,\n",
    "        last_layer_dim_vf: int = 64,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # IMPORTANT:\n",
    "        # Save output dimensions, used to create the distributions\n",
    "        self.latent_dim_pi = last_layer_dim_pi\n",
    "        self.latent_dim_vf = last_layer_dim_vf\n",
    "\n",
    "        # Policy network\n",
    "        self.policy_net = nn.Sequential(\n",
    "            nn.Linear(feature_dim, last_layer_dim_pi), nn.ReLU()\n",
    "        )\n",
    "        # Value network\n",
    "        self.value_net = nn.Sequential(\n",
    "            nn.Linear(feature_dim, last_layer_dim_vf), nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, features: th.Tensor) -> Tuple[th.Tensor, th.Tensor]:\n",
    "        \"\"\"\n",
    "        :return: (th.Tensor, th.Tensor) latent_policy, latent_value of the specified network.\n",
    "            If all layers are shared, then ``latent_policy == latent_value``\n",
    "        \"\"\"\n",
    "        return self.forward_actor(features), self.forward_critic(features)\n",
    "\n",
    "    def forward_actor(self, features: th.Tensor) -> th.Tensor:\n",
    "        return self.policy_net(features)\n",
    "\n",
    "    def forward_critic(self, features: th.Tensor) -> th.Tensor:\n",
    "        return self.value_net(features)\n",
    "\n",
    "\n",
    "class CustomActorCriticPolicy(ActorCriticPolicy):\n",
    "    def __init__(\n",
    "        self,\n",
    "        observation_space: spaces.Space,\n",
    "        action_space: spaces.Space,\n",
    "        lr_schedule: Callable[[float], float],\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ):\n",
    "\n",
    "        super().__init__(\n",
    "            observation_space,\n",
    "            action_space,\n",
    "            lr_schedule,\n",
    "            # Pass remaining arguments to base class\n",
    "            *args,\n",
    "            **kwargs,\n",
    "        )\n",
    "        # Disable orthogonal initialization\n",
    "        self.ortho_init = False\n",
    "\n",
    "    def _build_mlp_extractor(self) -> None:\n",
    "        self.mlp_extractor = CustomNetwork(self.features_dim)\n",
    "\n",
    "\n",
    "model = PPO(CustomActorCriticPolicy, \"CartPole-v1\", verbose=1)\n",
    "model.learn(5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddd7e9d-1caf-4cba-b431-92a8e3e9bb51",
   "metadata": {},
   "source": [
    "# collect rollouts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1cb4a9-b229-46e6-9700-4b0bf71e434b",
   "metadata": {},
   "source": [
    "# create rollout buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdfc397-9e16-4f15-b1c5-b2571e45265a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
