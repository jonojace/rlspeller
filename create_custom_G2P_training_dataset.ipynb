{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39e0f974-fdaa-4e78-bb39-ba91c3189f1a",
   "metadata": {},
   "source": [
    "# Goal of this notebook\n",
    "\n",
    "- use certain metrics (LM perplexity, G2P error) to identify wordtypes that are more likely to be mispronounced by our grapheme-input TTS system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa0fd09-7310-41b3-a86e-985037e0f5c0",
   "metadata": {},
   "source": [
    "# automatic reloading magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "aeda9093-4c98-46c1-a7d7-0edad8bcb0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5b9302-7704-409e-b496-dab91dbac0a7",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "658c0e24-f88f-4f5d-a6fa-9e4e860e4a50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import jiwer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72abf8f6-bbed-401f-b160-5fd99426f4e8",
   "metadata": {},
   "source": [
    "# check if have correct type of node "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c1b6e438-88c6-4129-be4e-c67f7c45811f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "barre.inf.ed.ac.uk\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "\n",
    "# print hostname to make sure we are on correct node\n",
    "disallowed_nodes = ['escience6']\n",
    "hostname = socket.gethostname()\n",
    "print(hostname)\n",
    "node = hostname.split('.')[0]\n",
    "if node in disallowed_nodes:\n",
    "    raise ValueError(f\"Running on disallowed node {node}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9169c48f-261e-4e4c-9a26-33020fb901bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.is_available()\n",
    "assert torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97c2e95-0e24-4ea6-a902-350056452164",
   "metadata": {},
   "source": [
    "# Load OOV list\n",
    "\n",
    "(wordtypes not seen in the half of LJSpeech used to train TTS and ASR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "28a6ac11-1f51-44c1-abe2-2b026560d076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original before cleaning/sampling len(oovs)=8343\n"
     ]
    }
   ],
   "source": [
    "# get oov wordtypes list (words that are not seen in tts training)\n",
    "oov_wordlist_path = '/home/s1785140/data/ljspeech_fastpitch/oov_list.json'\n",
    "with open(oov_wordlist_path, 'r') as f:\n",
    "    oovs_and_freqs = json.load(f)\n",
    "    \n",
    "oovs = set(w.strip() for w in oovs_and_freqs.keys())\n",
    "print(f'original before cleaning/sampling {len(oovs)=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de77af14-466e-444d-a5bd-b76c9f4c140c",
   "metadata": {},
   "source": [
    "# Load G2P pronunciation lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a1cb1807-44bb-418b-835c-ba9992860703",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset librig2p-nostress (/home/s1785140/.cache/huggingface/datasets/flexthink___librig2p-nostress/default/0.0.0/95c204c6be42796a753ef410b5dfce2bfa21d61b51f0c3ffe85cf6e3a4dee65f)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8062053425204fad8e850d276330ae2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load lexicon that G2P model was trained on\n",
    "dataset_dict = load_dataset(\"flexthink/librig2p-nostress\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "249eda8c-2d6b-48cf-9626-eda56f19d239",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.arrow_dataset.Dataset"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset_dict['lexicon_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e8aead54-bc3f-4530-847c-6a05eb3a8cfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# combine data splits in the lexicon \n",
    "# (as we are not training G2P, don't need train valid test splits)\n",
    "from datasets import concatenate_datasets\n",
    "datasets = [dataset_dict['lexicon_train'], dataset_dict['lexicon_valid'], dataset_dict['lexicon_test']]\n",
    "dataset = concatenate_datasets(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "70c388e9-2e51-422d-8b94-77b5fafbe853",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create dict of wordtype to pronunciation\n",
    "lexicon = {}\n",
    "for char, phn in zip(dataset['char'], dataset['phn']):\n",
    "    lexicon[char.lower().strip()] = phn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707abef2-051b-4bc0-bf86-5684c2833a58",
   "metadata": {},
   "source": [
    "# only consider the OOV words that are in the pronunciation lexicon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b72decc9-87b4-4eda-806e-5cef4f69383e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8343"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(oovs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "83a96a53-ed17-4a5c-aa60-c0bcab6e7d18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7966"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oovs_in_lexicon = oovs.intersection(lexicon.keys())\n",
    "len(oovs_in_lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f1aa82ff-84ca-4e60-87c0-3496aff8c1ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "377"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oovs_not_in_lexicon = oovs - oovs_in_lexicon\n",
    "len(oovs_not_in_lexicon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34dd0d5-2cdf-47f0-af4b-0d9b98ad960b",
   "metadata": {},
   "source": [
    "# Compare LibriG2P coverage against CMUdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "7033912d-0722-4551-871c-8112d7e13934",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cmudict in /disk/nfs/ostrom/s1785140/miniconda3/envs/speller/lib/python3.8/site-packages (1.0.13)\n",
      "Requirement already satisfied: importlib-resources<6.0.0,>=5.10.1 in /disk/nfs/ostrom/s1785140/miniconda3/envs/speller/lib/python3.8/site-packages (from cmudict) (5.12.0)\n",
      "Requirement already satisfied: importlib-metadata<6.0.0,>=5.1.0 in /disk/nfs/ostrom/s1785140/miniconda3/envs/speller/lib/python3.8/site-packages (from cmudict) (5.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /disk/nfs/ostrom/s1785140/miniconda3/envs/speller/lib/python3.8/site-packages (from importlib-metadata<6.0.0,>=5.1.0->cmudict) (3.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install cmudict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "bd87196e-338e-4689-9e7e-b5534de35811",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cmudict as cmudict_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f11b1079-a860-4dca-afce-8608328f9073",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cmudict = cmudict_module.dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b530de8-8fa4-439d-a381-c92b231b3e25",
   "metadata": {},
   "source": [
    "## normalise cmudict entries\n",
    "\n",
    "- key: all lowercase\n",
    "- values: phone strings should not hav any stress markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "6126cb74-0db3-40a4-ad89-ffe80ddcc1f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys do not contain any capital letters\n"
     ]
    }
   ],
   "source": [
    "for wordtype in cmudict.keys():\n",
    "    if wordtype.isupper():\n",
    "        raise ValueError\n",
    "else:\n",
    "    print(\"Keys do not contain any capital letters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6af544c7-234c-4878-8229-b79982223d52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prons = cmudict['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a94850c0-8625-4e59-bfb2-68072d29c4ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['K', 'AA1', 'N', 'T', 'EH0', 'N', 'T'],\n",
       " ['K', 'AH0', 'N', 'T', 'EH1', 'N', 'T']]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "e97b1308-08a8-4562-9576-146e361593cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['K', 'AA', 'N', 'T', 'EH', 'N', 'T']"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def strip_stress(pron):\n",
    "    stripped_pron = []\n",
    "    for phn in pron:\n",
    "        stripped_pron.append(phn.strip('0123456789'))\n",
    "    return stripped_pron\n",
    "\n",
    "strip_stress(['K', 'AA1', 'N', 'T', 'EH0', 'N', 'T'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "5f58fa18-1ed7-4713-87cf-ec9d7b05a4ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_cmudict = {}\n",
    "for wordtype, prons in cmudict.items():\n",
    "    new_prons = []\n",
    "    for pron in prons:\n",
    "        new_prons.append(strip_stress(pron))\n",
    "    new_cmudict[wordtype] = new_prons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "bee5b91e-80c5-4768-a4ab-113443f57d38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cmudict = new_cmudict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "3fea7d46-8a77-44d6-968c-88b0fb7e455f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['K', 'AA', 'N', 'T', 'EH', 'N', 'T'], ['K', 'AH', 'N', 'T', 'EH', 'N', 'T']]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmudict['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2647f2-ca47-4989-bafa-485e7b5a4a16",
   "metadata": {},
   "source": [
    "## find words in OOV list that are in CMUDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "f752de63-9b0b-49e6-a368-5f148ac4dbad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8343"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(oovs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "d4a56427-5032-492a-b3d9-d7c500db6125",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7233"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oovs_in_cmudict = oovs.intersection(cmudict.keys())\n",
    "len(oovs_in_cmudict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a7fc4864-d9ad-4bad-905f-d003cefbc1f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1110"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oovs_not_in_cmudict = oovs - oovs_in_cmudict\n",
    "len(oovs_not_in_cmudict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36042d3e-28bf-4031-8114-726b1b7bc8e5",
   "metadata": {},
   "source": [
    "## find OOVs not in LibriG2P or cmudict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "6c81c154-225a-4e02-be9e-414dfa480ad6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "274"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oovs_not_in_cmudict_and_librig2p = oovs_not_in_cmudict.intersection(oovs_not_in_lexicon)\n",
    "len(oovs_not_in_cmudict_and_librig2p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "9d5ad0d1-1c2a-400a-a667-cef66407a4c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accordez',\n",
       " 'adaptively',\n",
       " 'affectionless',\n",
       " 'afterwork',\n",
       " 'agardh',\n",
       " 'agencys',\n",
       " 'agonal',\n",
       " 'akermans',\n",
       " 'akkad',\n",
       " 'aldermens',\n",
       " 'alinement',\n",
       " 'aloman',\n",
       " 'amuhia',\n",
       " 'amylaceous',\n",
       " 'anabolism',\n",
       " 'arachtu',\n",
       " 'argool',\n",
       " 'arke',\n",
       " 'armys',\n",
       " 'arthor',\n",
       " 'askern',\n",
       " 'baddow',\n",
       " 'bagne',\n",
       " 'bamell',\n",
       " 'barbariously',\n",
       " 'bashour',\n",
       " 'batess',\n",
       " 'bbl',\n",
       " 'belian',\n",
       " 'billfolds',\n",
       " 'bodoni',\n",
       " 'bouhes',\n",
       " 'bradawls',\n",
       " 'bringuiers',\n",
       " 'bubbletop',\n",
       " 'buranelli',\n",
       " 'busdriver',\n",
       " 'buxtons',\n",
       " 'cabmans',\n",
       " 'caducibranchs',\n",
       " 'cannings',\n",
       " 'cardiotachyscope',\n",
       " 'catwalks',\n",
       " 'caunts',\n",
       " 'centurys',\n",
       " 'cerebrospinal',\n",
       " 'chaldasan',\n",
       " 'charae',\n",
       " 'chiselers',\n",
       " 'chromatin',\n",
       " 'chromatophores',\n",
       " 'chummage',\n",
       " 'cissian',\n",
       " 'citys',\n",
       " 'cleancutness',\n",
       " 'clipperton',\n",
       " 'collaborates',\n",
       " 'colsman',\n",
       " 'compters',\n",
       " 'conceptualisation',\n",
       " 'condigne',\n",
       " 'connallys',\n",
       " 'conveners',\n",
       " 'countrys',\n",
       " 'courtmartialed',\n",
       " 'crosshair',\n",
       " 'cutdowns',\n",
       " 'cyruss',\n",
       " 'daulby',\n",
       " 'daulbys',\n",
       " 'delarues',\n",
       " 'delustered',\n",
       " 'deoxidation',\n",
       " 'detre',\n",
       " 'diemens',\n",
       " 'dixblanc',\n",
       " 'dollimore',\n",
       " 'drittal',\n",
       " 'duranno',\n",
       " 'dustlike',\n",
       " 'dwyers',\n",
       " 'earthenwares',\n",
       " 'eightthirty',\n",
       " 'elevenfifty',\n",
       " 'eleventhirty',\n",
       " 'embryologists',\n",
       " 'endotracheal',\n",
       " 'entrapper',\n",
       " 'ervay',\n",
       " 'erythraean',\n",
       " 'experimentalize',\n",
       " 'fains',\n",
       " 'familiarization',\n",
       " 'familys',\n",
       " 'fassons',\n",
       " 'fenning',\n",
       " 'fivefifty',\n",
       " 'foregrip',\n",
       " 'fortyish',\n",
       " 'fourfifty',\n",
       " 'fourforty',\n",
       " 'fourthirty',\n",
       " 'ft',\n",
       " 'gardelle',\n",
       " 'gardelles',\n",
       " 'garotting',\n",
       " 'gatesmen',\n",
       " 'gobrias',\n",
       " 'godmanchester',\n",
       " 'gunmans',\n",
       " 'handprinting',\n",
       " 'hangmans',\n",
       " 'harlands',\n",
       " 'harrowbys',\n",
       " 'hematoma',\n",
       " 'henrichson',\n",
       " 'hidells',\n",
       " 'highchair',\n",
       " 'hindlimbs',\n",
       " 'histologist',\n",
       " 'hockers',\n",
       " 'huntons',\n",
       " 'hurchel',\n",
       " 'inanimated',\n",
       " 'intermediacy',\n",
       " 'jamess',\n",
       " 'jehoiakin',\n",
       " 'jensons',\n",
       " 'jermys',\n",
       " 'jumjuma',\n",
       " 'kellermans',\n",
       " 'kerp',\n",
       " 'ketchs',\n",
       " 'knurled',\n",
       " 'koldewey',\n",
       " 'kurrs',\n",
       " 'latonas',\n",
       " 'laverstock',\n",
       " 'lebizen',\n",
       " 'lecasser',\n",
       " 'leew',\n",
       " 'lennies',\n",
       " 'lerigos',\n",
       " 'linnie',\n",
       " 'liquorpond',\n",
       " 'lj',\n",
       " 'lld',\n",
       " 'lubbocks',\n",
       " 'lumpless',\n",
       " 'lyndal',\n",
       " 'macintoshs',\n",
       " 'manacling',\n",
       " 'marchesvan',\n",
       " 'marsolino',\n",
       " 'menobranchus',\n",
       " 'mentelin',\n",
       " 'meteyards',\n",
       " 'misemployment',\n",
       " 'misfires',\n",
       " 'misseurs',\n",
       " 'mohrenschildts',\n",
       " 'mps',\n",
       " 'murret',\n",
       " 'mvd',\n",
       " 'mwddy',\n",
       " 'neilds',\n",
       " 'nejef',\n",
       " 'newmans',\n",
       " 'ninethirty',\n",
       " 'nitrites',\n",
       " 'nonreferral',\n",
       " 'nutfield',\n",
       " 'officialy',\n",
       " 'omally',\n",
       " 'onefifteen',\n",
       " 'onefifty',\n",
       " 'oneforty',\n",
       " 'ontogenic',\n",
       " 'ordinarys',\n",
       " 'orientgesellschaft',\n",
       " 'orwells',\n",
       " 'oswaldskovitch',\n",
       " 'overconcentrated',\n",
       " 'pannartz',\n",
       " 'pegsworth',\n",
       " 'perennibranchs',\n",
       " 'phipoe',\n",
       " 'photosynthetic',\n",
       " 'phylogenic',\n",
       " 'piemen',\n",
       " 'plumule',\n",
       " 'praecipe',\n",
       " 'projectionist',\n",
       " 'propagandizing',\n",
       " 'prossa',\n",
       " 'protist',\n",
       " 'protista',\n",
       " 'protists',\n",
       " 'prusakova',\n",
       " 'pugnaciousness',\n",
       " 'punchmark',\n",
       " 'pushbutton',\n",
       " 'quigleys',\n",
       " 'reappropriate',\n",
       " 'recollectedness',\n",
       " 'redesdales',\n",
       " 'reemployed',\n",
       " 'reexpand',\n",
       " 'refaced',\n",
       " 'remands',\n",
       " 'romaness',\n",
       " 'roupells',\n",
       " 'rubeus',\n",
       " 'ryders',\n",
       " 'saffery',\n",
       " 'salsallat',\n",
       " 'satler',\n",
       " 'schizoid',\n",
       " 'schleidens',\n",
       " 'schwanns',\n",
       " 'selvages',\n",
       " 'sevenfifteen',\n",
       " 'seventhirty',\n",
       " 'sharings',\n",
       " 'shoestore',\n",
       " 'shroeder',\n",
       " 'sideposts',\n",
       " 'sinacherib',\n",
       " 'siredon',\n",
       " 'sixthirty',\n",
       " 'societys',\n",
       " 'spectrographic',\n",
       " 'stombaughs',\n",
       " 'stortford',\n",
       " 'stuckeys',\n",
       " 'swandown',\n",
       " 'sweynheim',\n",
       " 'tarpeys',\n",
       " 'taxonomic',\n",
       " 'tenforty',\n",
       " 'tenthirty',\n",
       " 'thistlewoods',\n",
       " 'thornleys',\n",
       " 'threetwenty',\n",
       " 'thurtells',\n",
       " 'toffana',\n",
       " 'toffania',\n",
       " 'tradescantia',\n",
       " 'treviranus',\n",
       " 'trisect',\n",
       " 'trotskyite',\n",
       " 'trulys',\n",
       " 'twelvefifteen',\n",
       " 'twofifteen',\n",
       " 'twoforty',\n",
       " 'twothirty',\n",
       " 'udalric',\n",
       " 'ultrarightists',\n",
       " 'unicellar',\n",
       " 'uninvested',\n",
       " 'unremedied',\n",
       " 'urological',\n",
       " 'vartos',\n",
       " 'vindelin',\n",
       " 'voebels',\n",
       " 'watto',\n",
       " 'wattss',\n",
       " 'weares',\n",
       " 'wiedersheim',\n",
       " 'wiedersheims',\n",
       " 'yardsman',\n",
       " 'zeiners',\n",
       " 'zoospores',\n",
       " 'zulueta'}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oovs_not_in_cmudict_and_librig2p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "33942ccb-5fa8-43b7-8940-99734bddc183",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: num2words in /disk/nfs/ostrom/s1785140/miniconda3/envs/speller/lib/python3.8/site-packages (0.5.12)\n",
      "Requirement already satisfied: docopt>=0.6.2 in /disk/nfs/ostrom/s1785140/miniconda3/envs/speller/lib/python3.8/site-packages (from num2words) (0.6.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install num2words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "4c7cd34f-cd54-4587-b7ec-9e75934fd34a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import num2words\n",
    "from num2words import num2words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "5c98f9d8-a5c5-4b5e-8add-07b5bc4cb9c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'twenty-five'"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num2words(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "2ed4a52a-dd92-4469-9306-f167b3b83fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = [num2words(i).strip('-') for i in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "d42b6e66-6c20-482f-a98b-a30445d9dfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def does_not_contain_num(s):\n",
    "    for num in nums:\n",
    "        if num in s:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "d490c1b7-b24d-43f6-8ff7-0fd7e3239a8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111 len(oovs_not_in_cmudict_and_librig2p)=274\n",
      "222 len(oovs_not_in_cmudict_and_librig2p)=268\n",
      "333 len(oovs_not_in_cmudict_and_librig2p)=246\n"
     ]
    }
   ],
   "source": [
    "## filter this list \n",
    "\n",
    "\n",
    "\n",
    "# word len\n",
    "print(f\"111 {len(oovs_not_in_cmudict_and_librig2p)=}\")\n",
    "oovs_not_in_cmudict_and_librig2p = set(w for w in oovs_not_in_cmudict_and_librig2p if len(w) >= 4)\n",
    "print(f\"222 {len(oovs_not_in_cmudict_and_librig2p)=}\")\n",
    "\n",
    "# not a number\n",
    "oovs_not_in_cmudict_and_librig2p = set(w for w in oovs_not_in_cmudict_and_librig2p if does_not_contain_num(w))\n",
    "print(f\"333 {len(oovs_not_in_cmudict_and_librig2p)=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d4ffe0-18e0-4303-b335-bb7d34e241be",
   "metadata": {},
   "source": [
    "# generate pronunciation for each word in the data used to train ASR/TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "38c9cdfa-868d-4cd2-8f1a-785305610298",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = '/home/s1785140/data/ljspeech_fastpitch/train_meta_half.txt'\n",
    "with open(train_data, 'r') as f:\n",
    "    train_data = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "eeb418f8-77b8-41f8-959f-1fcd5e93e465",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_utts = [l.split('|')[-1] for l in train_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "a1c8b476-526c-41b5-89d1-c1d3c2bb52ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use text cleaner to clean each utt\n",
    "\n",
    "from fastpitch.common.text.cleaners import lowercase_no_punc as text_cleaner\n",
    "\n",
    "train_utts = [text_cleaner(utt) for utt in train_utts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "bd2650cc-6de7-4dc5-9e0e-48a7e91d08c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5612"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_wordtypes = set()\n",
    "for utt in train_utts:\n",
    "    for token in utt.split(' '):\n",
    "        train_wordtypes.add(token)\n",
    "len(train_wordtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "7e129cec-a993-4bdd-af32-cb0ae78f7592",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'friend',\n",
       " 'wear',\n",
       " 'voebel',\n",
       " 'exit',\n",
       " 'surveys',\n",
       " 'procured',\n",
       " 'portions',\n",
       " 'extreme',\n",
       " 'be',\n",
       " 'crowded',\n",
       " 'thieves',\n",
       " 'elbow',\n",
       " 'signature',\n",
       " 'acquitted',\n",
       " 'medicine',\n",
       " 'limited',\n",
       " 'my',\n",
       " 'sister',\n",
       " 'accomplices',\n",
       " 'owners',\n",
       " 'retired',\n",
       " 'led',\n",
       " 'governors',\n",
       " 'crying',\n",
       " 'traders',\n",
       " 'britain',\n",
       " 'fpcc',\n",
       " 'homologies',\n",
       " 'evaded',\n",
       " 'concourse',\n",
       " 'wall',\n",
       " 'june',\n",
       " 'four',\n",
       " 'billions',\n",
       " 'doors',\n",
       " 'latona',\n",
       " 'daughters',\n",
       " 'poisoning',\n",
       " 'barrel',\n",
       " 'exact',\n",
       " 'donnell',\n",
       " 'religious',\n",
       " 'honestly',\n",
       " 'enforcement',\n",
       " 'monies',\n",
       " 'bureau',\n",
       " 'indignation',\n",
       " 'rendered',\n",
       " 'kleins',\n",
       " 'build',\n",
       " 'doubted',\n",
       " 'wonder',\n",
       " 'adduced',\n",
       " 'fluid',\n",
       " 'profound',\n",
       " 'operation',\n",
       " 'gordon',\n",
       " 'appointed',\n",
       " 'alan',\n",
       " 'lancaster',\n",
       " 'temple',\n",
       " 'worn',\n",
       " 'lads',\n",
       " 'wagner',\n",
       " 'belmont',\n",
       " 'attempting',\n",
       " 'about',\n",
       " 'enforced',\n",
       " 'allegations',\n",
       " 'prisoners',\n",
       " 'house',\n",
       " 'warning',\n",
       " 'renewed',\n",
       " 'york',\n",
       " 'fingers',\n",
       " 'books',\n",
       " 'threw',\n",
       " 'tendencies',\n",
       " 'defensive',\n",
       " 'inscription',\n",
       " 'ago',\n",
       " 'badly',\n",
       " 'cuba',\n",
       " 'appear',\n",
       " 'arsenic',\n",
       " 'branches',\n",
       " 'stevenson',\n",
       " 'expressed',\n",
       " 'positively',\n",
       " 'example',\n",
       " 'violently',\n",
       " 'movable',\n",
       " 'unfortunate',\n",
       " 'asserted',\n",
       " 'hartogs',\n",
       " 'active',\n",
       " 'fifteen',\n",
       " 'hulks',\n",
       " 'validity',\n",
       " 'statement',\n",
       " 'complex',\n",
       " 'observation',\n",
       " 'dark',\n",
       " 'solemnity',\n",
       " 'disturbing',\n",
       " 'seeds',\n",
       " 'church',\n",
       " 'purporting',\n",
       " 'card',\n",
       " 'marsalis',\n",
       " 'revill',\n",
       " 'resemblances',\n",
       " 'spoke',\n",
       " 'u',\n",
       " 'shoot',\n",
       " 'reported',\n",
       " 'repeat',\n",
       " 'mandate',\n",
       " 'connected',\n",
       " 'particularly',\n",
       " 'gothic',\n",
       " 'valid',\n",
       " 'recall',\n",
       " 'oswalds',\n",
       " 'porter',\n",
       " 'notorieties',\n",
       " 'written',\n",
       " 'turner',\n",
       " 'fired',\n",
       " 'leads',\n",
       " 'kings',\n",
       " 'originated',\n",
       " 'qualifications',\n",
       " 'wrote',\n",
       " 'files',\n",
       " 'there',\n",
       " 'succession',\n",
       " 'batch',\n",
       " 'roy',\n",
       " 'replica',\n",
       " 'cooperate',\n",
       " 'needs',\n",
       " 'burglar',\n",
       " 'hours',\n",
       " 'green',\n",
       " 'from',\n",
       " 'compelled',\n",
       " 'mile',\n",
       " 'beside',\n",
       " 'crowding',\n",
       " 'cell',\n",
       " 'victim',\n",
       " 'has',\n",
       " 'accord',\n",
       " 'techniques',\n",
       " 'close',\n",
       " 'rent',\n",
       " 'fragment',\n",
       " 'never',\n",
       " 'procedure',\n",
       " 'eyewitnesses',\n",
       " 'found',\n",
       " 'masses',\n",
       " 'prime',\n",
       " 'pulpit',\n",
       " 'finding',\n",
       " 'rules',\n",
       " 'dated',\n",
       " 'manufactory',\n",
       " 'responded',\n",
       " 'copies',\n",
       " 'letter',\n",
       " 'awaited',\n",
       " 'angles',\n",
       " 'seated',\n",
       " 'yes',\n",
       " 'largest',\n",
       " 'evening',\n",
       " 'problems',\n",
       " 'detailed',\n",
       " 'denials',\n",
       " 'were',\n",
       " 'evils',\n",
       " 'rising',\n",
       " 'born',\n",
       " 'executions',\n",
       " 'murphy',\n",
       " 'joshua',\n",
       " 'captured',\n",
       " 'becomes',\n",
       " 'proper',\n",
       " 'thief',\n",
       " 'dust',\n",
       " 'sees',\n",
       " 'yourself',\n",
       " 'knife',\n",
       " 'rain',\n",
       " 'colony',\n",
       " 'vote',\n",
       " 'task',\n",
       " 'strangulation',\n",
       " 'treasury',\n",
       " 'papers',\n",
       " 'bennet',\n",
       " 'approver',\n",
       " 'account',\n",
       " 'comprehensive',\n",
       " 'ghastly',\n",
       " 'continues',\n",
       " 'aged',\n",
       " 'reconstructed',\n",
       " 'gallows',\n",
       " 'bullets',\n",
       " 'slight',\n",
       " 'trusted',\n",
       " 'conception',\n",
       " 'assassinated',\n",
       " 'emphasis',\n",
       " 'unlimited',\n",
       " 'felony',\n",
       " 'powers',\n",
       " 'leaf',\n",
       " 'kind',\n",
       " 'alimentary',\n",
       " 'family',\n",
       " 'robbed',\n",
       " 'searched',\n",
       " 'procedures',\n",
       " 'unit',\n",
       " 'save',\n",
       " 'judgment',\n",
       " 'fbis',\n",
       " 'speculation',\n",
       " 'stairs',\n",
       " 'n',\n",
       " 'part',\n",
       " 'merely',\n",
       " 'listed',\n",
       " 'ending',\n",
       " 'coat',\n",
       " 'quality',\n",
       " 'amounted',\n",
       " 'recommends',\n",
       " 'broken',\n",
       " 'damage',\n",
       " 'memorial',\n",
       " 'rapidly',\n",
       " 'distance',\n",
       " 'records',\n",
       " 'burthen',\n",
       " 'failed',\n",
       " 'capable',\n",
       " 'listing',\n",
       " 'problem',\n",
       " 'formation',\n",
       " 'collective',\n",
       " 'rushed',\n",
       " 'joining',\n",
       " 'decision',\n",
       " 'thing',\n",
       " 'awareness',\n",
       " 'cistern',\n",
       " 'addressing',\n",
       " 'shaken',\n",
       " 'obvious',\n",
       " 'footing',\n",
       " 'maynard',\n",
       " 'tube',\n",
       " 'inmate',\n",
       " 'people',\n",
       " 'packing',\n",
       " 'minutely',\n",
       " 'ministers',\n",
       " 'groups',\n",
       " 'plant',\n",
       " 'confession',\n",
       " 'nothing',\n",
       " 'liaison',\n",
       " 'comparative',\n",
       " 'losing',\n",
       " 'murdered',\n",
       " 'places',\n",
       " 'stole',\n",
       " 'department',\n",
       " 'signs',\n",
       " 'disturbance',\n",
       " 'wanting',\n",
       " 'register',\n",
       " 'seeking',\n",
       " 'thousands',\n",
       " 'southwest',\n",
       " 'gaily',\n",
       " 'constructive',\n",
       " 'communication',\n",
       " 'lived',\n",
       " 'lodgings',\n",
       " 'dressing',\n",
       " 'mountain',\n",
       " 'happy',\n",
       " 'contents',\n",
       " 'claim',\n",
       " 'respective',\n",
       " 'mercy',\n",
       " 'roll',\n",
       " 'pretended',\n",
       " 'rose',\n",
       " 'car',\n",
       " 'downstairs',\n",
       " 'reveal',\n",
       " 'framed',\n",
       " 'resemblance',\n",
       " 'jumped',\n",
       " 'dwelling',\n",
       " 'berlin',\n",
       " 'satisfactorily',\n",
       " 'warder',\n",
       " 'made',\n",
       " 'adequate',\n",
       " 'seeing',\n",
       " 'defining',\n",
       " 'reflect',\n",
       " 'caspar',\n",
       " 'feared',\n",
       " 'devotion',\n",
       " 'experiment',\n",
       " 'spoken',\n",
       " 'sick',\n",
       " 'pushed',\n",
       " 'due',\n",
       " 'atrocious',\n",
       " 'issued',\n",
       " 'waist',\n",
       " 'brown',\n",
       " 'presidents',\n",
       " 'investigations',\n",
       " 'pay',\n",
       " 'norfolk',\n",
       " 'entrance',\n",
       " 'spoil',\n",
       " 'decorum',\n",
       " 'timed',\n",
       " 'airway',\n",
       " 'literature',\n",
       " 'jebb',\n",
       " 'plain',\n",
       " 'times',\n",
       " 'acutely',\n",
       " 'en',\n",
       " 'economic',\n",
       " 'treated',\n",
       " 'unfavorable',\n",
       " 'tread',\n",
       " 'revision',\n",
       " 'bar',\n",
       " 'primary',\n",
       " 'materials',\n",
       " 'privileges',\n",
       " 'jones',\n",
       " 'drunkenness',\n",
       " 'information',\n",
       " 'excitement',\n",
       " 'danger',\n",
       " 'assigned',\n",
       " 'employees',\n",
       " 'nutrition',\n",
       " 'rise',\n",
       " 'presently',\n",
       " 'please',\n",
       " 'wherever',\n",
       " 'purchasing',\n",
       " 'presented',\n",
       " 'automobile',\n",
       " 'alley',\n",
       " 'behavior',\n",
       " 'consideration',\n",
       " 'steps',\n",
       " 'palace',\n",
       " 'lady',\n",
       " 'prospective',\n",
       " 'motivation',\n",
       " 'dividends',\n",
       " 'avoid',\n",
       " 'sympathy',\n",
       " 'educated',\n",
       " 'dough',\n",
       " 'bouhe',\n",
       " 'bodily',\n",
       " 'emergency',\n",
       " 'scores',\n",
       " 'suspicion',\n",
       " 'securely',\n",
       " 'retain',\n",
       " 'citizenship',\n",
       " 'forwarded',\n",
       " 'commenced',\n",
       " 'de',\n",
       " 'soviet',\n",
       " 'frequently',\n",
       " 'successively',\n",
       " 'gas',\n",
       " 'manpower',\n",
       " 'railing',\n",
       " 'criminal',\n",
       " 'somewhat',\n",
       " 'aroused',\n",
       " 'respects',\n",
       " 'complaints',\n",
       " 'exercise',\n",
       " 'identifiable',\n",
       " 'premises',\n",
       " 'ere',\n",
       " 'yet',\n",
       " 'overlooked',\n",
       " 'vice',\n",
       " 'finance',\n",
       " 'measures',\n",
       " 'life',\n",
       " 'situation',\n",
       " 'metropolitan',\n",
       " 'union',\n",
       " 'names',\n",
       " 'garnish',\n",
       " 'conclude',\n",
       " 'statute',\n",
       " 'effects',\n",
       " 'asked',\n",
       " 'mullay',\n",
       " 'fights',\n",
       " 'elevator',\n",
       " 'maltby',\n",
       " 'inability',\n",
       " 'boys',\n",
       " 'greater',\n",
       " 'narrative',\n",
       " 'appointment',\n",
       " 'militant',\n",
       " 'etc',\n",
       " 'accident',\n",
       " 'bay',\n",
       " 'ask',\n",
       " 'selling',\n",
       " 'inconvenience',\n",
       " 'turn',\n",
       " 'stombaugh',\n",
       " 'temporary',\n",
       " 'telling',\n",
       " 'allotment',\n",
       " 'moments',\n",
       " 'frames',\n",
       " 'failures',\n",
       " 'mostly',\n",
       " 'silent',\n",
       " 'trips',\n",
       " 'contact',\n",
       " 'everyone',\n",
       " 'kellerman',\n",
       " 'convicted',\n",
       " 'conducted',\n",
       " 'constantly',\n",
       " 'rode',\n",
       " 'coiners',\n",
       " 'bitumen',\n",
       " 'urged',\n",
       " 'third',\n",
       " 'fast',\n",
       " 'accomplishment',\n",
       " 'objective',\n",
       " 'exactly',\n",
       " 'arrangement',\n",
       " 'track',\n",
       " 'companys',\n",
       " 'leaving',\n",
       " 'kate',\n",
       " 'go',\n",
       " 'limit',\n",
       " 'helpless',\n",
       " 'impossible',\n",
       " 'vicinity',\n",
       " 'committal',\n",
       " 'progress',\n",
       " 'affair',\n",
       " 'recently',\n",
       " 'rope',\n",
       " 'tom',\n",
       " 'hertford',\n",
       " 'enacted',\n",
       " 'belsize',\n",
       " 'constant',\n",
       " 'request',\n",
       " 'lawson',\n",
       " 'influenced',\n",
       " 'shells',\n",
       " 'lunch',\n",
       " 'we',\n",
       " 'perry',\n",
       " 'least',\n",
       " 'ostensibly',\n",
       " 'cases',\n",
       " 'force',\n",
       " 'inspector',\n",
       " 'stomach',\n",
       " 'kay',\n",
       " 'manacled',\n",
       " 'assistance',\n",
       " 'studied',\n",
       " 'warrant',\n",
       " 'spirits',\n",
       " 'well',\n",
       " 'president',\n",
       " 'accept',\n",
       " 'provide',\n",
       " 'experts',\n",
       " 'seven',\n",
       " 'minor',\n",
       " 'instructed',\n",
       " 'plates',\n",
       " 'voluntary',\n",
       " 'branch',\n",
       " 'murderer',\n",
       " 'royal',\n",
       " 'towards',\n",
       " 'credit',\n",
       " 'capacity',\n",
       " 'turning',\n",
       " 'fundamentally',\n",
       " 'cetera',\n",
       " 'cry',\n",
       " 'real',\n",
       " 'belonged',\n",
       " 'affecting',\n",
       " 'grenades',\n",
       " 'warehouse',\n",
       " 'flee',\n",
       " 'removed',\n",
       " 'guilt',\n",
       " 'unsatisfactory',\n",
       " 'firms',\n",
       " 'professional',\n",
       " 'styled',\n",
       " 'servants',\n",
       " 'immediately',\n",
       " 'aperture',\n",
       " 'here',\n",
       " 'luck',\n",
       " 'seems',\n",
       " 'facts',\n",
       " 'pool',\n",
       " 'lift',\n",
       " 'of',\n",
       " 'see',\n",
       " 'contrast',\n",
       " 'sixteenth',\n",
       " 'writing',\n",
       " 'rolt',\n",
       " 'commanded',\n",
       " 'quarters',\n",
       " 'excessive',\n",
       " 'engaged',\n",
       " 'females',\n",
       " 'score',\n",
       " 'moved',\n",
       " 'constructed',\n",
       " 'replaced',\n",
       " 'included',\n",
       " 'distinctly',\n",
       " 'soon',\n",
       " 'items',\n",
       " 'dangers',\n",
       " 'above',\n",
       " 'importance',\n",
       " 'wharf',\n",
       " 'towers',\n",
       " 'truancy',\n",
       " 'pint',\n",
       " 'equal',\n",
       " 'climbing',\n",
       " 'tap',\n",
       " 'end',\n",
       " 'modified',\n",
       " 'usually',\n",
       " 'accommodation',\n",
       " 'anxious',\n",
       " 'tray',\n",
       " 'norman',\n",
       " 'trauma',\n",
       " 'building',\n",
       " 'remains',\n",
       " 'oxygenation',\n",
       " 'harm',\n",
       " 'or',\n",
       " 'longer',\n",
       " 'maintenance',\n",
       " 'zahm',\n",
       " 'hughes',\n",
       " 'vigorous',\n",
       " 'reluctance',\n",
       " 'reforms',\n",
       " 'brick',\n",
       " 'ammunition',\n",
       " 'dock',\n",
       " 'r',\n",
       " 'technology',\n",
       " 'dependent',\n",
       " 'one',\n",
       " 'unoccupied',\n",
       " 'incentive',\n",
       " 'faced',\n",
       " 'intended',\n",
       " 'lax',\n",
       " 'locate',\n",
       " 'develop',\n",
       " 'objected',\n",
       " 'alerted',\n",
       " 'vital',\n",
       " 'been',\n",
       " 'adams',\n",
       " 'pick',\n",
       " 'stature',\n",
       " 'linking',\n",
       " 'fruitful',\n",
       " 'showed',\n",
       " 'stories',\n",
       " 'handmade',\n",
       " 'defraud',\n",
       " 'conveyed',\n",
       " 'replied',\n",
       " 'quart',\n",
       " 'ruined',\n",
       " 'efforts',\n",
       " 'learning',\n",
       " 'permit',\n",
       " 'peace',\n",
       " 'hardwicke',\n",
       " 'root',\n",
       " 'liberty',\n",
       " 'five',\n",
       " 'prefer',\n",
       " 'controlling',\n",
       " 'scan',\n",
       " 'yeast',\n",
       " 'participated',\n",
       " 'offender',\n",
       " 'conte',\n",
       " 'fastened',\n",
       " 'culprit',\n",
       " 'father',\n",
       " 'arm',\n",
       " 'spread',\n",
       " 'rifling',\n",
       " 'wardsman',\n",
       " 'occur',\n",
       " 'ideal',\n",
       " 'excretion',\n",
       " 'sufficiently',\n",
       " 'sworn',\n",
       " 'oak',\n",
       " 'step',\n",
       " 'labor',\n",
       " 'hammock',\n",
       " 'wrist',\n",
       " 'try',\n",
       " 'presence',\n",
       " 'adult',\n",
       " 'expresses',\n",
       " 'hiding',\n",
       " 'quarreling',\n",
       " 'rapid',\n",
       " 'publican',\n",
       " 'strict',\n",
       " 'fritz',\n",
       " 'cranks',\n",
       " 'excellent',\n",
       " 'ample',\n",
       " 'revealed',\n",
       " 'arnold',\n",
       " 'terror',\n",
       " 'casket',\n",
       " 'medical',\n",
       " 'next',\n",
       " 'invented',\n",
       " 'shipping',\n",
       " 'absorbs',\n",
       " 'six',\n",
       " 'treatment',\n",
       " 'imgur',\n",
       " 'entering',\n",
       " 'kennedys',\n",
       " 'loaded',\n",
       " 'maximum',\n",
       " 'wider',\n",
       " 'printers',\n",
       " 'expressing',\n",
       " 'conceived',\n",
       " 'regularly',\n",
       " 'lack',\n",
       " 'plead',\n",
       " 'cellular',\n",
       " 'knead',\n",
       " 'belonging',\n",
       " 'clifton',\n",
       " 'posts',\n",
       " 'valuables',\n",
       " 'for',\n",
       " 'heat',\n",
       " 'alert',\n",
       " 'hayes',\n",
       " 'mortar',\n",
       " 'jury',\n",
       " 'documents',\n",
       " 'murderers',\n",
       " 'chances',\n",
       " 'chats',\n",
       " 'calculated',\n",
       " 'abraham',\n",
       " 'line',\n",
       " 'serial',\n",
       " 'crowd',\n",
       " 'activities',\n",
       " 'protoplasm',\n",
       " 'until',\n",
       " 'meant',\n",
       " 'organization',\n",
       " 'even',\n",
       " 'containing',\n",
       " 'unable',\n",
       " 'value',\n",
       " 'thomas',\n",
       " 'asking',\n",
       " 'blanket',\n",
       " 'coming',\n",
       " 'caliber',\n",
       " 'universal',\n",
       " 'attachment',\n",
       " 'captors',\n",
       " 'contemplated',\n",
       " 'luncheon',\n",
       " 'subdued',\n",
       " 'specific',\n",
       " 'category',\n",
       " 'rob',\n",
       " 'tomorrow',\n",
       " 'industry',\n",
       " 'cruelty',\n",
       " 'sirens',\n",
       " 'purpose',\n",
       " 'spend',\n",
       " 'weigh',\n",
       " 'reigns',\n",
       " 'absent',\n",
       " 'independently',\n",
       " 'pleasant',\n",
       " 'destiny',\n",
       " 'rifles',\n",
       " 'required',\n",
       " 'wrapping',\n",
       " 'writer',\n",
       " 'devoted',\n",
       " 'raised',\n",
       " 'accession',\n",
       " 'establishment',\n",
       " 'constituted',\n",
       " 'television',\n",
       " 'bench',\n",
       " 'visual',\n",
       " 'attached',\n",
       " 'poverty',\n",
       " 'prove',\n",
       " 'sixty',\n",
       " 'nine',\n",
       " 'alike',\n",
       " 'verify',\n",
       " 'studies',\n",
       " 'arrested',\n",
       " 'contrary',\n",
       " 'authorized',\n",
       " 'alighted',\n",
       " 'prices',\n",
       " 'symptoms',\n",
       " 'favorite',\n",
       " 'babylonian',\n",
       " 'journeys',\n",
       " 'observations',\n",
       " 'london',\n",
       " 'shrigley',\n",
       " 'escapes',\n",
       " 'areas',\n",
       " 'illinois',\n",
       " 'printed',\n",
       " 'extravagance',\n",
       " 'cheek',\n",
       " 'verbal',\n",
       " 'dietaries',\n",
       " 'bushy',\n",
       " 'confirmed',\n",
       " 'external',\n",
       " 'generally',\n",
       " 'whereas',\n",
       " 'democracy',\n",
       " 'occurred',\n",
       " 'sixteen',\n",
       " 'soames',\n",
       " 'disappointed',\n",
       " 'attacked',\n",
       " 'guineas',\n",
       " 'pan',\n",
       " 'detachment',\n",
       " 'landed',\n",
       " 'flight',\n",
       " 'tragic',\n",
       " 'group',\n",
       " 'coals',\n",
       " 'reader',\n",
       " 'combined',\n",
       " 'thirteen',\n",
       " 'personnel',\n",
       " 'harvey',\n",
       " 'take',\n",
       " 'day',\n",
       " 'supreme',\n",
       " 'framers',\n",
       " 'ear',\n",
       " 'killed',\n",
       " 'add',\n",
       " 'avenue',\n",
       " 'manual',\n",
       " 'production',\n",
       " 'judges',\n",
       " 'community',\n",
       " 'creature',\n",
       " 'disposed',\n",
       " 'ninety',\n",
       " 'decade',\n",
       " 'tuft',\n",
       " 'absorbed',\n",
       " 'shame',\n",
       " 'indicating',\n",
       " 'deer',\n",
       " 'conversation',\n",
       " 'scattered',\n",
       " 'caducibranch',\n",
       " 'organism',\n",
       " 'concerned',\n",
       " 'flow',\n",
       " 'gibbon',\n",
       " 'inner',\n",
       " 'out',\n",
       " 'illustrations',\n",
       " 'view',\n",
       " 't',\n",
       " 'debtors',\n",
       " 'inhabitants',\n",
       " 'cool',\n",
       " 'zapruder',\n",
       " 'superseded',\n",
       " 'something',\n",
       " 'planned',\n",
       " 'varying',\n",
       " 'point',\n",
       " 'underpass',\n",
       " 'attributed',\n",
       " 'original',\n",
       " 'prompted',\n",
       " 'voluntarily',\n",
       " 'fain',\n",
       " 'ordering',\n",
       " 'resources',\n",
       " 'surgeon',\n",
       " 'mansion',\n",
       " 'while',\n",
       " 'legislature',\n",
       " 'majority',\n",
       " 'stopped',\n",
       " 'cracked',\n",
       " 'handkerchief',\n",
       " 'terrified',\n",
       " 'obscured',\n",
       " 'along',\n",
       " 'which',\n",
       " 'edwin',\n",
       " 'live',\n",
       " 'flour',\n",
       " 'die',\n",
       " 'shaped',\n",
       " 'wish',\n",
       " 'defect',\n",
       " 'bankruptcy',\n",
       " 'boards',\n",
       " 'purposely',\n",
       " 'dissenting',\n",
       " 'downtown',\n",
       " 'did',\n",
       " 'deciding',\n",
       " 'wait',\n",
       " 'last',\n",
       " 'addressed',\n",
       " 've',\n",
       " 'long',\n",
       " 'merchant',\n",
       " 'require',\n",
       " 'severe',\n",
       " 'properly',\n",
       " 'rigid',\n",
       " 'within',\n",
       " 'stars',\n",
       " 'answered',\n",
       " 'atrocity',\n",
       " 'available',\n",
       " 'betting',\n",
       " 'place',\n",
       " 'governmental',\n",
       " 'houston',\n",
       " 'suitable',\n",
       " 'corps',\n",
       " 'move',\n",
       " 'sensitive',\n",
       " 'need',\n",
       " 'centuries',\n",
       " 'runs',\n",
       " 'persuasive',\n",
       " 'trading',\n",
       " 'kingdom',\n",
       " 'prolonged',\n",
       " 'boxes',\n",
       " 'harold',\n",
       " 'on',\n",
       " 'acid',\n",
       " 'carefully',\n",
       " 'solitary',\n",
       " 'writs',\n",
       " 'murder',\n",
       " 'phases',\n",
       " 'michael',\n",
       " 'factors',\n",
       " 'breadth',\n",
       " 'lawn',\n",
       " 'turk',\n",
       " 'leather',\n",
       " 'san',\n",
       " 'settlement',\n",
       " 'clothing',\n",
       " 'wheeled',\n",
       " 's',\n",
       " 'consented',\n",
       " 'revive',\n",
       " 'detection',\n",
       " 'lees',\n",
       " 'scaffold',\n",
       " 'social',\n",
       " 'horror',\n",
       " 'distinguish',\n",
       " 'navy',\n",
       " 'heavily',\n",
       " 'ruth',\n",
       " 'communications',\n",
       " 'saying',\n",
       " 'results',\n",
       " 'door',\n",
       " 'mental',\n",
       " 'comfort',\n",
       " 'shown',\n",
       " 'solely',\n",
       " 'operated',\n",
       " 'capitalist',\n",
       " 'rations',\n",
       " 'cleanliness',\n",
       " 'meaning',\n",
       " 'resting',\n",
       " 'suicides',\n",
       " 'northern',\n",
       " 'bedding',\n",
       " 'seemingly',\n",
       " 'roosevelt',\n",
       " 'diverse',\n",
       " 'burglary',\n",
       " 'makes',\n",
       " 'adopted',\n",
       " 'learnt',\n",
       " 'carbonic',\n",
       " 'hostility',\n",
       " 'separation',\n",
       " 'roberts',\n",
       " 'rarely',\n",
       " 'strychnia',\n",
       " 'skull',\n",
       " 'widow',\n",
       " 'mounted',\n",
       " 'likely',\n",
       " 'matter',\n",
       " 'demonstrated',\n",
       " 'worry',\n",
       " 'neighboring',\n",
       " 'lost',\n",
       " 'angeles',\n",
       " 'variety',\n",
       " 'requirement',\n",
       " 'edmunds',\n",
       " 'slowly',\n",
       " 'yarborough',\n",
       " 'thornley',\n",
       " 'sergeant',\n",
       " ...}"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_wordtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "feff57cc-0706-422c-a508-a405b989d608",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are  5431  training wordtypes in cmudict\n"
     ]
    }
   ],
   "source": [
    "print(\"there are \", len(train_wordtypes.intersection(set(cmudict.keys()))),\" training wordtypes in cmudict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "f3513b9d-e990-4630-b30d-cc44d0ad9026",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use cmudict to get pronunciation for train wordtypes\n",
    "\n",
    "train_wordtype2pron = {}\n",
    "for w in train_wordtypes.intersection(set(cmudict.keys())):\n",
    "    train_wordtype2pron[w] = cmudict[w][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "3945c495-fd86-4738-ad93-dcbbbf8d68cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use G2P to predict pronunciations for wordtypes in training set but not in cmudict\n",
    "\n",
    "from speechbrain.pretrained import GraphemeToPhoneme\n",
    "g2p = GraphemeToPhoneme.from_hparams(\"speechbrain/soundchoice-g2p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "5646b2b5-00ae-49e5-9621-bea7479db5ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                             | 0/181 [00:00<?, ?it/s]Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|███████████████████████████████████████████████████| 181/181 [00:51<00:00,  3.49it/s]\n"
     ]
    }
   ],
   "source": [
    "for w in tqdm(train_wordtypes - set(cmudict.keys())):\n",
    "    train_wordtype2pron[w] = g2p(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d166cb-c951-423a-ad02-7be349eb179b",
   "metadata": {},
   "source": [
    "## save pron dict to disk\n",
    "\n",
    "in two formats\n",
    "- generic\n",
    "- for training G2P model (https://pypi.org/project/phonetisaurus/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "b8b742af-4180-47c6-bf9b-7ba227ae3814",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generic\n",
    "with open('/home/s1785140/data/ljspeech_fastpitch/train_meta_half_pron_dict.json', 'w') as f:\n",
    "    json.dump(train_wordtype2pron, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "c943b94a-c16a-45df-a598-dc3e406aa8fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for G2P training\n",
    "#/path/to/lexicon.dict\n",
    "#lexicon format:\n",
    "#word1 phoneme1 phoneme2 ...\n",
    "#word2 phoneme1 phoneme2 phoneme3 ...\n",
    "g2p_training_lexicon_lines = []\n",
    "for w, pron in train_wordtype2pron.items():\n",
    "    l = f\"{w} {' '.join(pron)}\"\n",
    "    g2p_training_lexicon_lines.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "672819e3-f81a-4467-b902-fcfb2305d509",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'friend F R EH N D'"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g2p_training_lexicon_lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "a2e62ae8-4475-493e-b659-7f942e86d0a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('/home/s1785140/data/ljspeech_fastpitch/train_meta_half_prons_for_training_g2p.dict', 'w') as f:\n",
    "    f.write('\\n'.join(g2p_training_lexicon_lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a8019a-dc36-4aa5-ac32-3519f308d347",
   "metadata": {},
   "source": [
    "# Train G2P model using only wordtypes contained in data used to train TTS/ASR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "6265822b-372f-4b42-9cd0-4470d1f64549",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Collecting phonetisaurus\n",
      "  Downloading phonetisaurus-0.3.0-py3-none-manylinux1_x86_64.whl (12.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: phonetisaurus\n",
      "Successfully installed phonetisaurus-0.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install phonetisaurus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "a73d6103-4958-47c3-9c40-36050386c7e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[94mINFO:phonetisaurus-train:2023-03-15 16:08:51\u001b[0m:  Checking command configuration...\n",
      "\u001b[94mDEBUG:phonetisaurus-train:2023-03-15 16:08:51\u001b[0m:  Directory does not exist.  Trying to create.\n",
      "\u001b[94mINFO:phonetisaurus-train:2023-03-15 16:08:51\u001b[0m:  Checking lexicon for reserved characters: '}', '|', '_'...\n",
      "\u001b[94mDEBUG:phonetisaurus-train:2023-03-15 16:08:51\u001b[0m:  arpa_path:  train/model.o8.arpa\n",
      "\u001b[94mDEBUG:phonetisaurus-train:2023-03-15 16:08:51\u001b[0m:  corpus_path:  train/model.corpus\n",
      "\u001b[94mDEBUG:phonetisaurus-train:2023-03-15 16:08:51\u001b[0m:  dir_prefix:  train\n",
      "\u001b[94mDEBUG:phonetisaurus-train:2023-03-15 16:08:51\u001b[0m:  grow:  False\n",
      "\u001b[94mDEBUG:phonetisaurus-train:2023-03-15 16:08:51\u001b[0m:  lexicon_file:  /tmp/tmp5lwpye_m.txt\n",
      "\u001b[94mDEBUG:phonetisaurus-train:2023-03-15 16:08:51\u001b[0m:  logger:  <Logger phonetisaurus-train (DEBUG)>\n",
      "\u001b[94mDEBUG:phonetisaurus-train:2023-03-15 16:08:51\u001b[0m:  makeJointNgramCommand:  <bound method G2PModelTrainer._mitlm of <__main__.G2PModelTrainer object at 0x7f6608dc4580>>\n",
      "\u001b[94mDEBUG:phonetisaurus-train:2023-03-15 16:08:51\u001b[0m:  model_path:  train/model.fst\n",
      "\u001b[94mDEBUG:phonetisaurus-train:2023-03-15 16:08:51\u001b[0m:  model_prefix:  model\n",
      "\u001b[94mDEBUG:phonetisaurus-train:2023-03-15 16:08:51\u001b[0m:  ngram_order:  8\n",
      "\u001b[94mDEBUG:phonetisaurus-train:2023-03-15 16:08:51\u001b[0m:  seq1_del:  False\n",
      "\u001b[94mDEBUG:phonetisaurus-train:2023-03-15 16:08:51\u001b[0m:  seq1_max:  2\n",
      "\u001b[94mDEBUG:phonetisaurus-train:2023-03-15 16:08:51\u001b[0m:  seq2_del:  True\n",
      "\u001b[94mDEBUG:phonetisaurus-train:2023-03-15 16:08:51\u001b[0m:  seq2_max:  2\n",
      "\u001b[94mDEBUG:phonetisaurus-train:2023-03-15 16:08:51\u001b[0m:  verbose:  True\n",
      "\u001b[94mDEBUG:phonetisaurus-train:2023-03-15 16:08:51\u001b[0m:  phonetisaurus-align --input=/tmp/tmp5lwpye_m.txt --ofile=train/model.corpus --seq1_del=false --seq2_del=true --seq1_max=2 --seq2_max=2 --grow=false\n",
      "\u001b[94mINFO:phonetisaurus-train:2023-03-15 16:08:51\u001b[0m:  Aligning lexicon...\n",
      "phonetisaurus-align: /lib64/libstdc++.so.6: version `GLIBCXX_3.4.20' not found (required by phonetisaurus-align)\n",
      "phonetisaurus-align: /lib64/libstdc++.so.6: version `GLIBCXX_3.4.21' not found (required by phonetisaurus-align)\n",
      "phonetisaurus-align: /lib64/libstdc++.so.6: version `GLIBCXX_3.4.21' not found (required by /home/s1785140/miniconda3/envs/speller/lib/python3.8/site-packages/phonetisaurus/lib/x86_64/libfst.so.13)\n",
      "\u001b[94mERROR:phonetisaurus-train:2023-03-15 16:08:51\u001b[0m:  Alignment failed.  Exiting.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/s1785140/miniconda3/envs/speller/bin/phonetisaurus\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/home/s1785140/miniconda3/envs/speller/lib/python3.8/site-packages/phonetisaurus/__main__.py\", line 74, in main\n",
      "    do_train(args, casing, env)\n",
      "  File \"/home/s1785140/miniconda3/envs/speller/lib/python3.8/site-packages/phonetisaurus/__main__.py\", line 209, in do_train\n",
      "    train(lexicon=lexicon, model_path=args.model, corpus_path=args.corpus, env=env)\n",
      "  File \"/home/s1785140/miniconda3/envs/speller/lib/python3.8/site-packages/phonetisaurus/__init__.py\", line 121, in train\n",
      "    subprocess.check_call(train_cmd, cwd=temp_dir_str, env=env)\n",
      "  File \"/home/s1785140/miniconda3/envs/speller/lib/python3.8/subprocess.py\", line 364, in check_call\n",
      "    raise CalledProcessError(retcode, cmd)\n",
      "subprocess.CalledProcessError: Command '['phonetisaurus-train', '--lexicon', '/tmp/tmp5lwpye_m.txt', '--seq2_del', '--verbose']' returned non-zero exit status 1.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['phonetisaurus', 'train', '--model', '/home/s1785140/data/ljspeech_fastpitch/train_meta_half_phonetisaurusG2P_model.fst', '/home/s1785140/data/ljspeech_fastpitch/train_meta_half_prons_for_training_g2p.dict'], returncode=1)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "subprocess.run([\"phonetisaurus\",\n",
    "                \"train\",\n",
    "                \"--model\", \n",
    "                \"/home/s1785140/data/ljspeech_fastpitch/train_meta_half_phonetisaurusG2P_model.fst\",\n",
    "                \"/home/s1785140/data/ljspeech_fastpitch/train_meta_half_prons_for_training_g2p.dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f69c6f-c10e-41f3-ae61-0f3fab8149e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
